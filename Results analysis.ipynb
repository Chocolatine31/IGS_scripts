{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7245fb5-bd42-4507-aa7b-7ca70e59682b",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56506c04-a227-4e74-8899-fd5c759c01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic & memory management\n",
    "import time # for performance checks\n",
    "import datetime # for log\n",
    "from datetime import timedelta\n",
    "import psutil # for memory checks\n",
    "from psutil._common import bytes2human\n",
    "import winsound # for sound notification when script over\n",
    "import sys\n",
    "import gc # garbage collector - clean up memory\n",
    "\n",
    "# Data analysis\n",
    "import os\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import rasterio.mask\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from rasterstats import zonal_stats  #for zonal analysis\n",
    "from sklearn import metrics    #for confusion matrix\n",
    "import dask.array as da # Package added to sds2024 environment for chunking and paralllel processing of large files\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import BoundaryNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14211d8d-c3ad-40f3-a75d-67bc4dc40073",
   "metadata": {},
   "source": [
    "# Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da805206-991d-4c34-8a5d-e834242ef700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Paths\n",
    "preppedDat_path = 'C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/'\n",
    "rawDat_path = 'C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/raw/'\n",
    "output_path = 'C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/'\n",
    "interimFiles_path = 'C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/'\n",
    "workFiles_path = 'C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/work files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f537be65-d94a-49f3-b564-65bfed8dedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AOI_path = preppedDat_path+'Study_area_basedOn_UK_BFC_EPSG27700.gpkg' # Study area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e27b3f-957c-4f25-a5dd-3e43c3cbd537",
   "metadata": {},
   "source": [
    "# Auxiliary scripts\n",
    "## Memory usage check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10069ad5-1ab8-47ae-8301-cbb90d52b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check memory usage\n",
    "logram = f'RAM memory % used:{psutil.virtual_memory()[2]} --- {bytes2human(psutil.virtual_memory()[3])}      ||      Swap memory used {psutil.swap_memory().percent}% --- {bytes2human(psutil.swap_memory().used)}'\n",
    "## Code from:\n",
    "## https://stackoverflow.com/questions/40993626/list-memory-usage-in-ipython-and-jupyter\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "logvar = f'Memory use: {sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)}'\n",
    "logall = f'{logram}\\n{logvar}'\n",
    "\n",
    "print(logall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ed74fb-115b-4b68-bf7b-016f968b957b",
   "metadata": {},
   "source": [
    "## Performance counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4623bc70-40ab-4cc2-b5aa-945c4d9e4310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code block run in 0:00:00.000082\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter() # Performance counter\n",
    "\n",
    "# Performance check\n",
    "end = time.perf_counter()\n",
    "elapsed_time = end - start\n",
    "# Convert the elapsed time to a timedelta object \n",
    "elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "logproc = f'Code block run in {elapsed_time_str}'\n",
    "print(logproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0708ac84-9d07-4dc4-b137-5b0cfc949606",
   "metadata": {},
   "source": [
    "# Energy output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46b4d8-230f-4605-a9a8-f3c71e36e70b",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a90d05-0f0c-409a-b371-3f4faa873c10",
   "metadata": {},
   "source": [
    "### Patch statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03058971-b487-4d27-99c0-4089b4e6c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for energy output\n",
    "# Created 24/02\n",
    "# Last edit 15/03\n",
    "def energy_out(scenario_nr, xltables_path):\n",
    "    start = time.perf_counter()\n",
    "    print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Patch stats start')\n",
    "    \n",
    "    # Get gpkg paths list\n",
    "    results_folder = f'{output_path}areas/'\n",
    "    filenames = os.listdir(results_folder)\n",
    "    scenar_str = f'Scenario{scenario_nr}_'\n",
    "    gdf_paths = [f'{results_folder}{_}' for _ in filenames if scenar_str in _] # Pick only files with specified scenario number\n",
    "    \n",
    "    # Iterating across the various allsub results (all patches/patches above area threshold)\n",
    "    for i in gdf_paths:\n",
    "        # Define write paths\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        write_path_allCells = f'{output_path}stats/{filename_noExt}_Energy_patch_stats.xlsx'\n",
    "        write_path_gpkg = f'{output_path}energy/{filename_noExt}_Energy.gpkg'\n",
    "        \n",
    "        # Read file for selected allsub  result\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Reading file {i}')\n",
    "        gdf = gpd.read_file(i)\n",
    "        \n",
    "        ############ 1. SOLAR processing ############\n",
    "        # Create gdf for Solar and Solarwind patches only\n",
    "        re_type = 'Solar'\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing {filename_noExt} --- {re_type}')\n",
    "        sol_gdf = gdf.loc[(gdf['RE_type']==re_type)|(gdf['RE_type']=='SolarWind')] # Select both RE-specific and overlap patches\n",
    "        # Solar resource layers paths\n",
    "        solparam_df = pd.read_excel(xltables_path, sheet_name=f'E Output Params {re_type}')  # Load table from excel sheet\n",
    "        sol_prod_path = solparam_df.loc[solparam_df['Parameter']=='PVOUT (Specific Yield)', 'Value'].iloc[0]\n",
    "        sol_GHI_path = solparam_df.loc[solparam_df['Parameter']=='GHI (Global Horizontal Irradiance)', 'Value'].iloc[0]\n",
    "    \n",
    "        ### Solar specific yield per patch ###\n",
    "        # Get PVOUT per patch\n",
    "        with rio.open(sol_prod_path) as src:\n",
    "            raster =  src.read(1)\n",
    "            geom = sol_gdf['geometry']\n",
    "            stats = zonal_stats(geom, raster, affine = src.transform, stats = 'max min mean median count', all_touched = True, nodata=src.nodata)\n",
    "        # Turn into a df\n",
    "        stats_df = pd.DataFrame(stats, index = sol_gdf.index)\n",
    "        # Reindex to match the original sol_gdf index\n",
    "        stats_df.index = sol_gdf.index\n",
    "        # Merge with source gdf\n",
    "        gdf_stats = gdf.merge(stats_df, how = 'left' ,left_index=True, right_index=True)\n",
    "        gdf_stats['area_check_Sol_yield'] = gdf_stats['Area_(m2)']/gdf_stats['count'] # To check for errors\n",
    "        gdf_stats.rename(columns = {'min':'min_Sol_yield','max':'max_Sol_yield','mean':'mean_Sol_yield','count':'count_Sol_yield','median':'median_Sol_yield'}, inplace=True)\n",
    "\n",
    "        ### GHI per patch ###\n",
    "        with rio.open(sol_GHI_path) as src:\n",
    "            raster =  src.read(1)\n",
    "            geom = sol_gdf['geometry']\n",
    "            stats = zonal_stats(geom, raster, affine = src.transform, stats = 'max min mean median count', all_touched = True, nodata=src.nodata)\n",
    "        # Turn into a df\n",
    "        stats_df = pd.DataFrame(stats, index = sol_gdf.index)\n",
    "        # Merge with gdf\n",
    "        gdf_stats = gdf_stats.merge(stats_df, how = 'left', left_index=True, right_index=True)\n",
    "        gdf_stats['area_check_GHI'] = gdf_stats['Area_(m2)']/gdf_stats['count'] # To check for errors\n",
    "        gdf_stats.rename(columns = {'min':'min_GHI','max':'max_GHI','mean':'mean_GHI','count':'count_GHI','median':'median_GHI'}, inplace=True)\n",
    "        \n",
    "        ### Installed Capacity per patch ###\n",
    "        cap_dens = solparam_df.loc[solparam_df['Parameter']=='Capacity density (MWp/kmÂ²)', 'Value'].iloc[0] # get capacity density from Excel sheet\n",
    "        gdf_stats['Solar Capacity (MWp) (solar only)'] = cap_dens * (gdf_stats['Area_(m2)']/1e6)\n",
    "        \n",
    "        ### Energy per patch ###\n",
    "        ## PVOUT method ##\n",
    "        gdf_stats['Annual Solar Production (GWh)(PVOUT)'] = gdf_stats['Solar Capacity (MWp) (solar only)']*gdf_stats['median_Sol_yield']/1e3 # /1e3 to turn into GWh bc capacity is in MW (PVOUT yield is in kWh/kWp = MWh/MWp)\n",
    "        ## Equation method (McKenna2022a p5) ##\n",
    "        # Get parameters from excel sheet\n",
    "        packing_factor = (solparam_df.loc[solparam_df['Parameter']=='Packing factor (% of area used by panels)', 'Value'].iloc[0])/100\n",
    "        tilt_gain = ((solparam_df.loc[solparam_df['Parameter']=='Tilt gain (%)', 'Value'].iloc[0])+100)/100\n",
    "        year_h = 8760\n",
    "        panel_efficiency = (solparam_df.loc[solparam_df['Parameter']=='Panel efficiency (%)', 'Value'].iloc[0])/100\n",
    "        perf_ratio = (solparam_df.loc[solparam_df['Parameter']=='Performance ratio (%)', 'Value'].iloc[0])/100\n",
    "        gdf_stats['Irradiance (W/m2)'] = gdf_stats['median_GHI']*1e3/8760 # GHI is in kWh/m2/annum --> /8760 hours to convert kWh/a to kW, *1e3 to convert kW/m2 to W/m2 (= MW/km2)\n",
    "        gdf_stats['Annual Solar Production (GWh)(equation)'] = tilt_gain * year_h * panel_efficiency * gdf_stats['Irradiance (W/m2)'] * gdf_stats['Area_(m2)'] * perf_ratio * packing_factor /1e9 # /1e9 to convert from W to GW # McKenna2022a equation (p5)\n",
    "\n",
    "        ############ 2. WIND processing ############\n",
    "        # Create gdf for Wind and Solarwind patches only\n",
    "        re_type = 'Wind'\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing {filename_noExt} --- {re_type}')\n",
    "        win_gdf = gdf.loc[(gdf['RE_type']==re_type)|(gdf['RE_type']=='SolarWind')] # Select both re-specific and overlap patches\n",
    "        # Wind resource layers paths\n",
    "        winparam_df = pd.read_excel(xltables_path, sheet_name=f'E Output Params {re_type}')  # Load table from excel sheet\n",
    "        win_prod_path = winparam_df.loc[winparam_df['Parameter']=='Annual Production (for most adequate class)', 'Value'].iloc[0] # Annual production\n",
    "        win_class_path = winparam_df.loc[winparam_df['Parameter']=='Turbine Class Map', 'Value'].iloc[0] # Optimal turbine class\n",
    "    \n",
    "        ### Annual Production per patch ####\n",
    "        with rio.open(win_prod_path) as src:\n",
    "            raster =  src.read(1)\n",
    "            geom = win_gdf['geometry']\n",
    "            stats = zonal_stats(geom, raster, affine = src.transform, stats = 'max min mean median count', all_touched = True, nodata=src.nodata)\n",
    "        # Turn into a df\n",
    "        stats_df = pd.DataFrame(stats, index = win_gdf.index)\n",
    "        # Merge with gdf\n",
    "        gdf_stats = gdf_stats.merge(stats_df, how='left', left_index=True, right_index=True)\n",
    "        gdf_stats['area_check_Win_production'] = gdf_stats['Area_(m2)']/gdf_stats['count']\n",
    "    \n",
    "        ### Optimal turbine class per patch ###\n",
    "        with rio.open(win_class_path) as src:\n",
    "            raster =  src.read(1)\n",
    "            geom = win_gdf['geometry']\n",
    "            stats = zonal_stats(geom, raster, affine = src.transform, stats = 'max min mean median count', all_touched = True, nodata=src.nodata)\n",
    "        # Turn into a df\n",
    "        stats_df = pd.DataFrame(stats, index = win_gdf.index)    \n",
    "        # Merge with gdf\n",
    "        gdf_stats = gdf_stats.merge(stats_df, how='left',left_index=True, right_index=True, suffixes = ('_Win_production','_Win_Tclass'))\n",
    "        gdf_stats['median_Win_Tclass'] = gdf_stats['median_Win_Tclass'].round() # Rounding to avoid errors with medians that fall exactly at 1.5 or 2.5\n",
    "        gdf_stats['area_check_Win_Tclass'] = gdf_stats['Area_(m2)']/gdf_stats['count_Win_Tclass']\n",
    "        ### Capacity per patch ###\n",
    "        # Turbine density: Get values from Excel sheet, make dict for mapping\n",
    "        turb_dens_df = winparam_df[winparam_df['Parameter'] == 'Turbine density (turbine/kmÂ²)']\n",
    "        turb_dens_dict = dict(zip(turb_dens_df['Turbine class'], turb_dens_df['Value']))\n",
    "        # Map turbine density to turbine class\n",
    "        gdf_stats['Turbine_density'] = gdf_stats['median_Win_Tclass'].map(turb_dens_dict)\n",
    "        # Calculate turbines per patch\n",
    "        gdf_stats['Nr_turbines'] = gdf_stats['Area_(m2)']/1e6*gdf_stats['Turbine_density']\n",
    "        # Calculate capacity\n",
    "        turb_pow = winparam_df.loc[(winparam_df['Parameter'] == 'Turbine capacity (MW)'),'Value'].iloc[0] # Getting turbine rated capacity\n",
    "        gdf_stats['Wind Capacity (MWp)'] = (gdf_stats['Area_(m2)']/1e6) * gdf_stats['Turbine_density'] * turb_pow\n",
    "        \n",
    "        ### Energy per patch ###\n",
    "        # Calculate energy output\n",
    "        gdf_stats['Annual Wind Production (GWh)'] = gdf_stats['mean_Win_production'] * gdf_stats['Nr_turbines']\n",
    "        ### Footprint ###\n",
    "        turb_foot_Denh = winparam_df.loc[(winparam_df['Parameter'] == 'Footprint (ha/MW)'),'Value'].iloc[0] # Getting turbine footprint (Denohlm method)\n",
    "        gdf_stats['Wind footprint (kmÂ²) (Denholm)'] = gdf_stats['Nr_turbines'] * turb_pow * turb_foot_Denh/100 # Uses Denohlm2009 value of 0.4ha/MW - /100 to convert ha to km2\n",
    "        turb_foot_Dela = winparam_df.loc[(winparam_df['Parameter'] == 'Footprint (kmÂ²)'),'Value'].iloc[0] # Getting turbine footprint (Delafield method)\n",
    "        gdf_stats['Wind footprint (kmÂ²) (Delafield)'] = gdf_stats['Nr_turbines'] * turb_foot_Dela\n",
    "        gdf_stats['Wind footprint (% of patch area) (Denholm)'] = (gdf_stats['Wind footprint (kmÂ²) (Denholm)']/(gdf_stats['Area_(m2)']/1e6))*100\n",
    "        gdf_stats['Wind footprint (% of patch area) (Delafield)'] = (gdf_stats['Wind footprint (kmÂ²) (Delafield)']/(gdf_stats['Area_(m2)']/1e6))*100\n",
    "  \n",
    "        ############ 3. OVERLAP Processing #############\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing {filename_noExt} --- Overlaps')\n",
    "        ### 3.1. No overlap allowed --> use RE with best yield on patch\n",
    "        # Function to get RE with highest yield for each patch\n",
    "        def get_max(row):\n",
    "            if pd.isna(row['Annual Solar Production (GWh)(PVOUT)']) and pd.isna(row['Annual Wind Production (GWh)']) :\n",
    "                return np.nan, np.nan\n",
    "            elif pd.isna(row['Annual Solar Production (GWh)(PVOUT)']) and not pd.isna(row['Annual Wind Production (GWh)']):\n",
    "                return row['Annual Wind Production (GWh)'], 'Wind'\n",
    "            elif pd.isna(row['Annual Wind Production (GWh)']) and not pd.isna(row['Annual Solar Production (GWh)(PVOUT)']):\n",
    "                return row['Annual Solar Production (GWh)(PVOUT)'], 'Solar'\n",
    "            elif row['Annual Solar Production (GWh)(PVOUT)'] > row['Annual Wind Production (GWh)']:\n",
    "                return row['Annual Solar Production (GWh)(PVOUT)'], 'Solar' \n",
    "            elif row['Annual Solar Production (GWh)(PVOUT)'] < row['Annual Wind Production (GWh)']:\n",
    "                return row['Annual Wind Production (GWh)'], 'Wind' \n",
    "            elif row['Annual Solar Production (GWh)(PVOUT)'] == row['Annual Wind Production (GWh)'] : # if energy yields are equal, Wind wins (smaller footprint)\n",
    "                return row['Annual Wind Production (GWh)'], 'Wind' \n",
    "        # Apply function\n",
    "        gdf_stats[['Energy per patch (any) (GWh) (no co-location)', 'OverlapExc_RE']] = pd.DataFrame(gdf_stats.apply(get_max, axis=1).tolist(), index=gdf_stats.index)\n",
    "    \n",
    "        ### 3.2. Overlap allowed --> apply % reduction to solar yield\n",
    "        # Get parameters from excel sheet\n",
    "        land_loss = (solparam_df.loc[solparam_df['Parameter']=='Co-locating with Wind: ground area loss (ha per turbine)', 'Value'].iloc[0])*10000 # *10,000 to convert to m2\n",
    "        shading_loss = (100 - solparam_df.loc[solparam_df['Parameter']=='Co-locating with Wind: shadow loss (%)', 'Value'].iloc[0])/100 # Converting % loss into proportion to multiply by\n",
    "        ## Calculate reduced solar capacity for shared sites only##\n",
    "        gdf_stats.loc[gdf_stats['RE_type'] == 'SolarWind','Solar Capacity (MWp) (co-location)'] = (gdf_stats['Solar Capacity (MWp) (solar only)'] * (1-((gdf_stats['Nr_turbines'] * land_loss)/gdf_stats['Area_(m2)']))) # multiplying by 1-fraction of area loss due to Wind infrastructure\n",
    "        ### Energy per patch ###\n",
    "        gdf_stats.loc[gdf_stats['RE_type'] == 'SolarWind','Annual Solar Production (GWh)(co-location)(PVOUT)'] = gdf_stats['Annual Solar Production (GWh)(PVOUT)'] * shading_loss * (1-((gdf_stats['Nr_turbines'] * land_loss)/gdf_stats['Area_(m2)']))\n",
    "        gdf_stats.loc[gdf_stats['RE_type'] == 'SolarWind','Annual Solar Production (GWh)(co-location)(equation)'] = gdf_stats['Annual Solar Production (GWh)(equation)'] * shading_loss * (1-((gdf_stats['Nr_turbines'] * land_loss)/gdf_stats['Area_(m2)']))\n",
    "        gdf_stats.loc[gdf_stats['RE_type'] == 'SolarWind','Wind+Solar Energy per patch (GWh)(co-location)(PVOUT)'] = gdf_stats['Annual Solar Production (GWh)(co-location)(PVOUT)'] + gdf_stats['Annual Wind Production (GWh)']\n",
    "        def total_eng_coloc(row):\n",
    "            if row['RE_type'] == 'SolarWind':\n",
    "                return row['Wind+Solar Energy per patch (GWh)(co-location)(PVOUT)']\n",
    "            elif row['RE_type'] == 'Solar':\n",
    "                return row['Annual Solar Production (GWh)(PVOUT)']\n",
    "            elif row['RE_type'] == 'Wind':\n",
    "                return row['Annual Wind Production (GWh)']\n",
    "        gdf_stats['Energy per patch (any) (GWh) (co-location)'] = gdf_stats.apply(total_eng_coloc, axis=1)\n",
    "    \n",
    "        # Write to gpkg\n",
    "        gdf_stats.to_file(write_path_gpkg)\n",
    "        \n",
    "        # Write to Excel file\n",
    "        with pd.ExcelWriter(write_path_allCells, mode='w') as writer:  \n",
    "            gdf_stats.to_excel(writer, sheet_name = f'Energy_out')\n",
    "\n",
    "       \n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'Code block run in {elapsed_time_str}'\n",
    "    print(logproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc29ffa-0ced-4f4c-8460-e8d8d3ea17cd",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44bb0196-39a3-4595-b69a-2975efc1d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of patch statistics\n",
    "# Created 7/03 (used to be part of energy_out, separated so that summary can be edited and recalculated fast) \n",
    "# Last edit 10/03\n",
    "def energy_summary(scenario_nr, xltables_path): \n",
    "    start = time.perf_counter()\n",
    "    ############ SUMMARIES ############\n",
    "    # Get gpkg paths list\n",
    "    results_folder = f'{output_path}energy/'\n",
    "    filenames = os.listdir(results_folder)\n",
    "    scenar_str = f'Scenario{scenario_nr}_'\n",
    "    gdf_paths = [f'{results_folder}{_}' for _ in filenames if scenar_str in _] # Pick only files with specified scenario number\n",
    "    \n",
    "    # Iterating across the various allsub results (all patches/patches above area threshold)\n",
    "    for i in gdf_paths:\n",
    "        # RE specs tables\n",
    "        solparam_df = pd.read_excel(xltables_path, sheet_name=f'E Output Params Solar')  # Load table from excel sheet\n",
    "        winparam_df = pd.read_excel(xltables_path, sheet_name=f'E Output Params Wind')  # Load table from excel sheet\n",
    "        # Define write path for summary excel file\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        write_path_summary = f'{output_path}stats/{filename_noExt}_summary_stats.xlsx'\n",
    "\n",
    "        patch_stats = f'{output_path}stats/{filename_noExt}_patch_stats.xlsx'\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Reading file {patch_stats}')\n",
    "        gdf_stats = pd.read_excel(patch_stats, sheet_name= 'Energy_out')\n",
    "\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Calculating summaries')      \n",
    "\n",
    "        # Solar Summary\n",
    "        sol_area_km2 = gdf_stats.loc[gdf_stats['RE_type']=='Solar']['Area_(m2)'].sum()/1e6\n",
    "        sum_dict = {'Solar area (kmÂ²)' : [sol_area_km2]}\n",
    "        sum_dict.update({'Solar area (% of GB)' : [sol_area_km2/230142*100]})\n",
    "        sum_dict.update({'Solar Annual production, solar only (TWh) (PVOUT)': (gdf_stats.loc[gdf_stats['RE_type']=='Solar']['Annual Solar Production (GWh)(PVOUT)'].sum()/1e3)})\n",
    "        sum_dict.update({'Solar Energy density, solar only (GWh/kmÂ²) (PVOUT)': (gdf_stats.loc[gdf_stats['RE_type']=='Solar']['Annual Solar Production (GWh)(PVOUT)'].sum()/(gdf_stats.loc[gdf_stats['RE_type']=='Solar']['Area_(m2)'].sum()/1e6))})\n",
    "        sum_dict.update({'Solar Annual production, solar only (TWh) (equation)': (gdf_stats.loc[gdf_stats['RE_type']=='Solar']['Annual Solar Production (GWh)(equation)'].sum()/1e3)})\n",
    "        sum_dict.update({'Solar Energy density, solar only (GWh/kmÂ²) (equation)': (gdf_stats.loc[gdf_stats['RE_type']=='Solar']['Annual Solar Production (GWh)(equation)'].sum()/(gdf_stats.loc[gdf_stats['RE_type']=='Solar']['Area_(m2)'].sum()/1e6))})\n",
    "        sum_dict.update({'Solar Capacity, solar only (GW)' : (gdf_stats.loc[gdf_stats['RE_type']=='Solar']['Solar Capacity (MWp) (solar only)'].sum())/1e3})\n",
    "        sum_dict.update({'Solar Capacity density, solar only (MW/kmÂ²)': (sum_dict['Solar Capacity, solar only (GW)']*1e3)/sum_dict['Solar area (kmÂ²)']})\n",
    "        # Wind Summary\n",
    "        win_area_km2 = gdf_stats.loc[gdf_stats['RE_type']=='Wind']['Area_(m2)'].sum()/1e6\n",
    "        turb_pow = winparam_df.loc[(winparam_df['Parameter'] == 'Turbine capacity (MW)'),'Value'].iloc[0] # Getting turbine power rating\n",
    "        sum_dict.update({'Wind area (kmÂ²)' : [win_area_km2]})\n",
    "        win_foot_Denh = gdf_stats.loc[gdf_stats['RE_type']=='Wind']['Wind footprint (kmÂ²) (Denholm)'].sum()\n",
    "        sum_dict.update({'Wind footprint (wind patches only) (kmÂ²) (Denholm)' : win_foot_Denh})\n",
    "        win_foot_Dela = gdf_stats.loc[gdf_stats['RE_type']=='Wind']['Wind footprint (kmÂ²) (Delafield)'].sum()\n",
    "        sum_dict.update({'Wind footprint (wind patches only) (kmÂ²) (Delafield)' : win_foot_Dela})\n",
    "        sum_dict.update({'Wind footprint (wind patches only) (% of patch area) (Denholm)' : sum_dict['Wind footprint (wind patches only) (kmÂ²) (Denholm)']/sum_dict['Wind area (kmÂ²)']*100})\n",
    "        sum_dict.update({'Wind footprint (wind patches only) (% of patch area) (Delafield)' : sum_dict['Wind footprint (wind patches only) (kmÂ²) (Delafield)']/sum_dict['Wind area (kmÂ²)']*100})\n",
    "        sum_dict.update({'Wind area (% of GB)' : [win_area_km2/230142*100]})\n",
    "        sum_dict.update({'Wind Annual production, wind only (TWh)': (gdf_stats.loc[gdf_stats['RE_type']=='Wind']['Annual Wind Production (GWh)'].sum()/1e3)})\n",
    "        sum_dict.update({'Wind Energy density, wind only (GWh/kmÂ²)': (gdf_stats.loc[gdf_stats['RE_type']=='Wind']['Annual Wind Production (GWh)'].sum()/(gdf_stats.loc[gdf_stats['RE_type']=='Wind']['Area_(m2)'].sum()/1e6))})\n",
    "        sum_dict.update({'Wind Number of turbines': (gdf_stats.loc[gdf_stats['RE_type']=='Wind']['Nr_turbines'].sum())})\n",
    "        sum_dict.update({'Wind Capacity, wind only (GW)': (gdf_stats.loc[gdf_stats['RE_type']=='Wind']['Wind Capacity (MWp)'].sum())/1e3})\n",
    "        sum_dict.update({'Wind Capacity density, wind only (MW/kmÂ²)': (sum_dict['Wind Capacity, wind only (GW)']*1e3)/sum_dict['Wind area (kmÂ²)']})\n",
    "        # Overlap zones\n",
    "        ol_area_km2 = gdf_stats.loc[gdf_stats['RE_type']=='SolarWind']['Area_(m2)'].sum()/1e6 \n",
    "        sum_dict.update({'Overlap area (kmÂ²)' : ol_area_km2})\n",
    "        sum_dict.update({'Overlap area (% of GB)' : ol_area_km2/230142*100})\n",
    "        sum_dict.update({'Overlap Annual production, co-location (TWh)': (gdf_stats.loc[gdf_stats['RE_type']=='SolarWind']['Wind+Solar Energy per patch (GWh)(co-location)(PVOUT)'].sum()/1e3)})\n",
    "        sum_dict.update({'Overlap Annual production, NO co-location (TWh)': (gdf_stats.loc[gdf_stats['RE_type']=='SolarWind']['Energy per patch (any) (GWh) (no co-location)'].sum()/1e3)})\n",
    "        sum_dict.update({'Overlap Solar Capacity (GW) co-location':(gdf_stats.loc[gdf_stats['RE_type']=='SolarWind']['Solar Capacity (MWp) (co-location)'].sum())/1e3})\n",
    "        sum_dict.update({'Overlap Wind Capacity (GW) co-location':(gdf_stats.loc[gdf_stats['RE_type']=='SolarWind']['Wind Capacity (MWp)'].sum())/1e3})\n",
    "        sum_dict.update({'Overlap + Solar area (kmÂ²)':sum_dict['Overlap area (kmÂ²)']+sum_dict['Solar area (kmÂ²)']})\n",
    "        sum_dict.update({'Overlap + Wind area (kmÂ²)':sum_dict['Overlap area (kmÂ²)']+sum_dict['Wind area (kmÂ²)']})\n",
    "        # Totals\n",
    "        sum_dict.update({'Total area (kmÂ²)' : (gdf_stats['Area_(m2)'].sum()/1e6)})\n",
    "        sum_dict.update({'Total area (% of GB)' : sum_dict['Total area (kmÂ²)']/230142*100})\n",
    "        sum_dict.update({'Total footprint (kmÂ²) co-location (Denholm footprint)': ol_area_km2+win_foot_Denh+sol_area_km2})\n",
    "        sum_dict.update({'Total footprint (% of GB) co-location (Denholm footprint)': sum_dict['Total footprint (kmÂ²) co-location (Denholm footprint)']/230142*100})\n",
    "        sum_dict.update({'Total Solar Production, co-location (TWh) (PVOUT)': (gdf_stats.loc[(gdf_stats['RE_type']=='SolarWind')]['Annual Solar Production (GWh)(co-location)(PVOUT)'].sum()/1e3)+(gdf_stats.loc[(gdf_stats['RE_type']=='Solar')]['Annual Solar Production (GWh)(PVOUT)'].sum()/1e3)}) \n",
    "        sum_dict.update({'Total Solar Production, co-location (TWh) (equation)': (gdf_stats.loc[(gdf_stats['RE_type']=='SolarWind')]['Annual Solar Production (GWh)(co-location)(equation)'].sum()/1e3)+(gdf_stats.loc[(gdf_stats['RE_type']=='Solar')]['Annual Solar Production (GWh)(equation)'].sum()/1e3)}) \n",
    "        sum_dict.update({'Total Solar Capacity, co-location (GW)' : sum_dict['Solar Capacity, solar only (GW)'] + sum_dict['Overlap Solar Capacity (GW) co-location']})\n",
    "        sum_dict.update({'Total Wind Capacity, co-location (GW)' : sum_dict['Wind Capacity, wind only (GW)'] + sum_dict['Overlap Wind Capacity (GW) co-location']})\n",
    "        sum_dict.update({'Total Wind Production, co-location (TWh)': (gdf_stats.loc[(gdf_stats['RE_type']=='SolarWind')|(gdf_stats['RE_type']=='Wind')]['Annual Wind Production (GWh)'].sum()/1e3)})\n",
    "        sum_dict.update({'Total Solar Production, NO co-location (TWh) (PVOUT)': (gdf_stats.loc[(gdf_stats['RE_type']=='SolarWind') & (gdf_stats['OverlapExc_RE']=='Solar')]['Energy per patch (any) (GWh) (no co-location)'].sum()/1e3)+(gdf_stats.loc[(gdf_stats['RE_type']=='Solar')]['Annual Solar Production (GWh)(PVOUT)'].sum()/1e3)})\n",
    "        sum_dict.update({'Total Wind Production, NO co-location (TWh)': (gdf_stats.loc[(gdf_stats['RE_type']=='SolarWind') & (gdf_stats['OverlapExc_RE']=='Wind')]['Energy per patch (any) (GWh) (no co-location)'].sum()/1e3) + (gdf_stats.loc[gdf_stats['RE_type']=='Wind']['Annual Wind Production (GWh)'].sum()/1e3)})\n",
    "        sum_dict.update({'Total Production, co-location (TWh)': sum_dict['Total Solar Production, co-location (TWh) (PVOUT)']+sum_dict['Total Wind Production, co-location (TWh)']})\n",
    "        sum_dict.update({'Total Production, NO co-location (TWh)': sum_dict['Total Solar Production, NO co-location (TWh) (PVOUT)']+sum_dict['Total Wind Production, NO co-location (TWh)']})\n",
    "        summary = pd.DataFrame.from_dict(sum_dict)\n",
    "        # Write to file\n",
    "        with pd.ExcelWriter(write_path_summary, mode='w') as writer:  \n",
    "            summary.to_excel(writer, sheet_name = f'Energy_out_Summary')\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Results written to file {write_path_summary}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'Code block run in {elapsed_time_str}'\n",
    "    print(logproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805f801-1e43-4152-a753-8e58e2e215c6",
   "metadata": {},
   "source": [
    "## Run functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc4f523-4e25-46df-afa3-ce2d3fc9a08d",
   "metadata": {},
   "source": [
    "### Patch output + summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5526962e-b6e4-4331-b8bf-74f62d0d4045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-22 23:17:04 - Patch stats FIX start\n",
      "2025-03-22 23:17:04 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario2_all_Energy.gpkg\n",
      "2025-03-22 23:55:21 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario2_area_threshold_Energy.gpkg\n",
      "Fixed and written to xlsx and gpkg\n",
      "2025-03-23 00:10:17 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario2_all_Energy_patch_stats.xlsx\n",
      "2025-03-23 00:17:33 - Calculating summaries\n",
      "2025-03-23 00:17:37 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario2_all_Energy_summary_stats.xlsx\n",
      "2025-03-23 00:17:37 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario2_area_threshold_Energy_patch_stats.xlsx\n",
      "2025-03-23 00:19:25 - Calculating summaries\n",
      "2025-03-23 00:19:26 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario2_area_threshold_Energy_summary_stats.xlsx\n",
      "Code block run in 0:09:09.063951\n",
      "2025-03-23 00:19:26 - Patch stats FIX start\n",
      "2025-03-23 00:19:26 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario3_all_Energy.gpkg\n",
      "2025-03-23 00:46:51 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario3_area_threshold_Energy.gpkg\n",
      "Fixed and written to xlsx and gpkg\n",
      "2025-03-23 00:57:12 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario3_all_Energy_patch_stats.xlsx\n",
      "2025-03-23 01:02:02 - Calculating summaries\n",
      "2025-03-23 01:02:05 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario3_all_Energy_summary_stats.xlsx\n",
      "2025-03-23 01:02:05 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario3_area_threshold_Energy_patch_stats.xlsx\n",
      "2025-03-23 01:03:16 - Calculating summaries\n",
      "2025-03-23 01:03:16 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario3_area_threshold_Energy_summary_stats.xlsx\n",
      "Code block run in 0:06:04.521830\n",
      "2025-03-23 01:03:17 - Patch stats FIX start\n",
      "2025-03-23 01:03:17 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario4_all_Energy.gpkg\n",
      "2025-03-23 01:14:14 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario4_area_threshold_Energy.gpkg\n",
      "Fixed and written to xlsx and gpkg\n",
      "2025-03-23 01:16:47 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario4_all_Energy_patch_stats.xlsx\n",
      "2025-03-23 01:19:23 - Calculating summaries\n",
      "2025-03-23 01:19:24 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario4_all_Energy_summary_stats.xlsx\n",
      "2025-03-23 01:19:24 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario4_area_threshold_Energy_patch_stats.xlsx\n",
      "2025-03-23 01:19:50 - Calculating summaries\n",
      "2025-03-23 01:19:50 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario4_area_threshold_Energy_summary_stats.xlsx\n",
      "Code block run in 0:03:03.761461\n",
      "2025-03-23 01:19:50 - Patch stats FIX start\n",
      "2025-03-23 01:19:50 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario5_all_Energy.gpkg\n",
      "2025-03-23 01:31:27 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario5_area_threshold_Energy.gpkg\n",
      "Fixed and written to xlsx and gpkg\n",
      "2025-03-23 01:35:13 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario5_all_Energy_patch_stats.xlsx\n",
      "2025-03-23 01:37:28 - Calculating summaries\n",
      "2025-03-23 01:37:29 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario5_all_Energy_summary_stats.xlsx\n",
      "2025-03-23 01:37:30 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario5_area_threshold_Energy_patch_stats.xlsx\n",
      "2025-03-23 01:38:07 - Calculating summaries\n",
      "2025-03-23 01:38:07 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario5_area_threshold_Energy_summary_stats.xlsx\n",
      "Code block run in 0:02:54.418142\n",
      "2025-03-23 01:38:07 - Patch stats FIX start\n",
      "2025-03-23 01:38:07 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario6_all_Energy.gpkg\n",
      "2025-03-23 01:48:17 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario6_area_threshold_Energy.gpkg\n",
      "Fixed and written to xlsx and gpkg\n",
      "2025-03-23 01:50:50 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario6_all_Energy_patch_stats.xlsx\n",
      "2025-03-23 01:53:10 - Calculating summaries\n",
      "2025-03-23 01:53:12 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario6_all_Energy_summary_stats.xlsx\n",
      "2025-03-23 01:53:12 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario6_area_threshold_Energy_patch_stats.xlsx\n",
      "2025-03-23 01:54:03 - Calculating summaries\n",
      "2025-03-23 01:54:04 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario6_area_threshold_Energy_summary_stats.xlsx\n",
      "Code block run in 0:03:14.023247\n",
      "2025-03-23 01:54:04 - Patch stats FIX start\n",
      "2025-03-23 01:54:04 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario7_all_Energy.gpkg\n",
      "2025-03-23 02:08:34 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario7_area_threshold_Energy.gpkg\n",
      "Fixed and written to xlsx and gpkg\n",
      "2025-03-23 02:13:18 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario7_all_Energy_patch_stats.xlsx\n",
      "2025-03-23 02:17:21 - Calculating summaries\n",
      "2025-03-23 02:17:23 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario7_all_Energy_summary_stats.xlsx\n",
      "2025-03-23 02:17:23 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario7_area_threshold_Energy_patch_stats.xlsx\n",
      "2025-03-23 02:18:36 - Calculating summaries\n",
      "2025-03-23 02:18:36 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario7_area_threshold_Energy_summary_stats.xlsx\n",
      "Code block run in 0:05:18.415258\n",
      "2025-03-23 02:18:37 - Patch stats FIX start\n",
      "2025-03-23 02:18:37 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_all_Energy.gpkg\n",
      "2025-03-23 03:28:07 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_area_threshold_Energy.gpkg\n",
      "Fixed and written to xlsx and gpkg\n",
      "2025-03-23 03:46:05 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_all_Energy_patch_stats.xlsx\n",
      "2025-03-23 03:54:09 - Calculating summaries\n",
      "2025-03-23 03:54:14 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_all_Energy_summary_stats.xlsx\n",
      "2025-03-23 03:54:14 - Reading file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_area_threshold_Energy_patch_stats.xlsx\n",
      "2025-03-23 03:56:19 - Calculating summaries\n",
      "2025-03-23 03:56:20 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_area_threshold_Energy_summary_stats.xlsx\n",
      "Code block run in 0:10:16.071297\n"
     ]
    }
   ],
   "source": [
    "xltables_path = f'{workFiles_path}Parameters.xlsx'\n",
    "for i in range(2,9):\n",
    "    scenario_nr = i\n",
    "    energy_out(scenario_nr, xltables_path)\n",
    "    energy_summary(scenario_nr, xltables_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58aeaf6b-97dd-449a-a5e4-203006426387",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_path = f'{output_path}energy/Scenario5_all_Energy.gpkg'\n",
    "gdf = gpd.read_file(gdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bb4be47-e8f2-423b-bdc9-04ce49836c40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class_1', 'class_2', 'Area_(m2)', 'RE_type', 'min_Sol_yield',\n",
       "       'max_Sol_yield', 'mean_Sol_yield', 'count_Sol_yield',\n",
       "       'median_Sol_yield', 'area_check_Sol_yield', 'min_GHI', 'max_GHI',\n",
       "       'mean_GHI', 'count_GHI', 'median_GHI', 'area_check_GHI',\n",
       "       'Solar Capacity (MWp) (solar only)',\n",
       "       'Annual Solar Production (GWh)(PVOUT)', 'Irradiance (W/m2)',\n",
       "       'Annual Solar Production (GWh)(equation)', 'min_Win_production',\n",
       "       'max_Win_production', 'mean_Win_production', 'count_Win_production',\n",
       "       'median_Win_production', 'area_check_Win_production', 'min_Win_Tclass',\n",
       "       'max_Win_Tclass', 'mean_Win_Tclass', 'count_Win_Tclass',\n",
       "       'median_Win_Tclass', 'area_check_Win_Tclass', 'Turbine_density',\n",
       "       'Nr_turbines', 'Wind Capacity (MWp)', 'Annual Wind Production (GWh)',\n",
       "       'Wind footprint (kmÂ²) (Denholm)', 'Wind footprint (kmÂ²) (Delafield)',\n",
       "       'Wind footprint (% of patch area) (Denholm)',\n",
       "       'Wind footprint (% of patch area) (Delafield)',\n",
       "       'Energy per patch (any) (GWh) (no co-location)', 'OverlapExc_RE',\n",
       "       'Solar Capacity (MWp) (co-location)',\n",
       "       'Annual Solar Production (GWh)(co-location)(PVOUT)',\n",
       "       'Annual Solar Production (GWh)(co-location)(equation)',\n",
       "       'Wind+Solar Energy per patch (GWh)(co-location)(PVOUT)',\n",
       "       'Energy per patch (any) (GWh) (co-location)', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f3291f-74de-479c-b28a-2b97f4faf161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38907"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gdf.loc[gdf['Area_(m2)']>= 50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f66e3348-70a0-42fa-b380-5e411cecdb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59598"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gdf.loc[gdf['Area_(m2)']>= 20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a4f4ed1-cec1-4675-969f-80537a98ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_5ha = gdf.loc[gdf['Area_(m2)']>= 50000]\n",
    "gdf_2ha = gdf.loc[gdf['Area_(m2)']>= 20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36698f4b-ba11-487b-8299-bc4c4c13e0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area_(m2)                       1.255513e+10\n",
       "Annual Wind Production (GWh)    1.952546e+05\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_5ha[['Area_(m2)', 'Annual Wind Production (GWh)']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01c7802e-439a-49d8-81d0-8b492b4dadd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area_(m2)                       1.322621e+10\n",
       "Annual Wind Production (GWh)    2.032766e+05\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_2ha[['Area_(m2)', 'Annual Wind Production (GWh)']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6766997e-4439-4952-b5cc-4590b7ac28bd",
   "metadata": {},
   "source": [
    "### Combine all summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ba3ae2-248b-4a53-88a0-8a3833ec0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge summaries\n",
    "scenarii = [1,3,5,6,7,8] # Number of all scenarii to be merged\n",
    "comp = [] # create empty list\n",
    "scen_nm = []\n",
    "for i in scenarii:\n",
    "    path1 = f'{output_path}stats/Scenario{i}_all_Energy_summary_stats.xlsx'\n",
    "    path2 = f'{output_path}stats/Scenario{i}_area_threshold_Energy_summary_stats.xlsx'\n",
    "    df1 = pd.read_excel(path1)\n",
    "    df2 = pd.read_excel(path2)\n",
    "    comp.append(df1.iloc[0]) # append the row with summary values\n",
    "    comp.append(df2.iloc[0])\n",
    "    scen_nm.append(f'S{i}')\n",
    "    scen_nm.append(f'S{i} thr')\n",
    "    \n",
    "init_df_path = f'{output_path}stats/Scenario{scenarii[0]}_all_Energy_summary_stats.xlsx'\n",
    "df_init_col = pd.read_excel(init_df_path).columns\n",
    "df = pd.DataFrame(comp)\n",
    "df.columns = df_init_col\n",
    "df.rename(columns = {'Unnamed: 0':'Scenario'}, inplace=True)\n",
    "df['Scenario'] = scen_nm\n",
    "# Save to file\n",
    "write_path = f'{output_path}stats/Comparison Energy scenarii.xlsx'\n",
    "with pd.ExcelWriter(write_path, mode='w') as writer:  \n",
    "    df.to_excel(writer, sheet_name = f'Energy_out_Summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb1faa-a04d-4a73-a69c-d8759cc11cec",
   "metadata": {},
   "source": [
    "# Land statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df48e0ff-0b74-4567-86e2-89120c53d9bf",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f101a-8d06-4acf-ba35-a8d924afb404",
   "metadata": {},
   "source": [
    "### Landstats : UKCEH land cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5ffe487-4413-42f7-ae1b-c5dc7c5b1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run all desired land statistics on MCDM result\n",
    "# Needs to be run after energy_out as it requires 'Wind footprint (kmÂ²) (Denholm)' column\n",
    "# Created 23/02\n",
    "# Last edit 16/03 - separate summary\n",
    "def landstats(scenario_nr) :\n",
    "    start = time.perf_counter()\n",
    "   \n",
    "    ### SETUP ###\n",
    "    # Get gpkg paths list\n",
    "    print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - #### Landstats ####')\n",
    "    results_folder = f'{output_path}energy/'\n",
    "    filenames = os.listdir(results_folder)\n",
    "    scenar_str = f'Scenario{scenario_nr}_'\n",
    "    gdf_paths = [f'{results_folder}{_}' for _ in filenames if scenar_str in _] # Pick only files with specified scenario number\n",
    "    lc_path = f'{preppedDat_path}Land Cover/UKCEH_LC_2023_10m.tif'\n",
    "    \n",
    "    # UKCEH Land Use\n",
    "    # Get categories\n",
    "    categories_table = pd.read_excel(f'{preppedDat_path}Land Cover/UKCEH_LC_2023_10m_labels.xlsx')\n",
    "    category_map = dict(zip(categories_table.value,categories_table.label))\n",
    "    \n",
    "    ### PROCESSING ###\n",
    "    # Iterating across the various allsub results (all patches/patches above area threshold)\n",
    "    for i in gdf_paths:\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing {i}')\n",
    "        # Define write path for summary excel file\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        write_file = filename_noExt.replace('_Energy','')\n",
    "        sum_write_path = f'{output_path}stats/{write_file}_LandCover_Summary_stats.xlsx'\n",
    "        patch_write_path = f'{output_path}stats/{write_file}_LandCover_Patch_stats.xlsx'\n",
    "        \n",
    "        # Read file for selected allsub  result\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Reading gpkg {i}')\n",
    "        gdf = gpd.read_file(i)\n",
    "    \n",
    "        ### ZONAL STATS ###\n",
    "        # Zonal stats (returns result per patch)\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Running zonal_stats')\n",
    "        with rio.open(lc_path) as src:\n",
    "            raster =  src.read(1)\n",
    "            UKCEHLC_stats = zonal_stats(gdf['geometry'], raster, affine = src.transform, categorical = True, category_map = category_map, all_touched = False) # all_touched not an issue since the polygons have been generated from a raster at the exact same resolution\n",
    "        # Turn into a dataframe\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Turn to df')\n",
    "        UKCEH_stats_df = pd.DataFrame(UKCEHLC_stats)\n",
    "        # Merge with gdf\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Merge with gdf from gpkg')\n",
    "        UKCEH_stats_gdf = gdf.merge(UKCEH_stats_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "        # Calculate wind footprint\n",
    "        # for each of the LC columns, calculate _Wind version with % land covered by turbines applied\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Calculate wind footprint')\n",
    "        cols = UKCEH_stats_df.columns\n",
    "        for i in cols:\n",
    "            UKCEH_stats_gdf[f'{i}_Wind'] = UKCEH_stats_gdf[i]*(UKCEH_stats_gdf['Wind footprint (% of patch area) (Denholm)']/100) # Uses Denholm footprint\n",
    "        \n",
    "        # Write to file\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Write patch stats to excel file')\n",
    "        with pd.ExcelWriter(patch_write_path,\n",
    "                        mode='w') as writer:  \n",
    "            UKCEH_stats_gdf.to_excel(writer, sheet_name='UCKEH_LC_Footprint')\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Results written to file {patch_write_path}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Code block run in {elapsed_time_str}'\n",
    "    print(logproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe43af37-3720-456d-b974-686b82e16c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# created 16/03 from PAs summary\n",
    "def land_summary(scenario_nr):\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    ### Paths prep ###\n",
    "    # Get gpkg paths list\n",
    "    print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - #### Land Cover Summary ####')\n",
    "    results_folder = f'{output_path}energy/'\n",
    "    filenames = os.listdir(results_folder)\n",
    "    scenar_str = f'Scenario{scenario_nr}_'\n",
    "    gdf_paths = [f'{results_folder}{_}' for _ in filenames if scenar_str in _] # Pick only files with specified scenario number\n",
    "    # Get categories\n",
    "    categories_table = pd.read_excel(f'{preppedDat_path}Land Cover/UKCEH_LULC_10m_categories_stats.xlsx')\n",
    "    category_map = dict(zip(categories_table.value,categories_table.label))\n",
    "    \n",
    "    # Iterating across the various allsub results (all patches/patches above area threshold)\n",
    "    for i in gdf_paths:\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing {i}')\n",
    "        # Define write path for summary excel file\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        write_file = filename_noExt.replace('_Energy','')\n",
    "        sum_write_path = f'{output_path}stats/{write_file}_LandCover_Summary_stats.xlsx'\n",
    "        patch_write_path = f'{output_path}stats/{write_file}_LandCover_Patch_stats.xlsx'\n",
    "\n",
    "        # Read patch stats table\n",
    "        stats_gdf = pd.read_excel(patch_write_path, sheet_name='UCKEH_LC_Footprint')\n",
    "        # Get columns for summary\n",
    "        col_list = list(category_map.values())+[0] # Gets all categories + Column 0 which is added by zonal_stats()\n",
    "        cols = stats_gdf.columns.intersection(col_list) # Gets intersection of category labels and existing column labels                \n",
    "        \n",
    "        # Summary\n",
    "        # Creating df with area values for categories\n",
    "        area_df = categories_table[['label','km2']].set_index('label')\n",
    "        # Solar : footprint = 100% of the area\n",
    "        summary = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Solar'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        summary.rename(columns={0:'Solar Area (kmÂ²)'}, inplace=True)\n",
    "        summary = area_df.merge(summary, how = 'right', left_index=True, right_index=True) # Merge summary with category area info\n",
    "        summary['Solar Area (% of category area)'] = summary['Solar Area (kmÂ²)'] / summary['km2']*100\n",
    "        # Wind\n",
    "        # Wind area\n",
    "        win_area_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Wind'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        win_area_df.rename(columns={0:'Wind Area (kmÂ²)'}, inplace=True)\n",
    "        # Wind Footprint\n",
    "        cols_win = [str(_) + '_Wind' for _ in cols]\n",
    "        win_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Wind'][cols_win].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        win_df.rename(columns={0:'Wind Footprint (kmÂ²)'}, inplace=True)\n",
    "        win_df.index = win_df.index.str.replace('_Wind','') # remove suffixes from index to match summary index\n",
    "        win_df = win_area_df.merge(win_df, how='left', left_index=True, right_index=True) # Merge with wind area data\n",
    "        summary = summary.merge(win_df, how='left', left_index=True, right_index=True) # Merge with summary\n",
    "        summary['Wind Area (% of category area)'] = summary['Wind Area (kmÂ²)'] / summary['km2']*100\n",
    "        summary['Wind Footprint (% of category area)'] = summary['Wind Footprint (kmÂ²)'] / summary['km2']*100\n",
    "        # Overlap zones : footprint = 100% of the area\n",
    "        ol_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='SolarWind'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        ol_df.rename(columns={0:'Overlap Area (kmÂ²)'}, inplace=True)\n",
    "        summary = summary.merge(ol_df, how='left', left_index=True, right_index=True) # Merge\n",
    "        summary['Overlap Area (% of category area)'] = summary['Overlap Area (kmÂ²)'] / summary['km2']*100\n",
    "        # Total columns\n",
    "        area_df = pd.DataFrame((stats_gdf[cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        area_df.rename(columns={0:'Total Area (kmÂ²)(calc from patch stats)'}, inplace=True)\n",
    "        summary = summary.merge(area_df, how='left', left_index=True, right_index=True) # Merge\n",
    "        summary['Total Area (% of category area)'] = summary['Total Area (kmÂ²)(calc from patch stats)'] / summary['km2']*100\n",
    "        summary['Total footprint (kmÂ²)'] = summary['Solar Area (kmÂ²)']+summary['Wind Footprint (kmÂ²)']+summary['Overlap Area (kmÂ²)']\n",
    "        summary['Total footprint (% of category area)'] = summary['Total footprint (kmÂ²)'] / summary['km2']*100\n",
    "        \n",
    "        # Write to file\n",
    "        with pd.ExcelWriter(sum_write_path,\n",
    "                        mode='w') as writer:  \n",
    "            summary.to_excel(writer, sheet_name='PAs_Footprint')\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Results written to file {sum_write_path}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Code block run in {elapsed_time_str}'\n",
    "    print(logproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51396f8-b53c-4c05-ac61-02208a460f81",
   "metadata": {},
   "source": [
    "### Agristats : ALC footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1924f58b-242d-4bb6-825f-fbebb3a321d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be run after energy_out as it requires 'Wind footprint (kmÂ²) (Denholm)' column\n",
    "# Created 10/03\n",
    "# Last edit 16/03 - separating summary\n",
    "def agristats(scenario_nr) :\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    ### Paths prep ###\n",
    "    # Get gpkg paths list\n",
    "    print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - #### Agristats ####')\n",
    "    results_folder = f'{output_path}energy/'\n",
    "    filenames = os.listdir(results_folder)\n",
    "    scenar_str = f'Scenario{scenario_nr}_'\n",
    "    gdf_paths = [f'{results_folder}{_}' for _ in filenames if scenar_str in _] # Pick only files with specified scenario number\n",
    "    # Categorical raster\n",
    "    raster_path = f'{preppedDat_path}AgriGrades/UK_ALC_all_cat.tif'\n",
    "    # Get categories\n",
    "    categories_table = pd.read_excel(f'{preppedDat_path}AgriGrades/UK_ALC_labels.xlsx')\n",
    "    category_map = dict(zip(categories_table.value,categories_table.label))\n",
    "    \n",
    "    # Iterating across the various allsub results (all patches/patches above area threshold)\n",
    "    for i in gdf_paths:\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing {i}')\n",
    "        # Define write path for summary excel file\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        write_file = filename_noExt.replace('_Energy','')\n",
    "        sum_write_path = f'{output_path}stats/{write_file}_Agri_Summary_stats.xlsx'\n",
    "        patch_write_path = f'{output_path}stats/{write_file}_Agri_Patch_stats.xlsx'\n",
    "        \n",
    "        # Read file for selected allsub  result\n",
    "        gdf = gpd.read_file(i)\n",
    "    \n",
    "        ### ZONAL STATS ###\n",
    "        # Zonal stats (returns result per patch)\n",
    "        with rio.open(raster_path) as src:\n",
    "            raster =  src.read(1)\n",
    "            stats = zonal_stats(gdf['geometry'], raster, affine = src.transform, categorical = True, category_map = category_map, all_touched = False) \n",
    "            # all_touched not an issue since the polygons have been generated from a raster at the exact same resolution\n",
    "        # Turn into a dataframe\n",
    "        stats_df = pd.DataFrame(stats)\n",
    "        # Merge with gdf\n",
    "        stats_gdf = gdf.merge(stats_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "        # Calculate wind footprint\n",
    "        # for each of the LC columns, calculate _Wind version with % land covered by turbines applied\n",
    "        cols = stats_df.columns\n",
    "        for i in cols:\n",
    "            stats_gdf[f'{i}_Wind'] = stats_gdf[i]*(stats_gdf['Wind footprint (% of patch area) (Denholm)']/100) # Uses Denholm footprint\n",
    "        \n",
    "        # Write to file\n",
    "        with pd.ExcelWriter(patch_write_path,\n",
    "                        mode='w') as writer:  \n",
    "            stats_gdf.to_excel(writer, sheet_name='Agri_Footprint')\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Results written to file {patch_write_path}')\n",
    "        \n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Code block run in {elapsed_time_str}'\n",
    "    print(logproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c3a9dc5-4963-49ff-afe7-b6b8e5017d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# created 16/03 from PAs summary\n",
    "def agri_summary(scenario_nr):\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    ### Paths prep ###\n",
    "    # Get gpkg paths list\n",
    "    print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - #### ALC Summary ####')\n",
    "    results_folder = f'{output_path}energy/'\n",
    "    filenames = os.listdir(results_folder)\n",
    "    scenar_str = f'Scenario{scenario_nr}_'\n",
    "    gdf_paths = [f'{results_folder}{_}' for _ in filenames if scenar_str in _] # Pick only files with specified scenario number\n",
    "    # Get categories\n",
    "    categories_table = pd.read_excel(f'{preppedDat_path}AgriGrades/UK_ALC_all_cat_categories_stats.xlsx')\n",
    "    category_map = dict(zip(categories_table.value,categories_table.label))\n",
    "    \n",
    "    # Iterating across the various allsub results (all patches/patches above area threshold)\n",
    "    for i in gdf_paths:\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing {i}')\n",
    "        # Define write path for summary excel file\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        write_file = filename_noExt.replace('_Energy','')\n",
    "        sum_write_path = f'{output_path}stats/{write_file}_Agri_Summary_stats.xlsx'\n",
    "        patch_write_path = f'{output_path}stats/{write_file}_Agri_Patch_stats.xlsx'\n",
    "\n",
    "        # Read patch stats table\n",
    "        stats_gdf = pd.read_excel(patch_write_path, sheet_name='Agri_Footprint')\n",
    "        # Get columns for summary\n",
    "        col_list = list(category_map.values())+[0] # Gets all categories + Column 0 which is added by zonal_stats()\n",
    "        cols = stats_gdf.columns.intersection(col_list) # Gets intersection of category labels and existing column labels                \n",
    "        \n",
    "        # Summary\n",
    "        # Creating df with area values for categories\n",
    "        area_df = categories_table[['label','km2']].set_index('label')\n",
    "        # Solar : footprint = 100% of the area\n",
    "        summary = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Solar'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        summary.rename(columns={0:'Solar Area (kmÂ²)'}, inplace=True)\n",
    "        summary = area_df.merge(summary, how = 'right', left_index=True, right_index=True) # Merge summary with category area info\n",
    "        summary['Solar Area (% of category area)'] = summary['Solar Area (kmÂ²)'] / summary['km2']*100\n",
    "        # Wind\n",
    "        # Wind area\n",
    "        win_area_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Wind'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        win_area_df.rename(columns={0:'Wind Area (kmÂ²)'}, inplace=True)\n",
    "        # Wind Footprint\n",
    "        cols_win = [str(_) + '_Wind' for _ in cols]\n",
    "        win_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Wind'][cols_win].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        win_df.rename(columns={0:'Wind Footprint (kmÂ²)'}, inplace=True)\n",
    "        win_df.index = win_df.index.str.replace('_Wind','') # remove suffixes from index to match summary index\n",
    "        win_df = win_area_df.merge(win_df, how='left', left_index=True, right_index=True) # Merge with wind area data\n",
    "        summary = summary.merge(win_df, how='left', left_index=True, right_index=True) # Merge with summary\n",
    "        summary['Wind Area (% of category area)'] = summary['Wind Area (kmÂ²)'] / summary['km2']*100\n",
    "        summary['Wind Footprint (% of category area)'] = summary['Wind Footprint (kmÂ²)'] / summary['km2']*100\n",
    "        # Overlap zones : footprint = 100% of the area\n",
    "        ol_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='SolarWind'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        ol_df.rename(columns={0:'Overlap Area (kmÂ²)'}, inplace=True)\n",
    "        summary = summary.merge(ol_df, how='left', left_index=True, right_index=True) # Merge\n",
    "        summary['Overlap Area (% of category area)'] = summary['Overlap Area (kmÂ²)'] / summary['km2']*100\n",
    "        # Total columns\n",
    "        area_df = pd.DataFrame((stats_gdf[cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        area_df.rename(columns={0:'Total Area (kmÂ²)(calc from patch stats)'}, inplace=True)\n",
    "        summary = summary.merge(area_df, how='left', left_index=True, right_index=True) # Merge\n",
    "        summary['Total Area (% of category area)'] = summary['Total Area (kmÂ²)(calc from patch stats)'] / summary['km2']*100\n",
    "        summary['Total footprint (kmÂ²)'] = summary['Solar Area (kmÂ²)']+summary['Wind Footprint (kmÂ²)']+summary['Overlap Area (kmÂ²)']\n",
    "        summary['Total footprint (% of category area)'] = summary['Total footprint (kmÂ²)'] / summary['km2']*100\n",
    "        \n",
    "        # Write to file\n",
    "        with pd.ExcelWriter(sum_write_path,\n",
    "                        mode='w') as writer:  \n",
    "            summary.to_excel(writer, sheet_name='PAs_Footprint')\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Results written to file {sum_write_path}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Code block run in {elapsed_time_str}'\n",
    "    print(logproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b206e7-0b15-4074-9274-c191cb7c74eb",
   "metadata": {},
   "source": [
    "### Peatstats : Peatland footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "321b4386-5247-42da-8c42-97896de53d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be run after energy_out as it requires 'Wind footprint (kmÂ²) (Denholm)' column\n",
    "# Created 10/03\n",
    "# last edit 16/03 - separate summary creation\n",
    "def peatstats(scenario_nr) :\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    ### Paths prep ###\n",
    "    # Get gpkg paths list\n",
    "    print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - #### Peatstats ####')\n",
    "    results_folder = f'{output_path}energy/'\n",
    "    filenames = os.listdir(results_folder)\n",
    "    scenar_str = f'Scenario{scenario_nr}_'\n",
    "    gdf_paths = [f'{results_folder}{_}' for _ in filenames if scenar_str in _] # Pick only files with specified scenario number\n",
    "    # Categorical raster\n",
    "    raster_path = f'{preppedDat_path}Peatland/Peatland_all_Lvl.tif'\n",
    "    # Get categories\n",
    "    categories_table = pd.read_excel(f'{preppedDat_path}Peatland/Peatland_labels.xlsx')\n",
    "    category_map = dict(zip(categories_table.value,categories_table.label))\n",
    "    \n",
    "    # Iterating across the various allsub results (all patches/patches above area threshold)\n",
    "    for i in gdf_paths:\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing {i}')\n",
    "        # Define write path for summary excel file\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        write_file = filename_noExt.replace('_Energy','')\n",
    "        sum_write_path = f'{output_path}stats/{write_file}_Peat_Summary_stats.xlsx'\n",
    "        patch_write_path = f'{output_path}stats/{write_file}_Peat_Patch_stats.xlsx'\n",
    "        \n",
    "        # Read file for selected allsub  result\n",
    "        gdf = gpd.read_file(i)\n",
    "    \n",
    "        ### ZONAL STATS ###\n",
    "        # Zonal stats (returns result per patch)\n",
    "        with rio.open(raster_path) as src:\n",
    "            raster =  src.read(1)\n",
    "            stats = zonal_stats(gdf['geometry'], raster, affine = src.transform, categorical = True, category_map = category_map, all_touched = False) \n",
    "            # all_touched not an issue since the polygons have been generated from a raster at the exact same resolution\n",
    "        # Turn into a dataframe\n",
    "        stats_df = pd.DataFrame(stats)\n",
    "        # Merge with gdf\n",
    "        stats_gdf = gdf.merge(stats_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "        # Calculate wind footprint\n",
    "        # for each of the LC columns, calculate _Wind version with % land covered by turbines applied\n",
    "        cols = stats_df.columns\n",
    "        for i in cols:\n",
    "            stats_gdf[f'{i}_Wind'] = stats_gdf[i]*(stats_gdf['Wind footprint (% of patch area) (Denholm)']/100) # Uses Denholm footprint\n",
    "        \n",
    "        # Write to file\n",
    "        with pd.ExcelWriter(patch_write_path,\n",
    "                        mode='w') as writer:  \n",
    "            stats_gdf.to_excel(writer, sheet_name='Peatland_Footprint')\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Results written to file {patch_write_path}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Code block run in {elapsed_time_str}'\n",
    "    print(logproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b9180d-7a6a-4f2b-8b86-bc6f5125e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# created 16/03 from PAs summary\n",
    "def peat_summary(scenario_nr):\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    ### Paths prep ###\n",
    "    # Get gpkg paths list\n",
    "    print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - #### Peatland Summary ####')\n",
    "    results_folder = f'{output_path}energy/'\n",
    "    filenames = os.listdir(results_folder)\n",
    "    scenar_str = f'Scenario{scenario_nr}_'\n",
    "    gdf_paths = [f'{results_folder}{_}' for _ in filenames if scenar_str in _] # Pick only files with specified scenario number\n",
    "    # Get categories\n",
    "    categories_table = pd.read_excel(f'{preppedDat_path}Peatland/Peatland_categories_stats.xlsx')\n",
    "    category_map = dict(zip(categories_table.value,categories_table.label))\n",
    "    \n",
    "    # Iterating across the various allsub results (all patches/patches above area threshold)\n",
    "    for i in gdf_paths:\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing {i}')\n",
    "        # Define write path for summary excel file\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        write_file = filename_noExt.replace('_Energy','')\n",
    "        sum_write_path = f'{output_path}stats/{write_file}_Peat_Summary_stats.xlsx'\n",
    "        patch_write_path = f'{output_path}stats/{write_file}_Peat_Patch_stats.xlsx'\n",
    "\n",
    "        # Read patch stats table\n",
    "        stats_gdf = pd.read_excel(patch_write_path, sheet_name='Peatland_Footprint')\n",
    "        # Get columns for summary\n",
    "        col_list = list(category_map.values())+[0] # Gets all categories + Column 0 which is added by zonal_stats()\n",
    "        cols = stats_gdf.columns.intersection(col_list) # Gets intersection of category labels and existing column labels                \n",
    "        \n",
    "        # Summary\n",
    "        # Creating df with area values for categories\n",
    "        area_df = categories_table[['label','km2']].set_index('label')\n",
    "        # Solar : footprint = 100% of the area\n",
    "        summary = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Solar'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        summary.rename(columns={0:'Solar Area (kmÂ²)'}, inplace=True)\n",
    "        summary = area_df.merge(summary, how = 'right', left_index=True, right_index=True) # Merge summary with category area info\n",
    "        summary['Solar Area (% of category area)'] = summary['Solar Area (kmÂ²)'] / summary['km2']*100\n",
    "        # Wind\n",
    "        # Wind area\n",
    "        win_area_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Wind'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        win_area_df.rename(columns={0:'Wind Area (kmÂ²)'}, inplace=True)\n",
    "        # Wind Footprint\n",
    "        cols_win = [str(_) + '_Wind' for _ in cols]\n",
    "        win_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Wind'][cols_win].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        win_df.rename(columns={0:'Wind Footprint (kmÂ²)'}, inplace=True)\n",
    "        win_df.index = win_df.index.str.replace('_Wind','') # remove suffixes from index to match summary index\n",
    "        win_df = win_area_df.merge(win_df, how='left', left_index=True, right_index=True) # Merge with wind area data\n",
    "        summary = summary.merge(win_df, how='left', left_index=True, right_index=True) # Merge with summary\n",
    "        summary['Wind Area (% of category area)'] = summary['Wind Area (kmÂ²)'] / summary['km2']*100\n",
    "        summary['Wind Footprint (% of category area)'] = summary['Wind Footprint (kmÂ²)'] / summary['km2']*100\n",
    "        # Overlap zones : footprint = 100% of the area\n",
    "        ol_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='SolarWind'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        ol_df.rename(columns={0:'Overlap Area (kmÂ²)'}, inplace=True)\n",
    "        summary = summary.merge(ol_df, how='left', left_index=True, right_index=True) # Merge\n",
    "        summary['Overlap Area (% of category area)'] = summary['Overlap Area (kmÂ²)'] / summary['km2']*100\n",
    "        # Total columns\n",
    "        area_df = pd.DataFrame((stats_gdf[cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        area_df.rename(columns={0:'Total Area (kmÂ²)(calc from patch stats)'}, inplace=True)\n",
    "        summary = summary.merge(area_df, how='left', left_index=True, right_index=True) # Merge\n",
    "        summary['Total Area (% of category area)'] = summary['Total Area (kmÂ²)(calc from patch stats)'] / summary['km2']*100\n",
    "        summary['Total footprint (kmÂ²)'] = summary['Solar Area (kmÂ²)']+summary['Wind Footprint (kmÂ²)']+summary['Overlap Area (kmÂ²)']\n",
    "        summary['Total footprint (% of category area)'] = summary['Total footprint (kmÂ²)'] / summary['km2']*100\n",
    "        \n",
    "        # Write to file\n",
    "        with pd.ExcelWriter(sum_write_path,\n",
    "                        mode='w') as writer:  \n",
    "            summary.to_excel(writer, sheet_name='PAs_Footprint')\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Results written to file {sum_write_path}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Code block run in {elapsed_time_str}'\n",
    "    print(logproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7109ac34-935b-4b4a-a84d-aac66e16b35f",
   "metadata": {},
   "source": [
    "### PAstats : Protected Areas footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3eda3b1-28ed-4b5c-8c1c-6a3d3192fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be run after energy_out as it requires 'Wind footprint (kmÂ²) (Denholm)' column\n",
    "# Created 14/03\n",
    "def PAstats(scenario_nr) :\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    ### Paths prep ###\n",
    "    # Get gpkg paths list\n",
    "    print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - #### PAstats ####')\n",
    "    results_folder = f'{output_path}energy/'\n",
    "    filenames = os.listdir(results_folder)\n",
    "    scenar_str = f'Scenario{scenario_nr}_'\n",
    "    gdf_paths = [f'{results_folder}{_}' for _ in filenames if scenar_str in _] # Pick only files with specified scenario number\n",
    "    # Categorical raster\n",
    "    raster_path = f'{preppedDat_path}PAs/UNEP-WCMC_Protected_Areas_2024_merged_categorized.tif'\n",
    "    # Get categories\n",
    "    categories_table = pd.read_excel(f'{preppedDat_path}PAs/PAs_labels.xlsx')\n",
    "    category_map = dict(zip(categories_table.value,categories_table.label))\n",
    "    \n",
    "    # Iterating across the various allsub results (all patches/patches above area threshold)\n",
    "    for i in gdf_paths:\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing {i}')\n",
    "        # Define write path for summary excel file\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        write_file = filename_noExt.replace('_Energy','')\n",
    "        patch_write_path = f'{output_path}stats/{write_file}_PAs_Patch_stats.xlsx'\n",
    "        \n",
    "        # Read file for selected allsub  result\n",
    "        gdf = gpd.read_file(i)\n",
    "    \n",
    "        ### ZONAL STATS ###\n",
    "        # Zonal stats (returns result per patch)\n",
    "        with rio.open(raster_path) as src:\n",
    "            raster =  src.read(1)\n",
    "            stats = zonal_stats(gdf['geometry'], raster, affine = src.transform, categorical = True, category_map = category_map, all_touched = False) \n",
    "            # all_touched not an issue since the polygons have been generated from a raster at the exact same resolution\n",
    "        # Turn into a dataframe\n",
    "        stats_df = pd.DataFrame(stats)\n",
    "        # Merge with gdf\n",
    "        stats_gdf = gdf.merge(stats_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "        # Calculate wind footprint\n",
    "        # for each of the LC columns, calculate _Wind version with % land covered by turbines applied\n",
    "        cols = stats_df.columns\n",
    "        for i in cols:\n",
    "            stats_gdf[f'{i}_Wind'] = stats_gdf[i]*(stats_gdf['Wind footprint (% of patch area) (Denholm)']/100) # Uses Denholm footprint\n",
    "        \n",
    "        # Write to file\n",
    "        with pd.ExcelWriter(patch_write_path,\n",
    "                        mode='w') as writer:  \n",
    "            stats_gdf.to_excel(writer, sheet_name='PAs_Footprint')\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Results written to file {patch_write_path}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Code block run in {elapsed_time_str}'\n",
    "    print(logproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9da3d3e-81b8-4c88-b051-ffa6afb0989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created 15/03\n",
    "# Last edit 16/03 - remove raster_path as not needed here\n",
    "def PA_summary(scenario_nr):\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    ### Paths prep ###\n",
    "    # Get gpkg paths list\n",
    "    print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - #### PAs Summary ####')\n",
    "    results_folder = f'{output_path}energy/'\n",
    "    filenames = os.listdir(results_folder)\n",
    "    scenar_str = f'Scenario{scenario_nr}_'\n",
    "    gdf_paths = [f'{results_folder}{_}' for _ in filenames if scenar_str in _] # Pick only files with specified scenario number\n",
    "    # Get categories\n",
    "    categories_table = pd.read_excel(f'{preppedDat_path}PAs/UNEP-WCMC_Protected_Areas_2024_categories_stats.xlsx')\n",
    "    category_map = dict(zip(categories_table.value,categories_table.label))\n",
    "    \n",
    "    # Iterating across the various allsub results (all patches/patches above area threshold)\n",
    "    for i in gdf_paths:\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing {i}')\n",
    "        # Define write path for summary excel file\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        write_file = filename_noExt.replace('_Energy','')\n",
    "        sum_write_path = f'{output_path}stats/{write_file}_PAs_Summary_stats.xlsx'\n",
    "        patch_write_path = f'{output_path}stats/{write_file}_PAs_Patch_stats.xlsx'\n",
    "\n",
    "        # Read patch stats table\n",
    "        stats_gdf = pd.read_excel(patch_write_path, sheet_name='PAs_Footprint')\n",
    "        # Get columns for summary\n",
    "        col_list = list(category_map.values())+[0] # Gets all categories + Column 0 which is added by zonal_stats()\n",
    "        cols = stats_gdf.columns.intersection(col_list) # Gets intersection of category labels and existing column labels                \n",
    "        \n",
    "        # Summary\n",
    "        # Creating df with area values for categories\n",
    "        area_df = categories_table[['label','km2']].set_index('label')\n",
    "        # Solar : footprint = 100% of the area\n",
    "        summary = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Solar'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        summary.rename(columns={0:'Solar Area (kmÂ²)'}, inplace=True)\n",
    "        summary = area_df.merge(summary, how = 'right', left_index=True, right_index=True) # Merge summary with category area info\n",
    "        summary['Solar Area (% of category area)'] = summary['Solar Area (kmÂ²)'] / summary['km2']*100\n",
    "        # Wind\n",
    "        # Wind area\n",
    "        win_area_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Wind'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        win_area_df.rename(columns={0:'Wind Area (kmÂ²)'}, inplace=True)\n",
    "        # Wind Footprint\n",
    "        cols_win = [str(_) + '_Wind' for _ in cols]\n",
    "        win_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='Wind'][cols_win].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        win_df.rename(columns={0:'Wind Footprint (kmÂ²)'}, inplace=True)\n",
    "        win_df.index = win_df.index.str.replace('_Wind','') # remove suffixes from index to match summary index\n",
    "        win_df = win_area_df.merge(win_df, how='left', left_index=True, right_index=True) # Merge with wind area data\n",
    "        summary = summary.merge(win_df, how='left', left_index=True, right_index=True) # Merge with summary\n",
    "        summary['Wind Area (% of category area)'] = summary['Wind Area (kmÂ²)'] / summary['km2']*100\n",
    "        summary['Wind Footprint (% of category area)'] = summary['Wind Footprint (kmÂ²)'] / summary['km2']*100\n",
    "        # Overlap zones : footprint = 100% of the area\n",
    "        ol_df = pd.DataFrame((stats_gdf.loc[stats_gdf['RE_type']=='SolarWind'][cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        ol_df.rename(columns={0:'Overlap Area (kmÂ²)'}, inplace=True)\n",
    "        summary = summary.merge(ol_df, how='left', left_index=True, right_index=True) # Merge\n",
    "        summary['Overlap Area (% of category area)'] = summary['Overlap Area (kmÂ²)'] / summary['km2']*100\n",
    "        # Total columns\n",
    "        area_df = pd.DataFrame((stats_gdf[cols].sum()*100/1e6).sort_values(ascending=False)) # *100 pixels to mÂ², /1e6 for conversion to km2\n",
    "        area_df.rename(columns={0:'Total Area (kmÂ²)(calc from patch stats)'}, inplace=True)\n",
    "        summary = summary.merge(area_df, how='left', left_index=True, right_index=True) # Merge\n",
    "        summary['Total Area (% of category area)'] = summary['Total Area (kmÂ²)(calc from patch stats)'] / summary['km2']*100\n",
    "        summary['Total footprint (kmÂ²)'] = summary['Solar Area (kmÂ²)']+summary['Wind Footprint (kmÂ²)']+summary['Overlap Area (kmÂ²)']\n",
    "        summary['Total footprint (% of category area)'] = summary['Total footprint (kmÂ²)'] / summary['km2']*100\n",
    "        \n",
    "        # Write to file\n",
    "        with pd.ExcelWriter(sum_write_path,\n",
    "                        mode='w') as writer:  \n",
    "            summary.to_excel(writer, sheet_name='PAs_Footprint')\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Results written to file {sum_write_path}')\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Code block run in {elapsed_time_str}'\n",
    "    print(logproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf34be-f616-4e49-ab1a-e2f14c795b82",
   "metadata": {},
   "source": [
    "## Run functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0bb113-89e1-42ca-bfd8-c58e2c11b507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-21 14:14:55 - #### Landstats ####\n",
      "2025-03-21 14:14:55 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_all_Energy.gpkg\n",
      "2025-03-21 14:14:55 - Reading gpkg C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_all_Energy.gpkg\n",
      "2025-03-21 14:30:04 - Running zonal_stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roro_\\miniconda3\\envs\\sds2024_IGS\\Lib\\site-packages\\rasterstats\\io.py:335: NodataWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-21 14:55:25 - Turn to df\n",
      "2025-03-21 14:55:27 - Merge with gdf from gpkg\n",
      "2025-03-21 14:55:30 - Calculate wind footprint\n",
      "2025-03-21 14:55:31 - Write patch stats to excel file\n",
      "2025-03-21 15:57:51 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_all_LandCover_Patch_stats.xlsx\n",
      "2025-03-21 15:57:51 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_area_threshold_Energy.gpkg\n",
      "2025-03-21 15:57:51 - Reading gpkg C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_area_threshold_Energy.gpkg\n",
      "2025-03-21 16:03:53 - Running zonal_stats\n",
      "2025-03-21 16:16:25 - Turn to df\n",
      "2025-03-21 16:16:26 - Merge with gdf from gpkg\n",
      "2025-03-21 16:17:03 - Calculate wind footprint\n",
      "2025-03-21 16:17:03 - Write patch stats to excel file\n",
      "2025-03-21 16:35:37 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_area_threshold_LandCover_Patch_stats.xlsx\n",
      "2025-03-21 16:35:37 - Code block run in 2:20:41.854397\n",
      "\n",
      "2025-03-21 16:35:40 - #### Agristats ####\n",
      "2025-03-21 16:35:40 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_all_Energy.gpkg\n",
      "2025-03-21 17:47:36 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_all_Agri_Patch_stats.xlsx\n",
      "2025-03-21 17:47:36 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_area_threshold_Energy.gpkg\n",
      "2025-03-21 18:16:44 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_area_threshold_Agri_Patch_stats.xlsx\n",
      "2025-03-21 18:16:44 - Code block run in 1:41:03.888434\n",
      "\n",
      "2025-03-21 18:16:47 - #### Peatstats ####\n",
      "2025-03-21 18:16:47 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_all_Energy.gpkg\n",
      "2025-03-21 19:31:13 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_all_Peat_Patch_stats.xlsx\n",
      "2025-03-21 19:31:13 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_area_threshold_Energy.gpkg\n",
      "2025-03-21 20:01:47 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_area_threshold_Peat_Patch_stats.xlsx\n",
      "2025-03-21 20:01:47 - Code block run in 1:45:00.656498\n",
      "\n",
      "2025-03-21 20:01:54 - #### PAstats ####\n",
      "2025-03-21 20:01:55 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_all_Energy.gpkg\n",
      "2025-03-21 21:05:03 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_all_PAs_Patch_stats.xlsx\n",
      "2025-03-21 21:05:03 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_area_threshold_Energy.gpkg\n",
      "2025-03-21 21:28:09 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_area_threshold_PAs_Patch_stats.xlsx\n",
      "2025-03-21 21:28:09 - Code block run in 1:26:11.970483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11909161"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarii = [8]\n",
    "for i in scenarii:\n",
    "    landstats(i)\n",
    "    print('')\n",
    "    agristats(i)\n",
    "    print('')\n",
    "    peatstats(i)\n",
    "    print('')\n",
    "    PAstats(i)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0087ddc6-6c1f-40fa-b06c-ea57c76e2019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-21 21:28:16 - #### Land Cover Summary ####\n",
      "2025-03-21 21:28:17 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_all_Energy.gpkg\n",
      "2025-03-21 21:41:37 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_all_LandCover_Summary_stats.xlsx\n",
      "2025-03-21 21:41:37 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_area_threshold_Energy.gpkg\n",
      "2025-03-21 21:44:45 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_area_threshold_LandCover_Summary_stats.xlsx\n",
      "2025-03-21 21:44:45 - Code block run in 0:16:28.960452\n",
      "\n",
      "2025-03-21 21:44:46 - #### ALC Summary ####\n",
      "2025-03-21 21:44:46 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_all_Energy.gpkg\n",
      "2025-03-21 21:54:30 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_all_Agri_Summary_stats.xlsx\n",
      "2025-03-21 21:54:30 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_area_threshold_Energy.gpkg\n",
      "2025-03-21 21:56:48 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_area_threshold_Agri_Summary_stats.xlsx\n",
      "2025-03-21 21:56:48 - Code block run in 0:12:01.750383\n",
      "\n",
      "2025-03-21 21:56:48 - #### Peatland Summary ####\n",
      "2025-03-21 21:56:48 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_all_Energy.gpkg\n",
      "2025-03-21 22:05:49 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_all_Peat_Summary_stats.xlsx\n",
      "2025-03-21 22:05:49 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_area_threshold_Energy.gpkg\n",
      "2025-03-21 22:08:03 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_area_threshold_Peat_Summary_stats.xlsx\n",
      "2025-03-21 22:08:03 - Code block run in 0:11:15.179295\n",
      "\n",
      "2025-03-21 22:08:04 - #### PAs Summary ####\n",
      "2025-03-21 22:08:04 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_all_Energy.gpkg\n",
      "2025-03-21 22:17:24 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_all_PAs_Summary_stats.xlsx\n",
      "2025-03-21 22:17:24 - Processing C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/energy/Scenario8_area_threshold_Energy.gpkg\n",
      "2025-03-21 22:19:38 - Results written to file C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/stats/Scenario8_area_threshold_PAs_Summary_stats.xlsx\n",
      "2025-03-21 22:19:38 - Code block run in 0:11:34.412038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scenarii = [8]\n",
    "for i in scenarii:\n",
    "    land_summary(i)\n",
    "    print('')\n",
    "    agri_summary(i)\n",
    "    print('')\n",
    "    peat_summary(i)\n",
    "    print('')\n",
    "    PA_summary(i)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01cf968-a733-4b0b-8232-a831e5ad784a",
   "metadata": {},
   "source": [
    "## Merge summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dedcb3f1-b0f1-4943-9dfb-3520ccfe2e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Agri\n",
      "Processing Peat\n",
      "Processing PAs\n",
      "Processing LandCover\n"
     ]
    }
   ],
   "source": [
    "cat = ['Agri', 'Peat', 'PAs', 'LandCover'] # Category to merge summaries for\n",
    "scenarii_nr = [1,2,3,5,6,7,8] # Scenarii to merge\n",
    "\n",
    "for c in cat:\n",
    "    # inital df\n",
    "    print(f'Processing {c}')\n",
    "    df1 = pd.read_excel(f'{output_path}stats/Scenario{scenarii_nr[0]}_all_{c}_Summary_stats.xlsx')\n",
    "    df1t = pd.read_excel(f'{output_path}stats/Scenario{scenarii_nr[0]}_area_threshold_{c}_Summary_stats.xlsx')\n",
    "    df1.set_index('Unnamed: 0', inplace=True) # Set zonal stats categories as index\n",
    "    df1t.set_index('Unnamed: 0', inplace=True)\n",
    "    #df1.loc['Scenario'] = f'S{scenarii_nr[0]}'\n",
    "    #df1t.loc['Scenario'] = f'S{scenarii_nr[0]} thr'\n",
    "    df1.columns = [f'S1_{_}' for _ in df1.columns] # Add prefix to columns\n",
    "    df1t.columns = [f'S1_thr_{_}' for _ in df1t.columns]\n",
    "    df_m = df1.merge(df1t, how = 'outer', left_index= True, right_index= True)\n",
    "    for i in scenarii_nr[1:]:\n",
    "        df = pd.read_excel(f'{output_path}stats/Scenario{i}_all_{c}_Summary_stats.xlsx')\n",
    "        dft = pd.read_excel(f'{output_path}stats/Scenario{i}_area_threshold_{c}_Summary_stats.xlsx')\n",
    "        df.set_index('Unnamed: 0', inplace=True) # Set zonal stats categories as index\n",
    "        dft.set_index('Unnamed: 0', inplace=True)\n",
    "        #df.loc['Scenario'] = f'S{i}'\n",
    "        #dft.loc['Scenario'] = f'S{i} thr'\n",
    "        df.columns = [f'S{i}_{_}' for _ in df.columns] # Add prefix to columns\n",
    "        dft.columns = [f'S{i}_thr_{_}' for _ in dft.columns]\n",
    "        df_m_S = df.merge(dft, how = 'outer', left_index= True, right_index= True)\n",
    "        df_m = df_m.merge(df_m_S, how = 'outer', left_index= True, right_index= True)\n",
    "    \n",
    "    write_path = f'{output_path}stats/Comparison {c} stats.xlsx'\n",
    "    with pd.ExcelWriter(write_path,\n",
    "                mode='w') as writer:  \n",
    "        df_m.to_excel(writer, sheet_name= c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f1c08-ba01-4294-b97b-87d96fad4a24",
   "metadata": {},
   "source": [
    "# Zonal stats for existing RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91a604e-e157-455d-a4f6-fbff059ab6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agri zones Ã existing RE\n",
    "## SETUP##\n",
    "raster_path = f'{preppedDat_path}AgriGrades/UK_ALC_all_cat.tif'\n",
    "categories_table = pd.read_excel(f'{preppedDat_path}AgriGrades/UK_ALC_labels.xlsx')\n",
    "category_map = dict(zip(categories_table.value,categories_table.label))\n",
    "write_path = f'{preppedDat_path}Agrigrades/UK_ALC_cat_ExistingRE.csv'\n",
    "####\n",
    "\n",
    "# Solar\n",
    "sol_geom_path = f'{preppedDat_path}Existing RE/global_solar_2020_poly_cropped.gpkg'\n",
    "sol_gdf = gpd.read_file(sol_geom_path)\n",
    "sol_gdf = sol_gdf.to_crs('EPSG:27700') #reproject\n",
    "sol_geom = sol_gdf['geometry']\n",
    "\n",
    "with rio.open(raster_path) as src:\n",
    "    raster =  src.read(1)\n",
    "    sol_stats = zonal_stats(sol_geom, raster, affine = src.transform, categorical = True, category_map = category_map, all_touched = False, nodata=src.nodata)\n",
    "# Turn into a df\n",
    "sol_stats_df = pd.DataFrame(sol_stats, index = sol_gdf.index)\n",
    "# Summary\n",
    "sum_df = pd.DataFrame(sol_stats_df.count(), columns = ['Existing Solar sites (count)'])\n",
    "\n",
    "# Wind\n",
    "win_geom_path = f'{preppedDat_path}Existing RE/global_wind_2020_point_cropped.gpkg'\n",
    "win_gdf = gpd.read_file(win_geom_path)\n",
    "win_gdf = win_gdf.to_crs('EPSG:27700') #reproject\n",
    "win_geom = win_gdf['geometry']\n",
    "\n",
    "with rio.open(raster_path) as src:\n",
    "    raster =  src.read(1)\n",
    "    win_stats = zonal_stats(win_geom, raster, affine = src.transform, categorical = True, category_map = category_map, all_touched = False, nodata=src.nodata)\n",
    "# Turn into a df\n",
    "win_stats_df = pd.DataFrame(win_stats, index = win_gdf.index)\n",
    "# Summary\n",
    "win_sum_df = pd.DataFrame(win_stats_df.count(), columns = ['Existing Wind sites (count)'])\n",
    "sum_df = sum_df.merge(win_sum_df, how = 'outer', left_index= True, right_index= True)\n",
    "sum_df['% of Solar sites'] = sum_df['Existing Solar sites (count)']/len(sol_gdf)*100\n",
    "sum_df['% of Wind sites'] = sum_df['Existing Wind sites (count)']/len(win_gdf)*100\n",
    "\n",
    "# Save\n",
    "sum_df.to_csv(write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ba0c33-54c0-4f2d-81f2-6ec2bb587b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peatland zones Ã existing RE\n",
    "## SETUP##\n",
    "raster_path = f'{preppedDat_path}Peatland/Peatland_all_Lvl.tif'\n",
    "categories_table = pd.read_excel(f'{preppedDat_path}Peatland/Peatland_labels.xlsx')\n",
    "category_map = dict(zip(categories_table.value,categories_table.label))\n",
    "write_path = f'{preppedDat_path}Peatland/Peatland_all_Lvl_ExistingRE.csv'\n",
    "####\n",
    "\n",
    "# Solar\n",
    "sol_geom_path = f'{preppedDat_path}Existing RE/global_solar_2020_poly_cropped.gpkg'\n",
    "sol_gdf = gpd.read_file(sol_geom_path)\n",
    "sol_gdf = sol_gdf.to_crs('EPSG:27700') #reproject\n",
    "sol_geom = sol_gdf['geometry']\n",
    "\n",
    "with rio.open(raster_path) as src:\n",
    "    raster =  src.read(1)\n",
    "    sol_stats = zonal_stats(sol_geom, raster, affine = src.transform, categorical = True, category_map = category_map, all_touched = False, nodata=src.nodata)\n",
    "# Turn into a df\n",
    "sol_stats_df = pd.DataFrame(sol_stats, index = sol_gdf.index)\n",
    "# Summary\n",
    "sum_df = pd.DataFrame(sol_stats_df.count(), columns = ['Existing Solar sites (count)'])\n",
    "\n",
    "# Wind\n",
    "win_geom_path = f'{preppedDat_path}Existing RE/global_wind_2020_point_cropped.gpkg'\n",
    "win_gdf = gpd.read_file(win_geom_path)\n",
    "win_gdf = win_gdf.to_crs('EPSG:27700') #reproject\n",
    "win_geom = win_gdf['geometry']\n",
    "\n",
    "with rio.open(raster_path) as src:\n",
    "    raster =  src.read(1)\n",
    "    win_stats = zonal_stats(win_geom, raster, affine = src.transform, categorical = True, category_map = category_map, all_touched = False, nodata=src.nodata)\n",
    "# Turn into a df\n",
    "win_stats_df = pd.DataFrame(win_stats, index = win_gdf.index)\n",
    "# Summary\n",
    "win_sum_df = pd.DataFrame(win_stats_df.count(), columns = ['Existing Wind sites (count)'])\n",
    "sum_df = sum_df.merge(win_sum_df, how = 'outer', left_index= True, right_index= True)\n",
    "sum_df['% of Solar sites'] = sum_df['Existing Solar sites (count)']/len(sol_gdf)*100\n",
    "sum_df['% of Wind sites'] = sum_df['Existing Wind sites (count)']/len(win_gdf)*100\n",
    "\n",
    "# Save\n",
    "sum_df.to_csv(write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e7d3be7-6a12-46e2-9513-1698030a8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAs zones Ã existing RE\n",
    "## SETUP##\n",
    "raster_path = f'{preppedDat_path}PAs/UNEP-WCMC_Protected_Areas_2024_merged_categorized.tif'\n",
    "categories_table = pd.read_excel(f'{preppedDat_path}PAs/PAs_labels.xlsx')\n",
    "category_map = dict(zip(categories_table.value,categories_table.label))\n",
    "write_path = f'{preppedDat_path}PAs/UNEP-WCMC_Protected_Areas_2024_merged_categorized_ExistingRE.csv'\n",
    "####\n",
    "\n",
    "# Solar\n",
    "sol_geom_path = f'{preppedDat_path}Existing RE/global_solar_2020_poly_cropped.gpkg'\n",
    "sol_gdf = gpd.read_file(sol_geom_path)\n",
    "sol_gdf = sol_gdf.to_crs('EPSG:27700') #reproject\n",
    "sol_geom = sol_gdf['geometry']\n",
    "\n",
    "with rio.open(raster_path) as src:\n",
    "    raster =  src.read(1)\n",
    "    sol_stats = zonal_stats(sol_geom, raster, affine = src.transform, categorical = True, category_map = category_map, all_touched = False, nodata=src.nodata)\n",
    "# Turn into a df\n",
    "sol_stats_df = pd.DataFrame(sol_stats, index = sol_gdf.index)\n",
    "# Summary\n",
    "sum_df = pd.DataFrame(sol_stats_df.count(), columns = ['Existing Solar sites (count)'])\n",
    "\n",
    "# Wind\n",
    "win_geom_path = f'{preppedDat_path}Existing RE/global_wind_2020_point_cropped.gpkg'\n",
    "win_gdf = gpd.read_file(win_geom_path)\n",
    "win_gdf = win_gdf.to_crs('EPSG:27700') #reproject\n",
    "win_geom = win_gdf['geometry']\n",
    "\n",
    "with rio.open(raster_path) as src:\n",
    "    raster =  src.read(1)\n",
    "    win_stats = zonal_stats(win_geom, raster, affine = src.transform, categorical = True, category_map = category_map, all_touched = False, nodata=src.nodata)\n",
    "# Turn into a df\n",
    "win_stats_df = pd.DataFrame(win_stats, index = win_gdf.index)\n",
    "# Summary\n",
    "win_sum_df = pd.DataFrame(win_stats_df.count(), columns = ['Existing Wind sites (count)'])\n",
    "sum_df = sum_df.merge(win_sum_df, how = 'outer', left_index= True, right_index= True)\n",
    "sum_df['% of Solar sites'] = sum_df['Existing Solar sites (count)']/len(sol_gdf)*100\n",
    "sum_df['% of Wind sites'] = sum_df['Existing Wind sites (count)']/len(win_gdf)*100\n",
    "\n",
    "# Save\n",
    "sum_df.to_csv(write_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "485cacff-9980-43dc-b897-883a43e8db6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2154"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sol_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c77b80a5-2a11-4240-869b-8041a0e8ff3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(win_gdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
