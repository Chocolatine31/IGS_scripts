{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e4a3a03-d22b-4624-9010-a77ee2e296ea",
   "metadata": {},
   "source": [
    "# 1. Setup  \n",
    "## 1.1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eff7ac6-1f8c-479e-b24e-897ca39641bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# Diagnostic & memory management\n",
    "import time # for performance checks\n",
    "import datetime # for log\n",
    "from datetime import timedelta\n",
    "import psutil # for memory checks\n",
    "from psutil._common import bytes2human\n",
    "import winsound # for sound notification when script over\n",
    "import sys\n",
    "import gc # garbage collector - clean up memory\n",
    "\n",
    "# Data processing\n",
    "import re #  for handling of regular expressions in string replacement\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import shapely                 #needed to set geopandas geometry \n",
    "from shapely.wkt import loads  #needed to set geopandas geometry\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon # Test test geometry type in layer processing\n",
    "\n",
    "import rasterio as rio # for rasters\n",
    "import rasterio.mask\n",
    "from rasterio import features\n",
    "import numpy as np\n",
    "import geofileops as gfo # Package added to sds2024 environment for faster processing of large vector files\n",
    "from scipy.ndimage import binary_dilation # For raster buffers\n",
    "import dask.array as da # Package added to sds2024 environment for chunking and parallel processing of large files\n",
    "\n",
    "from rasterio.features import shapes # for vectorization of rasters\n",
    "from shapely.geometry import shape # for vectorization of rasters\n",
    "\n",
    "# Graphics\n",
    "import folium  \n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "\n",
    "#import warnings\n",
    "#warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8371f9-1a9f-4aa7-baac-f84ac9878711",
   "metadata": {},
   "source": [
    "## 1.2. Data paths and parameters variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4171e8-0858-4f31-9858-059cb5f0e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Paths\n",
    "preppedDat_path = 'C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/'\n",
    "rawDat_path = 'C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/raw/'\n",
    "output_path = 'C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/'\n",
    "interimFiles_path = 'C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c220aaf-8622-4542-aad3-0e721e1ecf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "AOI_path = preppedDat_path+'Study_area_basedOn_UK_BFC_EPSG27700.gpkg' # Study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c3eb2c3-1ce8-419e-be69-968ac02c9c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resource</th>\n",
       "      <th>Class</th>\n",
       "      <th>S1 Buffer (m)</th>\n",
       "      <th>S2 Buffer (m)</th>\n",
       "      <th>S3 Buffer (m)</th>\n",
       "      <th>S4 Buffer (m)</th>\n",
       "      <th>S5 Buffer (m)</th>\n",
       "      <th>S1 inc/exc</th>\n",
       "      <th>S2 inc/exc</th>\n",
       "      <th>S3 inc/exc</th>\n",
       "      <th>...</th>\n",
       "      <th>S2 Threshold</th>\n",
       "      <th>S3 Threshold</th>\n",
       "      <th>S4 Threshold</th>\n",
       "      <th>S5 Threshold</th>\n",
       "      <th>Prepped Path</th>\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>filename_noExt</th>\n",
       "      <th>ext</th>\n",
       "      <th>subtraction order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Coastline</td>\n",
       "      <td>-50</td>\n",
       "      <td>-50</td>\n",
       "      <td>-50</td>\n",
       "      <td>-50</td>\n",
       "      <td>-50</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Study_area_basedOn_UK_BFC_EPSG27700.tif</td>\n",
       "      <td>Study_area_basedOn_UK_BFC_EPSG27700</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Coastline</td>\n",
       "      <td>-50</td>\n",
       "      <td>-50</td>\n",
       "      <td>-50</td>\n",
       "      <td>-50</td>\n",
       "      <td>-50</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Study_area_basedOn_UK_BFC_EPSG27700.tif</td>\n",
       "      <td>Study_area_basedOn_UK_BFC_EPSG27700</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Transportation Network</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>OS_open_roads_lines.tif</td>\n",
       "      <td>OS_open_roads_lines</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Transportation Network</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>OS_open_roads_lines.tif</td>\n",
       "      <td>OS_open_roads_lines</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Water and rivers</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Water_rivers_merged.tif</td>\n",
       "      <td>Water_rivers_merged</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Water and rivers</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Water_rivers_merged.tif</td>\n",
       "      <td>Water_rivers_merged</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Existing Solar</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>global_solar_2020_merged.tif</td>\n",
       "      <td>global_solar_2020_merged</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Existing Solar</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>global_solar_2020_merged.tif</td>\n",
       "      <td>global_solar_2020_merged</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Existing Wind</td>\n",
       "      <td>945</td>\n",
       "      <td>945</td>\n",
       "      <td>945</td>\n",
       "      <td>945</td>\n",
       "      <td>945</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>global_wind_2020_point_cropped.tif</td>\n",
       "      <td>global_wind_2020_point_cropped</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Existing Wind</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>global_wind_2020_point_cropped.tif</td>\n",
       "      <td>global_wind_2020_point_cropped</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Agricultural grade 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UK_ALC_cat1.tif</td>\n",
       "      <td>UK_ALC_cat1</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Agricultural grade 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UK_ALC_cat1.tif</td>\n",
       "      <td>UK_ALC_cat1</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Agricultural grade 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UK_ALC_cat2.tif</td>\n",
       "      <td>UK_ALC_cat2</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Agricultural grade 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UK_ALC_cat2.tif</td>\n",
       "      <td>UK_ALC_cat2</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Airports</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>hotosm_gbr_airports_points.tif</td>\n",
       "      <td>hotosm_gbr_airports_points</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Airports</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>hotosm_gbr_airports_points.tif</td>\n",
       "      <td>hotosm_gbr_airports_points</td>\n",
       "      <td>.tif</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Urban areas</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UKCEH_10m_urban.tif</td>\n",
       "      <td>UKCEH_10m_urban</td>\n",
       "      <td>.tif</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Urban areas</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UKCEH_10m_urban.tif</td>\n",
       "      <td>UKCEH_10m_urban</td>\n",
       "      <td>.tif</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Urban areas over 2 ha</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UKCEH_10m_urban_2ha.tif</td>\n",
       "      <td>UKCEH_10m_urban_2ha</td>\n",
       "      <td>.tif</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Battlefields &amp; World Heritage Sites</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Heritage_WHS_Battlefields.tif</td>\n",
       "      <td>Heritage_WHS_Battlefields</td>\n",
       "      <td>.tif</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Battlefields &amp; World Heritage Sites</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Heritage_WHS_Battlefields.tif</td>\n",
       "      <td>Heritage_WHS_Battlefields</td>\n",
       "      <td>.tif</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Monuments</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Heritage_Monuments.tif</td>\n",
       "      <td>Heritage_Monuments</td>\n",
       "      <td>.tif</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Monuments</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Heritage_Monuments.tif</td>\n",
       "      <td>Heritage_Monuments</td>\n",
       "      <td>.tif</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Parks &amp; gardens</td>\n",
       "      <td>2000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Heritage_Parks_Gardens.tif</td>\n",
       "      <td>Heritage_Parks_Gardens</td>\n",
       "      <td>.tif</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Parks &amp; gardens</td>\n",
       "      <td>2000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Heritage_Parks_Gardens.tif</td>\n",
       "      <td>Heritage_Parks_Gardens</td>\n",
       "      <td>.tif</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Listed Buildings</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Heritage_Listed_Buildings_merged.tif</td>\n",
       "      <td>Heritage_Listed_Buildings_merged</td>\n",
       "      <td>.tif</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Listed Buildings</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Heritage_Listed_Buildings_merged.tif</td>\n",
       "      <td>Heritage_Listed_Buildings_merged</td>\n",
       "      <td>.tif</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Ramsar &amp; SPA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>JNCC_Ramsar_SPA.tif</td>\n",
       "      <td>JNCC_Ramsar_SPA</td>\n",
       "      <td>.tif</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Ramsar &amp; SPA</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>JNCC_Ramsar_SPA.tif</td>\n",
       "      <td>JNCC_Ramsar_SPA</td>\n",
       "      <td>.tif</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Wind Turbines Spatial Framework (Scotland)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>inc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Wind_Turbine_Spatial_Framework_(Scot)_Cat1.tif</td>\n",
       "      <td>Wind_Turbine_Spatial_Framework_(Scot)_Cat1</td>\n",
       "      <td>.tif</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Woodland</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UKCEH_10m_woodland.tif</td>\n",
       "      <td>UKCEH_10m_woodland</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Woodland</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UKCEH_10m_woodland.tif</td>\n",
       "      <td>UKCEH_10m_woodland</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Peatland - Primary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>inc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Peatland_Lvl1_merged.tif</td>\n",
       "      <td>Peatland_Lvl1_merged</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Peatland - Primary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Peatland_Lvl1_merged.tif</td>\n",
       "      <td>Peatland_Lvl1_merged</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Peatland - Secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Peatland_Lvl2_merged.tif</td>\n",
       "      <td>Peatland_Lvl2_merged</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Peatland - Secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Peatland_Lvl2_merged.tif</td>\n",
       "      <td>Peatland_Lvl2_merged</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Agricultural grade 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UK_ALC_cat3.tif</td>\n",
       "      <td>UK_ALC_cat3</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Agricultural grade 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UK_ALC_cat3.tif</td>\n",
       "      <td>UK_ALC_cat3</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Protected Areas - Cat 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat1.tif</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat1</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Protected Areas - Cat 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat1.tif</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat1</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Protected Areas - Cat 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat2.tif</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat2</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Protected Areas - Cat 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat2.tif</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat2</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Protected Areas - Cat 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat3.tif</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat3</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Protected Areas - Cat 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat3.tif</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat3</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Protected Areas - Cat 4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>inc</td>\n",
       "      <td>inc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat4.tif</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat4</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Protected Areas - Cat 4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>inc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat4.tif</td>\n",
       "      <td>UNEP-WCMC_Protected_Areas_2024_merged_cat4</td>\n",
       "      <td>.tif</td>\n",
       "      <td>5.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Slope</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>571.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>OS Terrain 10m slope bicubic deflate float32 s...</td>\n",
       "      <td>OS Terrain 10m slope bicubic deflate float32 s...</td>\n",
       "      <td>.tif</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Slope</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>OS Terrain 10m slope bicubic deflate float32 s...</td>\n",
       "      <td>OS Terrain 10m slope bicubic deflate float32 s...</td>\n",
       "      <td>.tif</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Substations</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7000</td>\n",
       "      <td>7000</td>\n",
       "      <td>7000</td>\n",
       "      <td>exc</td>\n",
       "      <td>inc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>substations_Lovett2022.tif</td>\n",
       "      <td>substations_Lovett2022</td>\n",
       "      <td>.tif</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Substations</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7000</td>\n",
       "      <td>7000</td>\n",
       "      <td>7000</td>\n",
       "      <td>exc</td>\n",
       "      <td>inc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>substations_Lovett2022.tif</td>\n",
       "      <td>substations_Lovett2022</td>\n",
       "      <td>.tif</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Solar Resource</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>865.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Solar-GHI_extent.tif</td>\n",
       "      <td>Solar-GHI_extent</td>\n",
       "      <td>.tif</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Wind Resource</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>C:/Users/roro_/Documents/University/UG year 3/...</td>\n",
       "      <td>raster</td>\n",
       "      <td>Wind-speed_50m_extent.tif</td>\n",
       "      <td>Wind-speed_50m_extent</td>\n",
       "      <td>.tif</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Solar</td>\n",
       "      <td>Small areas</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from results</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Wind</td>\n",
       "      <td>Small areas</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>exc</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from results</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Resource                                       Class  S1 Buffer (m)  \\\n",
       "0     Solar                                   Coastline            -50   \n",
       "1      Wind                                   Coastline            -50   \n",
       "2      Wind                      Transportation Network            200   \n",
       "3     Solar                      Transportation Network            200   \n",
       "4      Wind                            Water and rivers             10   \n",
       "5     Solar                            Water and rivers             10   \n",
       "6      Wind                              Existing Solar             45   \n",
       "7     Solar                              Existing Solar             10   \n",
       "8      Wind                               Existing Wind            945   \n",
       "9     Solar                               Existing Wind             45   \n",
       "10    Solar                        Agricultural grade 1              0   \n",
       "11     Wind                        Agricultural grade 1              0   \n",
       "12    Solar                        Agricultural grade 2              0   \n",
       "13     Wind                        Agricultural grade 2              0   \n",
       "14     Wind                                    Airports           2000   \n",
       "15    Solar                                    Airports            100   \n",
       "16    Solar                                 Urban areas             10   \n",
       "17     Wind                                 Urban areas           1500   \n",
       "18     Wind                       Urban areas over 2 ha           1500   \n",
       "19     Wind         Battlefields & World Heritage Sites              0   \n",
       "20    Solar         Battlefields & World Heritage Sites              0   \n",
       "21     Wind                                   Monuments            500   \n",
       "22    Solar                                   Monuments            500   \n",
       "23     Wind                             Parks & gardens           2000   \n",
       "24    Solar                             Parks & gardens           2000   \n",
       "25    Solar                            Listed Buildings           1000   \n",
       "26     Wind                            Listed Buildings           1000   \n",
       "27    Solar                                Ramsar & SPA              0   \n",
       "28     Wind                                Ramsar & SPA           2000   \n",
       "29     Wind  Wind Turbines Spatial Framework (Scotland)              0   \n",
       "30    Solar                                    Woodland              0   \n",
       "31     Wind                                    Woodland             50   \n",
       "32     Wind                         Peatland - Primary               0   \n",
       "33    Solar                         Peatland - Primary               0   \n",
       "34    Solar                        Peatland - Secondary              0   \n",
       "35     Wind                        Peatland - Secondary              0   \n",
       "36     Wind                        Agricultural grade 3              0   \n",
       "37    Solar                        Agricultural grade 3              0   \n",
       "38    Solar                     Protected Areas - Cat 1              0   \n",
       "39     Wind                     Protected Areas - Cat 1              0   \n",
       "40    Solar                     Protected Areas - Cat 2              0   \n",
       "41     Wind                     Protected Areas - Cat 2              0   \n",
       "42    Solar                     Protected Areas - Cat 3              0   \n",
       "43     Wind                     Protected Areas - Cat 3              0   \n",
       "44     Wind                     Protected Areas - Cat 4              0   \n",
       "45    Solar                     Protected Areas - Cat 4              0   \n",
       "46    Solar                                       Slope              0   \n",
       "47     Wind                                       Slope              0   \n",
       "48     Wind                                 Substations           5000   \n",
       "49    Solar                                 Substations           5000   \n",
       "50    Solar                              Solar Resource              0   \n",
       "51     Wind                               Wind Resource              0   \n",
       "52    Solar                                 Small areas           <NA>   \n",
       "53     Wind                                 Small areas           <NA>   \n",
       "\n",
       "    S2 Buffer (m)  S3 Buffer (m)  S4 Buffer (m)  S5 Buffer (m) S1 inc/exc  \\\n",
       "0             -50            -50            -50            -50        exc   \n",
       "1             -50            -50            -50            -50        exc   \n",
       "2             200             20             10             20        exc   \n",
       "3              20             20             10             20        exc   \n",
       "4              10             10             10             10        exc   \n",
       "5              10             10             10             10        exc   \n",
       "6              45             45             45             45        exc   \n",
       "7              10             10             10             10        exc   \n",
       "8             945            945            945            945        exc   \n",
       "9              45             45             45             45        exc   \n",
       "10              0              0              0              0        exc   \n",
       "11              0              0              0              0        exc   \n",
       "12              0              0              0              0        exc   \n",
       "13              0              0              0              0        exc   \n",
       "14           2000           2000           2000           2000        exc   \n",
       "15            100            100            100            100        exc   \n",
       "16             10             10             10             10        exc   \n",
       "17           1000           1000           1000           1000        exc   \n",
       "18           1000           1000           1000           1000        inc   \n",
       "19              0              0              0              0        exc   \n",
       "20              0              0              0              0        exc   \n",
       "21            500            500            500            500        exc   \n",
       "22            500            500            500            500        exc   \n",
       "23           1000           1000            500           1000        exc   \n",
       "24           1000           1000           2000           2000        exc   \n",
       "25            500            500            500            500        exc   \n",
       "26            500            500            500            500        exc   \n",
       "27              0              0              0              0        exc   \n",
       "28           2000           2000           2000           2000        exc   \n",
       "29              0              0              0              0        exc   \n",
       "30              0              0              0              0        exc   \n",
       "31             50             50             50             50        exc   \n",
       "32              0              0              0              0        exc   \n",
       "33              0              0              0              0        exc   \n",
       "34              0              0              0              0        exc   \n",
       "35              0              0              0              0        exc   \n",
       "36              0              0              0              0        exc   \n",
       "37              0              0              0              0        exc   \n",
       "38              0              0              0              0        exc   \n",
       "39              0              0              0              0        exc   \n",
       "40              0              0              0              0        exc   \n",
       "41              0              0              0              0        exc   \n",
       "42              0              0              0              0        exc   \n",
       "43              0              0              0              0        exc   \n",
       "44              0              0              0              0        exc   \n",
       "45              0              0              0              0        exc   \n",
       "46              0              0              0              0        exc   \n",
       "47              0              0              0              0        exc   \n",
       "48           <NA>           7000           7000           7000        exc   \n",
       "49           <NA>           7000           7000           7000        exc   \n",
       "50              0              0              0              0        exc   \n",
       "51              0              0              0              0        exc   \n",
       "52           <NA>           <NA>           <NA>           <NA>        exc   \n",
       "53           <NA>           <NA>           <NA>           <NA>        exc   \n",
       "\n",
       "   S2 inc/exc S3 inc/exc  ... S2 Threshold S3 Threshold  S4 Threshold  \\\n",
       "0         exc        exc  ...          NaN          NaN           NaN   \n",
       "1         exc        exc  ...          NaN          NaN           NaN   \n",
       "2         exc        exc  ...          NaN          NaN           NaN   \n",
       "3         exc        exc  ...          NaN          NaN           NaN   \n",
       "4         exc        exc  ...          NaN          NaN           NaN   \n",
       "5         exc        exc  ...          NaN          NaN           NaN   \n",
       "6         exc        exc  ...          NaN          NaN           NaN   \n",
       "7         exc        exc  ...          NaN          NaN           NaN   \n",
       "8         exc        exc  ...          NaN          NaN           NaN   \n",
       "9         exc        exc  ...          NaN          NaN           NaN   \n",
       "10        exc        exc  ...          NaN          NaN           NaN   \n",
       "11        exc        exc  ...          NaN          NaN           NaN   \n",
       "12        exc        exc  ...          NaN          NaN           NaN   \n",
       "13        exc        exc  ...          NaN          NaN           NaN   \n",
       "14        exc        exc  ...          NaN          NaN           NaN   \n",
       "15        exc        exc  ...          NaN          NaN           NaN   \n",
       "16        exc        exc  ...          NaN          NaN           NaN   \n",
       "17        exc        exc  ...          NaN          NaN           NaN   \n",
       "18        inc        inc  ...          NaN          NaN           NaN   \n",
       "19          0        exc  ...          NaN          NaN           NaN   \n",
       "20        exc        exc  ...          NaN          NaN           NaN   \n",
       "21        exc        exc  ...          NaN          NaN           NaN   \n",
       "22        exc        exc  ...          NaN          NaN           NaN   \n",
       "23        exc        exc  ...          NaN          NaN           NaN   \n",
       "24        exc        exc  ...          NaN          NaN           NaN   \n",
       "25        exc        exc  ...          NaN          NaN           NaN   \n",
       "26        exc        exc  ...          NaN          NaN           NaN   \n",
       "27        exc        exc  ...          NaN          NaN           NaN   \n",
       "28        exc        exc  ...          NaN          NaN           NaN   \n",
       "29        inc        exc  ...          NaN          NaN           NaN   \n",
       "30        exc        exc  ...          NaN          NaN           NaN   \n",
       "31        exc        exc  ...          NaN          NaN           NaN   \n",
       "32        inc        exc  ...          NaN          NaN           NaN   \n",
       "33        exc        exc  ...          NaN          NaN           NaN   \n",
       "34        inc        inc  ...          NaN          NaN           NaN   \n",
       "35        inc        inc  ...          NaN          NaN           NaN   \n",
       "36        inc        inc  ...          NaN          NaN           NaN   \n",
       "37        inc        inc  ...          NaN          NaN           NaN   \n",
       "38        exc        exc  ...          NaN          NaN           NaN   \n",
       "39        exc        exc  ...          NaN          NaN           NaN   \n",
       "40        exc        exc  ...          NaN          NaN           NaN   \n",
       "41        exc        exc  ...          NaN          NaN           NaN   \n",
       "42        exc        exc  ...          NaN          NaN           NaN   \n",
       "43        exc        exc  ...          NaN          NaN           NaN   \n",
       "44        inc        inc  ...          NaN          NaN           NaN   \n",
       "45        inc        exc  ...          NaN          NaN           NaN   \n",
       "46        exc        exc  ...        571.0        571.0         571.0   \n",
       "47        exc        exc  ...       1131.0       1131.0        1131.0   \n",
       "48        inc        exc  ...          NaN          NaN           NaN   \n",
       "49        inc        exc  ...          NaN          NaN           NaN   \n",
       "50        exc        exc  ...        865.0        865.0         900.0   \n",
       "51        exc        exc  ...          5.0          5.0           5.0   \n",
       "52        exc        exc  ...      10000.0      10000.0       10000.0   \n",
       "53        exc        exc  ...      50000.0      20000.0       20000.0   \n",
       "\n",
       "    S5 Threshold                                       Prepped Path  \\\n",
       "0            NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "1            NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "2            NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "3            NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "4            NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "5            NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "6            NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "7            NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "8            NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "9            NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "10           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "11           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "12           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "13           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "14           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "15           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "16           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "17           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "18           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "19           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "20           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "21           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "22           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "23           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "24           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "25           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "26           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "27           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "28           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "29           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "30           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "31           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "32           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "33           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "34           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "35           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "36           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "37           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "38           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "39           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "40           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "41           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "42           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "43           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "44           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "45           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "46         571.0  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "47        1131.0  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "48           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "49           NaN  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "50         960.0  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "51           5.0  C:/Users/roro_/Documents/University/UG year 3/...   \n",
       "52       10000.0                                                NaN   \n",
       "53       20000.0                                                NaN   \n",
       "\n",
       "            type                                           filename  \\\n",
       "0         raster            Study_area_basedOn_UK_BFC_EPSG27700.tif   \n",
       "1         raster            Study_area_basedOn_UK_BFC_EPSG27700.tif   \n",
       "2         raster                            OS_open_roads_lines.tif   \n",
       "3         raster                            OS_open_roads_lines.tif   \n",
       "4         raster                            Water_rivers_merged.tif   \n",
       "5         raster                            Water_rivers_merged.tif   \n",
       "6         raster                       global_solar_2020_merged.tif   \n",
       "7         raster                       global_solar_2020_merged.tif   \n",
       "8         raster                 global_wind_2020_point_cropped.tif   \n",
       "9         raster                 global_wind_2020_point_cropped.tif   \n",
       "10        raster                                    UK_ALC_cat1.tif   \n",
       "11        raster                                    UK_ALC_cat1.tif   \n",
       "12        raster                                    UK_ALC_cat2.tif   \n",
       "13        raster                                    UK_ALC_cat2.tif   \n",
       "14        raster                     hotosm_gbr_airports_points.tif   \n",
       "15        raster                     hotosm_gbr_airports_points.tif   \n",
       "16        raster                                UKCEH_10m_urban.tif   \n",
       "17        raster                                UKCEH_10m_urban.tif   \n",
       "18        raster                            UKCEH_10m_urban_2ha.tif   \n",
       "19        raster                      Heritage_WHS_Battlefields.tif   \n",
       "20        raster                      Heritage_WHS_Battlefields.tif   \n",
       "21        raster                             Heritage_Monuments.tif   \n",
       "22        raster                             Heritage_Monuments.tif   \n",
       "23        raster                         Heritage_Parks_Gardens.tif   \n",
       "24        raster                         Heritage_Parks_Gardens.tif   \n",
       "25        raster               Heritage_Listed_Buildings_merged.tif   \n",
       "26        raster               Heritage_Listed_Buildings_merged.tif   \n",
       "27        raster                                JNCC_Ramsar_SPA.tif   \n",
       "28        raster                                JNCC_Ramsar_SPA.tif   \n",
       "29        raster     Wind_Turbine_Spatial_Framework_(Scot)_Cat1.tif   \n",
       "30        raster                             UKCEH_10m_woodland.tif   \n",
       "31        raster                             UKCEH_10m_woodland.tif   \n",
       "32        raster                           Peatland_Lvl1_merged.tif   \n",
       "33        raster                           Peatland_Lvl1_merged.tif   \n",
       "34        raster                           Peatland_Lvl2_merged.tif   \n",
       "35        raster                           Peatland_Lvl2_merged.tif   \n",
       "36        raster                                    UK_ALC_cat3.tif   \n",
       "37        raster                                    UK_ALC_cat3.tif   \n",
       "38        raster     UNEP-WCMC_Protected_Areas_2024_merged_cat1.tif   \n",
       "39        raster     UNEP-WCMC_Protected_Areas_2024_merged_cat1.tif   \n",
       "40        raster     UNEP-WCMC_Protected_Areas_2024_merged_cat2.tif   \n",
       "41        raster     UNEP-WCMC_Protected_Areas_2024_merged_cat2.tif   \n",
       "42        raster     UNEP-WCMC_Protected_Areas_2024_merged_cat3.tif   \n",
       "43        raster     UNEP-WCMC_Protected_Areas_2024_merged_cat3.tif   \n",
       "44        raster     UNEP-WCMC_Protected_Areas_2024_merged_cat4.tif   \n",
       "45        raster     UNEP-WCMC_Protected_Areas_2024_merged_cat4.tif   \n",
       "46        raster  OS Terrain 10m slope bicubic deflate float32 s...   \n",
       "47        raster  OS Terrain 10m slope bicubic deflate float32 s...   \n",
       "48        raster                         substations_Lovett2022.tif   \n",
       "49        raster                         substations_Lovett2022.tif   \n",
       "50        raster                               Solar-GHI_extent.tif   \n",
       "51        raster                          Wind-speed_50m_extent.tif   \n",
       "52  from results                                                NaN   \n",
       "53  from results                                                NaN   \n",
       "\n",
       "                                       filename_noExt   ext subtraction order  \n",
       "0                 Study_area_basedOn_UK_BFC_EPSG27700  .tif              1.00  \n",
       "1                 Study_area_basedOn_UK_BFC_EPSG27700  .tif              1.00  \n",
       "2                                 OS_open_roads_lines  .tif              1.01  \n",
       "3                                 OS_open_roads_lines  .tif              1.01  \n",
       "4                                 Water_rivers_merged  .tif              1.05  \n",
       "5                                 Water_rivers_merged  .tif              1.05  \n",
       "6                            global_solar_2020_merged  .tif              1.20  \n",
       "7                            global_solar_2020_merged  .tif              1.20  \n",
       "8                      global_wind_2020_point_cropped  .tif              1.40  \n",
       "9                      global_wind_2020_point_cropped  .tif              1.40  \n",
       "10                                        UK_ALC_cat1  .tif              1.60  \n",
       "11                                        UK_ALC_cat1  .tif              1.60  \n",
       "12                                        UK_ALC_cat2  .tif              1.70  \n",
       "13                                        UK_ALC_cat2  .tif              1.70  \n",
       "14                         hotosm_gbr_airports_points  .tif              1.80  \n",
       "15                         hotosm_gbr_airports_points  .tif              1.80  \n",
       "16                                    UKCEH_10m_urban  .tif              2.00  \n",
       "17                                    UKCEH_10m_urban  .tif              2.00  \n",
       "18                                UKCEH_10m_urban_2ha  .tif              2.10  \n",
       "19                          Heritage_WHS_Battlefields  .tif              3.00  \n",
       "20                          Heritage_WHS_Battlefields  .tif              3.00  \n",
       "21                                 Heritage_Monuments  .tif              3.10  \n",
       "22                                 Heritage_Monuments  .tif              3.10  \n",
       "23                             Heritage_Parks_Gardens  .tif              3.20  \n",
       "24                             Heritage_Parks_Gardens  .tif              3.20  \n",
       "25                   Heritage_Listed_Buildings_merged  .tif              3.30  \n",
       "26                   Heritage_Listed_Buildings_merged  .tif              3.30  \n",
       "27                                    JNCC_Ramsar_SPA  .tif              4.00  \n",
       "28                                    JNCC_Ramsar_SPA  .tif              4.00  \n",
       "29         Wind_Turbine_Spatial_Framework_(Scot)_Cat1  .tif              4.10  \n",
       "30                                 UKCEH_10m_woodland  .tif              5.00  \n",
       "31                                 UKCEH_10m_woodland  .tif              5.00  \n",
       "32                               Peatland_Lvl1_merged  .tif              5.10  \n",
       "33                               Peatland_Lvl1_merged  .tif              5.10  \n",
       "34                               Peatland_Lvl2_merged  .tif              5.15  \n",
       "35                               Peatland_Lvl2_merged  .tif              5.15  \n",
       "36                                        UK_ALC_cat3  .tif              5.23  \n",
       "37                                        UK_ALC_cat3  .tif              5.23  \n",
       "38         UNEP-WCMC_Protected_Areas_2024_merged_cat1  .tif              5.41  \n",
       "39         UNEP-WCMC_Protected_Areas_2024_merged_cat1  .tif              5.41  \n",
       "40         UNEP-WCMC_Protected_Areas_2024_merged_cat2  .tif              5.42  \n",
       "41         UNEP-WCMC_Protected_Areas_2024_merged_cat2  .tif              5.42  \n",
       "42         UNEP-WCMC_Protected_Areas_2024_merged_cat3  .tif              5.43  \n",
       "43         UNEP-WCMC_Protected_Areas_2024_merged_cat3  .tif              5.43  \n",
       "44         UNEP-WCMC_Protected_Areas_2024_merged_cat4  .tif              5.44  \n",
       "45         UNEP-WCMC_Protected_Areas_2024_merged_cat4  .tif              5.44  \n",
       "46  OS Terrain 10m slope bicubic deflate float32 s...  .tif              7.40  \n",
       "47  OS Terrain 10m slope bicubic deflate float32 s...  .tif              7.40  \n",
       "48                             substations_Lovett2022  .tif              7.50  \n",
       "49                             substations_Lovett2022  .tif              7.50  \n",
       "50                                   Solar-GHI_extent  .tif              7.80  \n",
       "51                              Wind-speed_50m_extent  .tif              7.80  \n",
       "52                                                NaN   NaN               NaN  \n",
       "53                                                NaN   NaN               NaN  \n",
       "\n",
       "[54 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting implantation factors from table\n",
    "# last edit 24/02/2025\n",
    "factors_df = pd.read_excel('C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/work files/IGS_Tables.xlsx', sheet_name = 'Suitability factors')\n",
    "# Add filename columns to factors_df\n",
    "for i in factors_df['Prepped Path']:\n",
    "    if pd.isnull(i):\n",
    "        continue # ignore rows with no input layer path\n",
    "    else:\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        ext = os.path.splitext(filename)[1]\n",
    "        factors_df.loc[factors_df['Prepped Path']==i,'filename'] = filename\n",
    "        factors_df.loc[factors_df['Prepped Path']==i,'filename_noExt'] = filename_noExt\n",
    "        factors_df.loc[factors_df['Prepped Path']==i,'ext'] = ext\n",
    "buffer_columns = [col for col in factors_df.columns if 'Buffer' in col]\n",
    "factors_df[buffer_columns] = factors_df[buffer_columns].astype('Int64') # using int64 cause the other int don't deal with NaN values\n",
    "inc_exc_columns = [col for col in factors_df.columns if 'inc/exc' in col]\n",
    "threshold_columns = [col for col in factors_df.columns if 'Threshold' in col]\n",
    "# Creating simpler df\n",
    "simple_cols = ['Resource','Class']+ buffer_columns + inc_exc_columns + threshold_columns + ['Prepped Path','type', 'filename', 'filename_noExt','ext', 'subtraction order']\n",
    "fac_df = factors_df[simple_cols].dropna(subset=['Prepped Path']).sort_values(by = 'subtraction order') #dropping all rows with no input path, reordering\n",
    "small_areas = factors_df[simple_cols].loc[factors_df['Class']=='Small areas'] # recovering small areas threshold rows\n",
    "fac_df = pd.concat([fac_df, small_areas], ignore_index= True)\n",
    "fac_df.reset_index(inplace=True)\n",
    "fac_df.drop(columns='index', inplace=True)\n",
    "fac_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c4dec9-3f66-4f68-b531-580a9afed908",
   "metadata": {},
   "source": [
    "## 1.3. Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5d175-c5e5-4fe8-9d01-8d0676c9f863",
   "metadata": {},
   "source": [
    "#### Memory usage check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04ef053-e764-46e4-8e3d-3ba65bd4092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM memory % used:69.3 --- 11.0G      ||      Swap memory used 18.2% --- 1.3G\n",
      "Memory use: [('factors_df', 84379), ('fac_df', 49694), ('small_areas', 1359), ('MultiPolygon', 936), ('Point', 936), ('Polygon', 936), ('timedelta', 432), ('simple_cols', 240), ('AOI_path', 189), ('i', 174)]\n"
     ]
    }
   ],
   "source": [
    "## Check memory usage\n",
    "logram = f'RAM memory % used:{psutil.virtual_memory()[2]} --- {bytes2human(psutil.virtual_memory()[3])}      ||      Swap memory used {psutil.swap_memory().percent}% --- {bytes2human(psutil.swap_memory().used)}'\n",
    "## Code from:\n",
    "## https://stackoverflow.com/questions/40993626/list-memory-usage-in-ipython-and-jupyter\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "logvar = f'Memory use: {sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:10]}'\n",
    "logall = f'{logram}\\n{logvar}'\n",
    "print(logall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c05d57a-7f3d-4f7b-82aa-ffb278b64b20",
   "metadata": {},
   "source": [
    "# 2. Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b03c97-5e2a-4f60-b574-cea791133a8a",
   "metadata": {},
   "source": [
    "## 2.1. Buffering  \n",
    "Buffering processes *=all layers for all scenarii**. If a file with the correct buffer size exists, the layer is skipped from processing.\n",
    "### 2.1.1. Polygons\n",
    "#### 2.1.1.1. Define functions (bufdis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cfc03fc-d403-4665-8c6a-41c1b2a96bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24/01 Buffer+dissolve 4.0: make output filename non-scenario or RE specific to easily reuse across when parameters are equal.  Output to bufids folder.\n",
    "# 23/01 Buffer + dissolve v3.0 (in Tests 0.06): splitting overly complex geometries to allow dissolve, checking for existing files to re-run only if overwrite = True, adding prefix for SOL/WIN, wrapping in function, adding a case for buf == 0\n",
    "\n",
    "# Internal function, to be iterated over for each layer inside bigger function\n",
    "# (24/01/2025)\n",
    "\n",
    "def bufdis_internal(paths_iteration, bufs_iteration, filename , filename_noExt, overwrite, logpath):\n",
    "    # Read layer\n",
    "    layer = gpd.read_file(paths_iteration)\n",
    "    # Check CRS & reproject if needed\n",
    "    if layer.crs=='EPSG:27700': # Testing CRS\n",
    "        logcrs = f'{filename} CRS is EPSG:27700   ---   {datetime.datetime.now()}\\n'\n",
    "        print(logcrs[:-2])\n",
    "    else:\n",
    "        layer = layer.to_crs('EPSG:27700') # Reprojecting if wrong\n",
    "        logcrs = f'{filename} CRS has been reprojected.   ---   {datetime.datetime.now()}\\n'\n",
    "        print(logcrs[:-2])\n",
    "    \n",
    "    # Apply buffer to geometry if buf != 0\n",
    "    if bufs_iteration == 0:\n",
    "        layer_b = layer['geometry']\n",
    "    elif bufs_iteration != 0 :\n",
    "        res = 2 if bufs_iteration < 300 else (3 if bufs_iteration<1000 else (4 if bufs_iteration<5000 else 5)) # Adaptive buffer resolution to reduce file size & speed up processing\n",
    "        layer_b = layer['geometry'].buffer(bufs_iteration, resolution = res)\n",
    "    logbuf = f'Buffer complete    ---   {datetime.datetime.now()}\\n Buffer value: {bufs_iteration}.\\n'\n",
    "    print(logbuf[:-2])\n",
    "    \n",
    "    #Clear variable to free up memory\n",
    "    del[layer]\n",
    "    \n",
    "    # Function to convert geometries to Multipolygon\n",
    "    def to_multipolygon(geom):\n",
    "        if isinstance(geom, Polygon):\n",
    "            return MultiPolygon([geom])\n",
    "        elif isinstance(geom, MultiPolygon):\n",
    "            return geom\n",
    "        else:\n",
    "            raise TypeError(\"Geometry must be a Polygon or MultiPolygon\")\n",
    "    # Check if the GeoSeries contains multiple geometry types - as this would be saved as a gpkg file with attribute 'geometry':'unknown', which GFO doesn't tolerate \n",
    "    unique_geom_types = layer_b.geom_type.unique()\n",
    "    # Convert to MultiPolygon if there are multiple geometry types \n",
    "    if len(unique_geom_types) > 1: \n",
    "        layer_b = layer_b.apply(to_multipolygon)\n",
    "        logmultpconv = 'Geometries converted to multipolygon \\n'\n",
    "        print(logmultpconv[:-2])\n",
    "    else:\n",
    "        logmultpconv = 'GeoSeries is only 1 geo_type \\n'\n",
    "        print(logmultpconv[:-2])\n",
    "    \n",
    "    # Check for number of features: if too many, split file\n",
    "    if len(layer_b) > 400000:\n",
    "        for k,l in zip(range(len(layer_b)//400000+1),range(0,len(layer_b),400000)):\n",
    "            # Write to file for GFO\n",
    "            write_path = f'{interimFiles_path}to_delete/{filename_noExt}_{k}_buf4dis_{bufs_iteration}.gpkg'\n",
    "            layer_b[l:l+399999].to_file(write_path) # GFO only works on files, therefore I'm saving this to disk\n",
    "            logwrt = f'Write split chunk {k} complete    ---   {datetime.datetime.now()}\\n File {k} written to {write_path} \\n'\n",
    "            print(logwrt[:-2])\n",
    "    \n",
    "            # Apply dissolve to all geoms in file, to reduce number of features - uses geofileops for speed\n",
    "            rewrite_path = f'{interimFiles_path}to_delete/{filename_noExt}_{k}_bufdis_{bufs_iteration}.gpkg'\n",
    "            input_path = write_path \n",
    "            output_path = rewrite_path\n",
    "            gfo.dissolve(input_path=input_path, output_path=output_path, explodecollections=False,force=overwrite) # explodecollections \n",
    "            logdis = f'Dissolve chunk {k} complete    ---   {datetime.datetime.now()}\\n File written to {rewrite_path} \\n'\n",
    "            print(logdis[:-2])\n",
    "    \n",
    "        # Merge the chunks into 1 big geom:\n",
    "        # Create a single GeoDataframe\n",
    "        for m in range(len(layer_b)//400000+1):\n",
    "            if m == 0:\n",
    "                diss = gpd.read_file(f'{interimFiles_path}to_delete/{filename_noExt}_{m}_bufdis_{bufs_iteration}.gpkg')\n",
    "            else:\n",
    "                diss_conc = gpd.read_file(f'{interimFiles_path}to_delete/{filename_noExt}_{m}_bufdis_{bufs_iteration}.gpkg')\n",
    "                diss = pd.concat([diss,diss_conc])\n",
    "                del diss_conc # clearing var for memory\n",
    "        # Write to file for GFO\n",
    "        write_path = f'{interimFiles_path}to_delete/{filename_noExt}_buf4dis_{bufs_iteration}.gpkg'\n",
    "        diss.to_file(write_path) # GFO only works on files, therefore I'm saving this to disk\n",
    "        logwrt = f'Write merged chunks complete    ---   {datetime.datetime.now()}\\n Concatenated file written to {write_path} \\n'\n",
    "        print(logwrt[:-2])\n",
    "        # Dissolve\n",
    "        rewrite_path = f'{interimFiles_path}bufdis/{filename_noExt}_bufdis_{bufs_iteration}.gpkg'\n",
    "        input_path = write_path \n",
    "        output_path = rewrite_path\n",
    "        gfo.dissolve(input_path=input_path, output_path=output_path, explodecollections=False,force=overwrite) # explodecollections \n",
    "        logdis = f'Dissolve merged chunks complete    ---   {datetime.datetime.now()}\\n File written to {rewrite_path} \\n'\n",
    "        print(logdis[:-2])\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        # Write to file for GFO\n",
    "        write_path = f'{interimFiles_path}to_delete/{filename_noExt}_buf4dis_{bufs_iteration}.gpkg'\n",
    "        layer_b.to_file(write_path) # GFO only works on files, therefore I'm saving this to disk\n",
    "        logwrt = f'Write buffer to file complete    ---   {datetime.datetime.now()}\\n File written to {write_path} \\n'\n",
    "        print(logwrt[:-2])\n",
    "    \n",
    "        # Apply dissolve to all geoms in file, to reduce number of features - uses geofileops for speed\n",
    "        rewrite_path = f'{interimFiles_path}bufdis/{filename_noExt}_bufdis_{bufs_iteration}.gpkg'\n",
    "        input_path = write_path \n",
    "        output_path = rewrite_path\n",
    "        gfo.dissolve(input_path=input_path, output_path=output_path, explodecollections=False,force=overwrite) # explodecollections \n",
    "        logdis = f'Dissolve complete    ---   {datetime.datetime.now()}\\n File written to {rewrite_path} \\n'\n",
    "        print(logdis[:-2])\n",
    "    \n",
    "    # Write to log\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.writelines([logcrs,logbuf,logmultpconv,logwrt,logdis,'\\n']) \n",
    "    \n",
    "    \n",
    "        \n",
    "    # Clear layer variables to free up memory\n",
    "    del layer_b\n",
    "    if 'diss' in locals():\n",
    "        del diss \n",
    "    if 'diss_conc' in locals():\n",
    "        del diss_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd7a0f4-0444-4ec5-8078-021ee815e828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bufdis function to buffer poly layers and dissolve geometries (geofileopps equivalent of unary_union)\n",
    "# paths = iterable of paths for geom files\n",
    "# bufs = iterable of buffer values\n",
    "\n",
    "# 23/01 Buffer + dissolve v3.0 (in Tests 0.06): splitting overly complex geometries to allow dissolve, checking for existing files to re-run only if overwrite = True, adding prefix for SOL/WIN, wrapping in function, adding a case for buf == 0\n",
    "# 24/01 Buffer+dissolve 4.0: make output filename non-scenario or RE specific to easily reuse across when parameters are equal. Output to bufids folder.\n",
    "# 31/01 removed re_type as obsolete\n",
    "def bufdis(paths, bufs, overwrite=False):\n",
    "    \n",
    "    start = time.perf_counter() # Performance counter\n",
    "    logpath = f'{interimFiles_path}logs/Bufdis Buffering log {datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")}.txt'# Create log\n",
    "    \n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.write(f'_____________Bufdis POLY BUFFER + DISSOLVE_____________\\n {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "        print(f'Bufdis POLY BUFFER + DISSOLVE -- Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    \n",
    "    loop_counter = 0 # initialise loop counter\n",
    "    for i, j in zip(paths, bufs):\n",
    "        loop_counter += 1 # Increment loop counter\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        \n",
    "        start_i = time.perf_counter() # Performance counter\n",
    "        log_filenm = f'File: {filename} \\nBuffer: {j}.\\n'\n",
    "        print(log_filenm[:-2])\n",
    "        with open(logpath, 'a') as logfile:\n",
    "            logfile.write(log_filenm) \n",
    "\n",
    "        # Check for existing file\n",
    "        exist_file = f'{interimFiles_path}bufdis/{filename_noExt}_bufdis_{j}.gpkg'\n",
    "        if overwrite==False: # Test for overwrite condition\n",
    "            log_or = f'Overwrite = False \\n'\n",
    "            print(log_or[:-2])\n",
    "            if os.path.exists(exist_file): # if file exists\n",
    "                logexist = f'File already exists: {exist_file}. \\n Skipping....\\n'\n",
    "                print(logexist)\n",
    "                with open(logpath, 'a') as logfile:\n",
    "                    logfile.writelines([log_or,logexist,'\\n']) \n",
    "                continue # Skip this layer if file exists\n",
    "            else:\n",
    "                logexist = f'File does not exist: {exist_file}. \\n Processing....\\n'\n",
    "                print(logexist[:-2]) \n",
    "                with open(logpath, 'a') as logfile:\n",
    "                    logfile.writelines([log_or,logexist]) \n",
    "\n",
    "                # Run buffering and dissolve function only if file doesn't exist\n",
    "                bufdis_internal(paths_iteration = i, bufs_iteration = j, filename = filename, filename_noExt = filename_noExt, overwrite = overwrite, logpath = logpath)\n",
    "\n",
    "        elif overwrite==True:\n",
    "            log_or = f'Overwrite = True \\n'\n",
    "            print(log_or[:-2])\n",
    "            if os.path.exists(exist_file): # if file exists\n",
    "                logexist = f'File already exists: {exist_file}. \\n Overwriting....\\n'\n",
    "                print(logexist[:-2])\n",
    "            else:\n",
    "                logexist = f'File does not exist: {exist_file}. \\n Processing....\\n'\n",
    "                print(logexist[:-2]) \n",
    "            with open(logpath, 'a') as logfile:\n",
    "                logfile.writelines([log_or,logexist]) \n",
    "\n",
    "            # Run buffering amd dissolve function in either case\n",
    "            bufdis_internal(paths_iteration = i, bufs_iteration = j, filename = filename, filename_noExt = filename_noExt, overwrite = overwrite, logpath = logpath)      \n",
    "\n",
    "        else:\n",
    "            log_or = f'Overwrite = Unspecified \\n'\n",
    "            print(log_or[:-2])\n",
    "            raise TypeError('Overwrite Condition Unspecified')\n",
    "\n",
    "        # Performance check\n",
    "        end_i = time.perf_counter()\n",
    "        elapsed_time_i = end_i - start_i\n",
    "        elapsed_time_str_i = str(timedelta(seconds=elapsed_time_i)) # Convert the elapsed time to a timedelta object\n",
    "        logproc = f'Layer processed in {elapsed_time_str_i}\\n'\n",
    "        print(logproc[:-2])\n",
    "        # Memory check (code from https://www.geeksforgeeks.org/how-to-get-current-cpu-and-ram-usage-in-python/)\n",
    "        logram = f'RAM memory % used:{psutil.virtual_memory()[2]} --- RAM Used (GB):{psutil.virtual_memory()[3]/1000000000}\\n'\n",
    "        print(logram)\n",
    "        \n",
    "        # Write to log\n",
    "        current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        with open(logpath, 'a') as logfile:\n",
    "            logfile.writelines([logproc,logram,'\\n']) \n",
    "\n",
    "\n",
    "    # Performance check\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'Code block run in {elapsed_time_str}\\nNumber of loops: {loop_counter} \\n'\n",
    "    print(logproc[:-2])\n",
    "    # Write to log\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.write(logproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e3037-4994-4275-9245-6f016b1d7fae",
   "metadata": {},
   "source": [
    "#### 2.1.1.2. Run buffering & dissolve function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be13139c-e5c6-4dd5-8d70-1edaf0aed5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_columns = [col for col in fac_df.columns if 'Buffer' in col]\n",
    "poly_pathbuf_df = fac_df.loc[fac_df['type']=='poly'].dropna(subset=buffer_columns)\n",
    "allbufs = bufs = poly_pathbuf_df[buffer_columns].values.flatten().tolist()\n",
    "allpaths = poly_pathbuf_df['Prepped Path'].repeat(len(buffer_columns)).tolist()\n",
    "buf_paths_df = pd.DataFrame([allbufs,allpaths]).T # Recombine into one df\n",
    "buf_paths_df_non0 = buf_paths_df.loc[buf_paths_df[0]!=0] # Drop zero values\n",
    "buf_paths_simple_df = buf_paths_df_non0.drop_duplicates() # Drop duplicate combinations\n",
    "bufs = buf_paths_simple_df[0].tolist()\n",
    "paths = buf_paths_simple_df[1].tolist()\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "858ef394-8d77-4894-9130-e506acbd4a0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bufdis POLY BUFFER + DISSOLVE -- Start 2025-03-13 23:15:15\n",
      "Code block run in 0:00:00.008710\n",
      "Number of loops: 0\n"
     ]
    }
   ],
   "source": [
    "# Run buffer+dissolve 4.0\n",
    "bufdis(paths = paths, bufs = bufs, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d411bde-dd76-454d-95b7-939c36558976",
   "metadata": {},
   "source": [
    "### 2.1.2. Rasters\n",
    "#### 2.1.2.1. Define functions (rasbuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62f14123-2294-4c6e-90a2-491a63046b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasbuf wrapper function\n",
    "# paths = iterable of raster paths (NB: for poly layers that need to be rasterized, use polyras and update Prepped Path in spreadsheet)\n",
    "# bufs = iterable of buffer values\n",
    "\n",
    "# started 27/01/2025\n",
    "# last edit 4/03/2025\n",
    "def rasbuf(paths, bufs, overwrite):\n",
    "    start = time.perf_counter() # Performance counter\n",
    "    logpath = f'{interimFiles_path}logs/Raster Buffering log {datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")}.txt'# Create log\n",
    "    \n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.write(f'_____________ RASTER BUFFER _____________\\n {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "        print(f'RASTER BUFFER -- Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "    loop_counter = 0 # initiate loop counter\n",
    "    to_check_buf = [] # Initialise lists of files to check (manual buffer, etc...)\n",
    "    to_check_max = []\n",
    "    # Iterate over files in the table\n",
    "    for i, j in zip(paths, bufs):\n",
    "        loop_counter += 1 #iterate loop counter\n",
    "        filename = os.path.basename(i)\n",
    "        filename_noExt = os.path.splitext(filename)[0]\n",
    "        \n",
    "        start_i = time.perf_counter() # Performance counter\n",
    "        log_filenm = f'File: {filename} ------------------------------------------------------\\nBuffer: {j}\\nPath: {i}.\\n'\n",
    "        print(log_filenm[:-2])\n",
    "        with open(logpath, 'a') as logfile:\n",
    "            logfile.write(log_filenm) \n",
    "             \n",
    "        # Check for existing file\n",
    "        exist_file = f'{interimFiles_path}rasbuf/{filename_noExt}_rasbuf_{j}.tif'\n",
    "        if overwrite==False: # Test for overwrite condition\n",
    "            log_or = f'Overwrite = False \\n'\n",
    "            print(log_or[:-2])\n",
    "            if os.path.exists(exist_file): # if file exists\n",
    "                logexist = f'File already exists: {exist_file} \\n Skipping....\\n'\n",
    "                print(logexist[:-2])\n",
    "                with open(logpath, 'a') as logfile:\n",
    "                    logfile.writelines([log_or,logexist,'\\n']) \n",
    "            else:\n",
    "                logexist = f'File does not exist: {exist_file} \\n Processing....\\n'\n",
    "                print(logexist[:-2]) \n",
    "                # Check for buffer size\n",
    "                if j >= 200:\n",
    "                    logsize = f'BUFFER SIZE {j} IS TOO LARGE! Process by hand using GRASS.\\n'\n",
    "                    to_check_buf.append(exist_file)\n",
    "                    print(logsize[:-2])\n",
    "                else:\n",
    "                    if j != 0:\n",
    "                        logsize = f'Buffer of size {j} is a good size for processing.\\n'\n",
    "                        print(logsize[:-2])\n",
    "                        # Run buffering function only if file doesn't exist and buffer small enough\n",
    "                        chk_maxval = rasbuf_internal(paths_iteration = i, bufs_iteration = j, filename = filename, filename_noExt = filename_noExt, logpath = logpath, exist_file=exist_file, overwrite = overwrite)  \n",
    "                        to_check_max.append(chk_maxval) # Append any layer that triggered warning messages to checklist\n",
    "                    else:\n",
    "                        logsize = f'Buffer of size {j} is zero. Skipping....\\n'\n",
    "                        print(logsize[:-2])\n",
    "                        \n",
    "                with open(logpath, 'a') as logfile:\n",
    "                    logfile.writelines([log_or,logexist, logsize,'\\n','\\n']) \n",
    "\n",
    "        elif overwrite==True:\n",
    "            log_or = f'Overwrite = True \\n'\n",
    "            print(log_or[:-2])\n",
    "            if os.path.exists(exist_file): # if file exists\n",
    "                logexist = f'File already exists: {exist_file} \\n Overwriting....\\n'\n",
    "                print(logexist[:-2])\n",
    "            else:\n",
    "                logexist = f'File does not exist: {exist_file} \\n Processing....\\n'\n",
    "                print(logexist[:-2]) \n",
    "            # Check for buffer size\n",
    "            if j >= 200:\n",
    "                logsize = f'BUFFER SIZE {j} IS TOO LARGE! Process by hand using GRASS.\\n'\n",
    "                print(logsize[:-2])\n",
    "            else:\n",
    "                if j != 0:\n",
    "                    logsize = f'Buffer of size {j} is a good size for processing.\\n'\n",
    "                    print(logsize[:-2])\n",
    "                    # Run buffering function in both cases, but only if buffer small enough\n",
    "                    chk_maxval = rasbuf_internal(paths_iteration = i, bufs_iteration = j, filename = filename, filename_noExt = filename_noExt, logpath = logpath, exist_file=exist_file, overwrite = overwrite) \n",
    "                    to_check_max.append(chk_maxval) # Append any layer that triggered warning messages to checklist\n",
    "                else:\n",
    "                    logsize = f'Buffer of size {j} is zero. Skipping....\\n'\n",
    "                    print(logsize[:-2])\n",
    "            \n",
    "                with open(logpath, 'a') as logfile:\n",
    "                    logfile.writelines([log_or, logexist , logsize,'\\n','\\n']) \n",
    "\n",
    "        else:\n",
    "            lor_or = f'Overwrite = Unspecified \\n'\n",
    "            print(log_or[:-2])\n",
    "            with open(logpath, 'a') as logfile:\n",
    "                logfile.writelines([log_or,'\\n','\\n']) \n",
    "            raise TypeError('Overwrite Condition Unspecified')\n",
    "        print('\\n')\n",
    "\n",
    "    log_tochk = f'Files to check: \\nBuffer: {to_check_buf} \\nMax val is not 1 : {to_check_max} \\n'\n",
    "    print(log_tochk)\n",
    "    with open(logpath, 'a') as logfile:\n",
    "            logfile.writelines([log_tochk,'\\n','\\n']) \n",
    "    \n",
    "    # Performance check\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'Rasbuf Code block run in {elapsed_time_str}\\nLoop count: {loop_counter} \\n'\n",
    "    print('\\n',logproc[:-2])\n",
    "    # Write to log\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.write(logproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12bc0726-8c8a-4322-b9cf-fcbe4b85d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal iterable raster buffering function\n",
    "# Adapted from https://gis.stackexchange.com/questions/86033/how-to-buffer-raster-pixels-by-their-values\n",
    "# Modified to work with last scipy version\n",
    "# started 27/01/2025\n",
    "# last edit 7/02/2025\n",
    "def rasbuf_internal(paths_iteration, bufs_iteration, filename, filename_noExt, logpath, exist_file, overwrite):\n",
    "    startbuf = time.perf_counter()\n",
    "    \n",
    "    # Read the raster layer\n",
    "    logrd= f'Read Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n File: {paths_iteration}.\\n'\n",
    "    print(logrd[:-2])\n",
    "    with rio.open(paths_iteration) as src:\n",
    "        raster = src.read(1)\n",
    "        crs=src.crs\n",
    "        transform = src.transform\n",
    "        meta = src.tags(1)\n",
    "        max_val = meta.get('STATISTICS_MAXIMUM')\n",
    "        if max_val != '1':\n",
    "            logmax = f'Maximum value is not 1, CHECK RESULTS! (Max = {max_val}).\\n'\n",
    "            print(logmax[:-2])\n",
    "            chk_maxval = paths_iteration\n",
    "        else:\n",
    "            logmax = f'(Max value = {max_val}).\\n'\n",
    "            print(logmax[:-2])\n",
    "            chk_maxval = None\n",
    "      \n",
    "    # Create a binary mask\n",
    "    mask = raster >= 1\n",
    "\n",
    "    # create circular kernel\n",
    "    def createKernel(radius):\n",
    "        kernel = np.zeros((2*radius+1, 2*radius+1))\n",
    "        y,x = np.ogrid[-radius:radius+1, -radius:radius+1]\n",
    "        mask = x**2 + y**2 <= radius**2\n",
    "        kernel[mask] = 1\n",
    "        return kernel\n",
    "    \n",
    "    # Define the buffer distance in PIXELS (1px = 10m --> Buffer (m) /10)\n",
    "    buf_dist = int(bufs_iteration/10)\n",
    "    \n",
    "    # Apply dilation\n",
    "    print(f'Dilation Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} --- File: {filename}')\n",
    "    buffered_mask = binary_dilation(mask, structure=createKernel(buf_dist))\n",
    "    logtypshap = f'buffered_mask dtype and shape: {buffered_mask.dtype, buffered_mask.shape}\\n'\n",
    "    print(logtypshap[:-2])\n",
    "    \n",
    "    del [mask,raster] # Clearing variables for memory\n",
    "\n",
    "    logar = f'Creating raster array Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}.\\n'\n",
    "    print(logar[:-2])\n",
    "    # Create a new raster with the buffered mask\n",
    "    dask_array = da.from_array(buffered_mask, chunks=(100, 100)) # Turning to dask array because otherwise the raster creation runs out of memory\n",
    "    buffered_raster = np.where(dask_array, 1, 0).astype(np.uint8)\n",
    "\n",
    "    # Save the buffered raster\n",
    "    write_path = exist_file\n",
    "    logwri=f'Write to file Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n Path: {write_path}\\n'\n",
    "    print(logwri[:-2])\n",
    "    with rio.open(\n",
    "        write_path, 'w',\n",
    "        driver='GTiff',\n",
    "        height=buffered_raster.shape[0],\n",
    "        width=buffered_raster.shape[1],\n",
    "        count=1,\n",
    "        dtype=buffered_raster.dtype,\n",
    "        crs=crs,\n",
    "        transform=transform,\n",
    "        compress='DEFLATE'\n",
    "    ) as dst:\n",
    "        dst.write(buffered_raster.compute(), 1)\n",
    "\n",
    "    try:\n",
    "        del raster\n",
    "    except:\n",
    "        print(\"('raster' var couldn't be deleted, likely doesn't exist)\")\n",
    "    \n",
    "    print(f'Process End {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    \n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.writelines([logrd,logmax,logtypshap,logar,logwri,'\\n'])\n",
    "\n",
    "    return chk_maxval\n",
    "        \n",
    "    endbuf = time.perf_counter()\n",
    "    elapsed_timebuf = endbuf - startbuf\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_strbuf = str(timedelta(seconds=elapsed_timebuf))\n",
    "    print(f'Code block run in {elapsed_time_strbuf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21125502-78ec-4b17-ae94-a3c8ac584dd3",
   "metadata": {},
   "source": [
    "#### 2.1.2.2. Run raster buffer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45f63fb5-1b11-400d-8171-71e9fcfcdf0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating df for raster buffering\n",
    "buffer_columns = [col for col in fac_df.columns if 'Buffer' in col] # Getting buffer columns names\n",
    "raster_pathbuf_df = fac_df.loc[(fac_df['type']=='raster') & (fac_df['Class']!= 'Coastline')].dropna(subset=buffer_columns) # dropping coastline layer as it needs special processing for negative buffer\n",
    "allbufs = raster_pathbuf_df[buffer_columns].values.flatten().tolist() # All buffer values to one list\n",
    "allpaths = raster_pathbuf_df['Prepped Path'].repeat(len(buffer_columns)).tolist() # All paths to one matching list\n",
    "buf_paths_df = pd.DataFrame([allbufs,allpaths]).T # Recombine into one df\n",
    "buf_paths_df_non0 = buf_paths_df.loc[buf_paths_df[0]!=0] # Drop zero values\n",
    "buf_paths_simple_df = buf_paths_df_non0.drop_duplicates() # Drop duplicate combinations\n",
    "bufs = buf_paths_simple_df[0].tolist()\n",
    "paths = buf_paths_simple_df[1].tolist()\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f02e4f1-bb83-479c-b8b3-ac400e250a54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RASTER BUFFER -- Start 2025-03-13 23:21:56\n",
      "File: OS_open_roads_lines.tif ------------------------------------------------------\n",
      "Buffer: 200\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Roads/OS_open_roads_lines.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/OS_open_roads_lines_rasbuf_200.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: OS_open_roads_lines.tif ------------------------------------------------------\n",
      "Buffer: 20\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Roads/OS_open_roads_lines.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/OS_open_roads_lines_rasbuf_20.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: OS_open_roads_lines.tif ------------------------------------------------------\n",
      "Buffer: 10\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Roads/OS_open_roads_lines.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/OS_open_roads_lines_rasbuf_10.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: Water_rivers_merged.tif ------------------------------------------------------\n",
      "Buffer: 10\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Land Cover/Water_rivers_merged.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/Water_rivers_merged_rasbuf_10.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: global_solar_2020_merged.tif ------------------------------------------------------\n",
      "Buffer: 45\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Existing RE/global_solar_2020_merged.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/global_solar_2020_merged_rasbuf_45.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: global_solar_2020_merged.tif ------------------------------------------------------\n",
      "Buffer: 10\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Existing RE/global_solar_2020_merged.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/global_solar_2020_merged_rasbuf_10.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: global_wind_2020_point_cropped.tif ------------------------------------------------------\n",
      "Buffer: 945\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Existing RE/global_wind_2020_point_cropped.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/global_wind_2020_point_cropped_rasbuf_945.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: global_wind_2020_point_cropped.tif ------------------------------------------------------\n",
      "Buffer: 45\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Existing RE/global_wind_2020_point_cropped.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/global_wind_2020_point_cropped_rasbuf_45.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: hotosm_gbr_airports_points.tif ------------------------------------------------------\n",
      "Buffer: 2000\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Airports/hotosm_gbr_airports_points.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/hotosm_gbr_airports_points_rasbuf_2000.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: hotosm_gbr_airports_points.tif ------------------------------------------------------\n",
      "Buffer: 100\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Airports/hotosm_gbr_airports_points.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/hotosm_gbr_airports_points_rasbuf_100.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: UKCEH_10m_urban.tif ------------------------------------------------------\n",
      "Buffer: 10\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Land Cover/UKCEH_10m_urban.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/UKCEH_10m_urban_rasbuf_10.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: UKCEH_10m_urban.tif ------------------------------------------------------\n",
      "Buffer: 1500\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Land Cover/UKCEH_10m_urban.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/UKCEH_10m_urban_rasbuf_1500.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: UKCEH_10m_urban.tif ------------------------------------------------------\n",
      "Buffer: 1000\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Land Cover/UKCEH_10m_urban.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/UKCEH_10m_urban_rasbuf_1000.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: UKCEH_10m_urban_2ha.tif ------------------------------------------------------\n",
      "Buffer: 1500\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Land Cover/UKCEH_10m_urban_2ha.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/UKCEH_10m_urban_2ha_rasbuf_1500.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: UKCEH_10m_urban_2ha.tif ------------------------------------------------------\n",
      "Buffer: 1000\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Land Cover/UKCEH_10m_urban_2ha.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/UKCEH_10m_urban_2ha_rasbuf_1000.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: Heritage_Monuments.tif ------------------------------------------------------\n",
      "Buffer: 500\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Heritage/Heritage_Monuments.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/Heritage_Monuments_rasbuf_500.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: Heritage_Parks_Gardens.tif ------------------------------------------------------\n",
      "Buffer: 2000\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Heritage/Heritage_Parks_Gardens.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/Heritage_Parks_Gardens_rasbuf_2000.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: Heritage_Parks_Gardens.tif ------------------------------------------------------\n",
      "Buffer: 1000\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Heritage/Heritage_Parks_Gardens.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/Heritage_Parks_Gardens_rasbuf_1000.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: Heritage_Parks_Gardens.tif ------------------------------------------------------\n",
      "Buffer: 500\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Heritage/Heritage_Parks_Gardens.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/Heritage_Parks_Gardens_rasbuf_500.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: Heritage_Listed_Buildings_merged.tif ------------------------------------------------------\n",
      "Buffer: 1000\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Heritage/Heritage_Listed_Buildings_merged.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/Heritage_Listed_Buildings_merged_rasbuf_1000.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: Heritage_Listed_Buildings_merged.tif ------------------------------------------------------\n",
      "Buffer: 500\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Heritage/Heritage_Listed_Buildings_merged.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/Heritage_Listed_Buildings_merged_rasbuf_500.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: JNCC_Ramsar_SPA.tif ------------------------------------------------------\n",
      "Buffer: 2000\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/PAs/JNCC_Ramsar_SPA.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/JNCC_Ramsar_SPA_rasbuf_2000.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "File: UKCEH_10m_woodland.tif ------------------------------------------------------\n",
      "Buffer: 50\n",
      "Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Land Cover/UKCEH_10m_woodland.tif\n",
      "Overwrite = False\n",
      "File already exists: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/UKCEH_10m_woodland_rasbuf_50.tif \n",
      " Skipping...\n",
      "\n",
      "\n",
      "Files to check: \n",
      "Buffer: [] \n",
      "Max val is not 1 : [] \n",
      "\n",
      "\n",
      " Rasbuf Code block run in 0:00:00.431276\n",
      "Loop count: 23\n"
     ]
    }
   ],
   "source": [
    "rasbuf(paths = paths, bufs = bufs, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7bb4a-dd2a-4866-b402-585e0dcfcd74",
   "metadata": {},
   "source": [
    "## 2.2. Subtraction of exclusion zones \n",
    "Subtractions are run per scenario, using the pre-generated buffer files. They generate scenario+RE-specific intermediate files to speed up re-runs if only a few layers are changed within a scenario (the layers most likely to change are kept later in the subtraction order so the new subtraction can be processed from the last unchanged layer).\n",
    "### 2.2.1. Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9fa831-df52-45ef-8e38-010d7942dc07",
   "metadata": {},
   "source": [
    "#### 2.2.1.1. Poly subtractions (polysub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3afdac96-e157-409a-92fa-9fc519b9b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polysub: GPD difference function for polygons\n",
    "# created 24/01/2025 (probably even before that, actually)\n",
    "# last edit 3/02\n",
    "\n",
    "# polysub_base_path = buffered coastline --> first iteration should be an intersection\n",
    "# polysub_df = dataframe of poly layers to subtract, provided by wrapper function, based on overall df filtered by layer type and priority (keeping all columns inc. file names and buffered files paths)\n",
    "# NB: Coastline must have been removed from polysub_df!\n",
    "\n",
    "def polysub(polysub_base_path, polysub_df, re_type, scenario_nr, logpath, overwrite=False):\n",
    "    start1 = time.perf_counter()\n",
    "    \n",
    "    # Print and log info\n",
    "    logorder = f'\\nPolysub - Start time --- {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} \\nBase: {polysub_base_path}\\nSubtraction order: \\n{polysub_df['filename_noExt']}'\n",
    "    print(logorder)\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.writelines([logorder,'\\n'])\n",
    "    if overwrite == True:\n",
    "        logov= f'Overwrite has not been implemented in this function, please delete files manually.'\n",
    "        print(logov)\n",
    "        with open(logpath, 'a') as logfile:\n",
    "            logfile.writelines([logov,'\\n'])\n",
    "\n",
    "    # Iterate over bufdis layers for subtraction\n",
    "    for i,j in enumerate(polysub_df['bufdis_path']):\n",
    "        # Define write path\n",
    "        write_file = f'S{scenario_nr}_{re_type}_polysub{i}_{polysub_df.loc[polysub_df['bufdis_path']==j, 'Class'].iloc[0][:24]}.gpkg'\n",
    "        polysub_write_path = f'{interimFiles_path}subs/{write_file}' # Write to interim file with subtraction number & subtracted Class in filename\n",
    "        #Check if polysub result already exists\n",
    "        if not os.path.exists(polysub_write_path): # if file does not exist\n",
    "            logexist = f'\\nFile {write_file} does not exist. Processing...'\n",
    "            print(logexist)\n",
    "            current_geom = gpd.read_file(j)\n",
    "            # Length check\n",
    "            loglen = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Geom df length is {len(current_geom)}. '\n",
    "            print(loglen)\n",
    "            with open(logpath, 'a') as logfile:\n",
    "                logfile.writelines([logexist, '\\n', loglen, '\\n'])    \n",
    "            if i == 0:\n",
    "                # Subtraction from base for first iteration\n",
    "                polysub_base = gpd.read_file(polysub_base_path)\n",
    "                result_geom = polysub_base.overlay(current_geom, how = 'difference')\n",
    "                # Log\n",
    "                logdif = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Base subtraction (polysub {i}) complete.'\n",
    "                print(logdif)\n",
    "                # Write\n",
    "                result_geom.to_file(polysub_write_path)\n",
    "                logwri = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Writing of polysub {i} file complete. Path: {polysub_write_path}'\n",
    "                print(logwri)\n",
    "                with open(logpath, 'a') as logfile:\n",
    "                    logfile.writelines([logdif,'\\n',logwri,'\\n'])\n",
    "                del polysub_base # for memory\n",
    "            else:\n",
    "                # Difference for all subsequent iterations\n",
    "                if 'result_geom' not in locals(): # checking result_geom exists from previous iteration. If not, read last written file (prev_write_path generated by skipping condition).\n",
    "                    result_geom = gpd.read_file(prev_write_path)\n",
    "                result_geom = result_geom.overlay(current_geom, how = 'difference') # Uses the var still in memory from previous iteration. Fast to write, but won't accept interruptions. May rewrite to check for existing and read file at every step.\n",
    "                logdif = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Difference {i} complete.'\n",
    "                print(logdif)\n",
    "                result_geom.to_file(polysub_write_path)\n",
    "                logwri = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Writing of polysub {i} file complete. Path: {polysub_write_path}'\n",
    "                with open(logpath, 'a') as logfile:\n",
    "                    logfile.writelines([logdif,'\\n',logwri,'\\n'])\n",
    "        else: # If file exists\n",
    "            logexist = f'\\nFile {write_file} exists. Skipping...'\n",
    "            prev_write_path = polysub_write_path\n",
    "            print(logexist)\n",
    "            with open(logpath, 'a') as logfile:\n",
    "                logfile.writelines([logexist,'\\n'])\n",
    "\n",
    "    # Clearing variables for memory\n",
    "    try:\n",
    "        del result_geom\n",
    "    except:\n",
    "        print(\"('result_geom' var could not be deleted, likely doesn't exist)\")\n",
    "    try:\n",
    "        del current_geom\n",
    "    except:\n",
    "        print(\"('current_geom' var could not be deleted, likely doesn't exist)\")\n",
    "    \n",
    "    end1 = time.perf_counter()\n",
    "    elapsed_time1 = end1 - start1\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str1 = str(timedelta(seconds=elapsed_time1))\n",
    "    logfun = f'GPD diff function run in {elapsed_time_str1}'\n",
    "    print(logfun)\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.writelines([logfun,'\\n'])\n",
    "\n",
    "    return polysub_write_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb920f-131e-4bb0-99ed-297b2cc0ca36",
   "metadata": {},
   "source": [
    "#### 2.2.1.2 Rasterization of poly layer (polyrast : used to rasterize result of polysub; also used in layers prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f7e812b-2953-4d7e-ab1f-dacf9dc0db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created 31/01\n",
    "# Last edit 24/02\n",
    "\n",
    "def polyrast(poly_path, raster_path, scenario_nr, logpath):\n",
    "    start = time.perf_counter()\n",
    "    logstart = f'\\nPolyrast Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "    print(logstart)\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.writelines([logstart,'\\n'])\n",
    "    # Getting file name for output naming\n",
    "    filename = os.path.basename(poly_path)\n",
    "    filename_noExt = os.path.splitext(filename)[0]\n",
    "    ext = os.path.splitext(filename)[1]\n",
    "    polyrast_write_file = f'{filename_noExt}.tif'\n",
    "    polyrast_write_path = f'{interimFiles_path}polyrast/{polyrast_write_file}'\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(polyrast_write_path):\n",
    "        logexist = f'File does not exist: {polyrast_write_path}. \\n Processing....'\n",
    "        print (logexist)\n",
    "        # Read the reference raster\n",
    "        logref = f'Read ref raster Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n from: {raster_path}'\n",
    "        print(logref)\n",
    "        with rio.open(raster_path) as src:\n",
    "            # Read poly layer\n",
    "            logrd = f'Read poly Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n from: {poly_path}'\n",
    "            print(logrd)\n",
    "            vector = gpd.read_file(poly_path)\n",
    "        \n",
    "            # Rasterize poly\n",
    "            #https://pygis.io/docs/e_raster_rasterize.html\n",
    "            geom = [shapes for shapes in vector.geometry]\n",
    "            logras = f'Rasterize poly Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "            print(logras)\n",
    "            # Rasterize vector using the shape and coordinate system of the raster\n",
    "            rasterized = features.rasterize(geom, out_shape = src.shape, fill = 0, out = None, transform = src.transform, all_touched = False, default_value = 1, dtype = None) # All touched = False --> only pixels fully inside the geom\n",
    "        \n",
    "            # Write to file\n",
    "            logwri = f'Writing rasterized poly to file Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "            print(logwri)\n",
    "            with rio.open(\n",
    "            polyrast_write_path, 'w',\n",
    "            driver='GTiff',\n",
    "            height=src.shape[0],\n",
    "            width=src.shape[1],\n",
    "            count=1,\n",
    "            dtype=rasterized.dtype,\n",
    "            crs=src.crs,\n",
    "            transform=src.transform,\n",
    "            compress='DEFLATE'\n",
    "            ) as dst:\n",
    "                dst.write(rasterized, 1)\n",
    "        with open(logpath, 'a') as logfile:\n",
    "            logfile.writelines([logexist,'\\n',logref,'\\n',logrd,'\\n',logras,'\\n',logwri,'\\n'])\n",
    "    else:\n",
    "        logexist = f'File already exists: {polyrast_write_path}. \\n Skipping....'\n",
    "        print (logexist)\n",
    "        with open(logpath, 'a') as logfile:\n",
    "            logfile.writelines([logexist,'\\n'])\n",
    "\n",
    "    # Clearing variables for memory\n",
    "    try:\n",
    "        del vector\n",
    "    except:\n",
    "        print(\"('vector' var could not be deleted, likely doesn't exist)\")\n",
    "    try:\n",
    "        del geom\n",
    "    except:\n",
    "        print(\"('geom' var could not be deleted, likely doesn't exist)\")\n",
    "    try:\n",
    "        del rasterized\n",
    "    except:\n",
    "        print(\"('rasterized' var could not be deleted, likely doesn't exist)\")\n",
    "    try:\n",
    "        del src\n",
    "    except:\n",
    "        print(\"('src' var could not be deleted, likely doesn't exist)\")\n",
    "    \n",
    "    logend = f'Polyrast End {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "    print(logend)\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logrun = f'Polyras Code block run in {elapsed_time_str}'\n",
    "    print(logrun)\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.writelines([logend,'\\n', logrun])\n",
    "    return polyrast_write_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cc342c5-ffbe-4d16-b869-e87ec80e0207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rassub : wrapper function for raster subtractions. Checks for file existence.\n",
    "# Created 30/01/2025\n",
    "# Last edit 13/03 - added buffer value to filename\n",
    "\n",
    "def rassub(rassub_base, rassub_df , re_type, scenario_nr, logpath, overwrite=False):\n",
    "    # rassub_base = raster of all the combined poly layers, provided by wrapper function\n",
    "    # rassub_df = dataframe of layers to subtract, provided by wrapper function, based on overall df filtered by layer type and priority (keeping all columns inc. file names and buffered files paths)\n",
    "    start_rs = time.perf_counter() # Performance counter\n",
    "    \n",
    "    # Print and log info\n",
    "    logorder = f'Rassub - Start time --- {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} \\nSubtraction order: \\n{rassub_df['filename_noExt']}'\n",
    "    print(logorder)\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.writelines([logorder,'\\n'])\n",
    "    if overwrite == True:\n",
    "        logov= f'Overwrite has not been implemented in this function, please delete files manually.'\n",
    "        print(logov)\n",
    "        with open(logpath, 'a') as logfile:\n",
    "            logfile.writelines([logov,'\\n'])\n",
    "    \n",
    "    # Iterate over rassub layers for subtraction\n",
    "    for i,j in enumerate(zip(rassub_df.index,rassub_df['rasbuf_path'])):\n",
    "        gc.collect() # Cleaning memory to start\n",
    "        print(f'Gc.collect applied')\n",
    "        # Define write path\n",
    "        buf_val = rassub_df.loc[j[0], f'S{scenario_nr} Buffer (m)']\n",
    "        write_file = f'S{scenario_nr}_{re_type}_rassub{i}_{rassub_df.loc[j[0], 'Class'][:24]}_{buf_val}.tif'\n",
    "        write_path = f'{interimFiles_path}subs/{write_file}' # Write to interim file with subtraction number, subtracted Class & buffer value in filename \n",
    "        if i == 0:\n",
    "            prev_write_path = None\n",
    "        #Check if already processed rassub raster exists for this class and iteration number\n",
    "        if not os.path.exists(write_path): # if file does not exist\n",
    "            logexist = f'\\nFile {write_file} does not exist. Processing...'\n",
    "            print(logexist)\n",
    "            with open(logpath, 'a') as logfile:\n",
    "                logfile.writelines([logexist, '\\n'])\n",
    "            \n",
    "            # Run rassub_internal\n",
    "            rassub_internal(iteration_nr = i, rassub_df_index = j[0], rasbuf_path = j[1], \n",
    "                            write_path = write_path, prev_write_path = prev_write_path, rassub_base = rassub_base, \n",
    "                            rassub_df = rassub_df, re_type = re_type, scenario_nr = scenario_nr, logpath = logpath, overwrite=False)\n",
    "\n",
    "        else: # If file exists\n",
    "            logexist = f'\\nFile {write_file} exists. Skipping...'\n",
    "            prev_write_path = write_path\n",
    "            print(logexist)\n",
    "            with open(logpath, 'a') as logfile:\n",
    "                logfile.writelines([logexist,'\\n'])\n",
    "            gc.collect()\n",
    "            print(f'Gc.collect applied')\n",
    "\n",
    "        logloop = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} End of loop {i}'\n",
    "        print(logloop)\n",
    "        with open(logpath, 'a') as logfile:\n",
    "            logfile.writelines([logloop,'\\n'])\n",
    "        gc.collect()\n",
    "        print(f'Gc.collect applied')\n",
    "        prev_write_path = write_path # saving path for next iteration\n",
    "    \n",
    "    # Clearing variables for memory\n",
    "    try:\n",
    "        del processed_data\n",
    "    except:\n",
    "        print(\"('processed_data' var couldn't be deleted, likely doesn't exist)\")\n",
    "    gc.collect()\n",
    "    print(f'Gc.collect applied')\n",
    "             \n",
    "    end_rs = time.perf_counter()\n",
    "    elapsed_time_rs = end_rs - start_rs\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str_rs = str(timedelta(seconds=elapsed_time_rs))\n",
    "    logfun = f'Raster difference function run in {elapsed_time_str_rs}'\n",
    "    print(logfun)\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.writelines([logfun,'\\n'])\n",
    "\n",
    "    return write_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b71b3e3-057e-4554-94da-38b7768e2bfb",
   "metadata": {},
   "source": [
    "#### 2.2.1.3. Raster subtractions (rassub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4cebef0-171f-4b46-83c3-516b58b98d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rassub internal function:  rasters subtraction\n",
    "# created 8/02\n",
    "# last edit 5/03 \n",
    "def rassub_internal(iteration_nr, rassub_df_index, rasbuf_path, write_path, prev_write_path, rassub_base, rassub_df, re_type, scenario_nr, logpath, overwrite=False):\n",
    "    # Read raster to subtract\n",
    "    lognm = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Processing layer {iteration_nr}, class: {rassub_df.loc[rassub_df_index, 'Class']}. \\nFile subtracted: {rasbuf_path}'\n",
    "    print(lognm)\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.writelines([lognm, '\\n'])\n",
    "    with rio.open(rasbuf_path) as src:\n",
    "        dask_ar = da.from_array(src.read(1), chunks= 100)\n",
    "        transform = src.transform\n",
    "        # Subtraction:\n",
    "        if iteration_nr == 0:\n",
    "            # IF FIRST ITERATION, subtract from base\n",
    "            # Read base\n",
    "            with rio.open(rassub_base) as src_base:\n",
    "                dask_ar_base = da.from_array(src_base.read(1), chunks= 100)\n",
    "            # Subtraction\n",
    "            logmsk = f'Subtracting from rassub base\\n Mask creation Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\nThreshold = {rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']} (if NA, all values above 0 are masked)'\n",
    "            print(logmsk)\n",
    "            if pd.isna(rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']): # for buffer layers\n",
    "                if (rassub_df.loc[rassub_df_index, 'Class']!= 'Substations'): # for all classes except substations\n",
    "                    mask = (dask_ar > 0) & (dask_ar < 255) # Make a boolean array out of non-null raster pixels (exclude 255 as this is the null value for buffers processed in GRASS)\n",
    "                    logthr = f'No threshold, binary subtraction'\n",
    "                    print(logthr)\n",
    "                elif (rassub_df.loc[rassub_df_index, 'Class']== 'Substations'):\n",
    "                    mask = da.invert((dask_ar > 0) & (dask_ar < 255)) # For Substations layer: mask inverted\n",
    "                    logthr = f'No threshold, substations --> mask inverted'\n",
    "                    print(logthr)\n",
    "            elif (pd.notna(rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']) and (rassub_df.loc[rassub_df_index, 'Class']=='Slope')):  # for threshold layers: slope\n",
    "                threshold = rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']\n",
    "                mask = dask_ar >= threshold\n",
    "                logthr = f'Threshold present, slope --> exclude values above {threshold}'\n",
    "                print(logthr)\n",
    "            elif (pd.notna(rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']) and (rassub_df.loc[rassub_df_index, 'Class']!='Slope')): # for threshold layers that are not slope\n",
    "                threshold = rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']\n",
    "                mask = dask_ar <= threshold\n",
    "                logthr = f'Threshold present, other --> exclude values below {threshold}'\n",
    "                print(logthr)\n",
    "            logdifst = f'Difference Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "            print(logdifst)\n",
    "            processed_data = da.where(mask, 0, dask_ar_base) #Pixels in mask set to 0         \n",
    "            # Log\n",
    "            logdif = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Raster Difference {iteration_nr} complete.'\n",
    "            print(logdif)\n",
    "            del dask_ar # For memory\n",
    "            gc.collect()\n",
    "            print(f'Gc.collect applied')\n",
    "            \n",
    "            # Write result to file\n",
    "            with rio.open(\n",
    "                write_path, 'w',\n",
    "                driver='GTiff',\n",
    "                height=processed_data.shape[0],\n",
    "                width=processed_data.shape[1],\n",
    "                count=1,\n",
    "                dtype=processed_data.dtype,\n",
    "                crs=src.crs,\n",
    "                transform=transform,\n",
    "                compress='DEFLATE'\n",
    "            ) as dst:\n",
    "                dst.write(processed_data.compute(), 1)\n",
    "            logwri = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Writing of rassub {iteration_nr} file complete. Path: {write_path}'\n",
    "            print(logwri)\n",
    "            with open(logpath, 'a') as logfile:\n",
    "                logfile.writelines([logmsk,'\\n',logthr,'\\n', logdifst,'\\n', logdif,'\\n', logwri,'\\n'])\n",
    "\n",
    "            # Clearing variables to free space in swap memory\n",
    "            del dask_ar_base\n",
    "            del mask\n",
    "            del dst\n",
    "            del processed_data\n",
    "            gc.collect()\n",
    "            print(f'Gc.collect applied')\n",
    "            \n",
    "        else:\n",
    "            # ELSE, SUBTRACT FROM PREVIOUS\n",
    "            # Reading previous layer\n",
    "            logprv = f'Reading from previous layer: {prev_write_path} --- {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "            print(logprv)\n",
    "            with open(logpath, 'a') as logfile:\n",
    "                logfile.writelines([logprv,'\\n'])\n",
    "            with rio.open(prev_write_path) as src_prev:\n",
    "                prev_dask_ar = da.from_array(src_prev.read(1), chunks= 100)\n",
    "            # Subtraction\n",
    "            logmsk = f'Mask creation Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\nThreshold = {rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']} (if NA, all values above 0 are masked)'\n",
    "            print(logmsk)\n",
    "            if pd.isna(rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']): # for buffer layers\n",
    "                if (rassub_df.loc[rassub_df_index, 'Class']!= 'Substations'): # for all classes except substations\n",
    "                    mask = (dask_ar > 0) & (dask_ar < 255) # Make a boolean array out of non-null raster pixels (exclude 255 as this is the null value for buffers processed in GRASS)\n",
    "                    logthr = f'No threshold, binary subtraction'\n",
    "                    print(logthr)\n",
    "                elif (rassub_df.loc[rassub_df_index, 'Class']== 'Substations'): # for substations\n",
    "                    mask = da.invert((dask_ar > 0) & (dask_ar < 255)) # For Substations layer: mask inverted\n",
    "                    logthr = f'No threshold, substations --> mask inverted'\n",
    "                    print(logthr)\n",
    "            elif (pd.notna(rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']) and (rassub_df.loc[rassub_df_index, 'Class']=='Slope')): # for threshold layers: slope\n",
    "                threshold = rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']\n",
    "                mask = dask_ar >= threshold\n",
    "                logthr = f'Threshold present, slope --> exclude values above {threshold}'\n",
    "                print(logthr)\n",
    "            elif (pd.notna(rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']) and (rassub_df.loc[rassub_df_index, 'Class']!='Slope')): # for threshold layers that are not slope\n",
    "                threshold = rassub_df.loc[rassub_df_index, f'S{scenario_nr} Threshold']\n",
    "                mask = dask_ar <= threshold\n",
    "                logthr = f'Threshold present, other --> exclude values below {threshold}'\n",
    "                print(logthr)\n",
    "            del dask_ar # For memory\n",
    "            gc.collect()\n",
    "            print(f'Gc.collect applied')\n",
    "            logdifst = f'Difference Start {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "            print(logdifst)            \n",
    "            processed_data = da.where(mask, 0, prev_dask_ar) #Pixels in mask set to 0         \n",
    "            logdif = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Raster Difference {iteration_nr} complete.'\n",
    "            print(logdif)\n",
    "\n",
    "            # Write result to file\n",
    "            with rio.open(\n",
    "                write_path, 'w',\n",
    "                driver='GTiff',\n",
    "                height=processed_data.shape[0],\n",
    "                width=processed_data.shape[1],\n",
    "                count=1,\n",
    "                dtype=processed_data.dtype,\n",
    "                crs=src.crs,\n",
    "                transform=transform,\n",
    "                compress='DEFLATE'\n",
    "            ) as dst:\n",
    "                dst.write(processed_data.compute(), 1)\n",
    "            logwri = f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - Writing of rassub {iteration_nr} file complete. Path: {write_path}'\n",
    "            print(logwri)\n",
    "            with open(logpath, 'a') as logfile:\n",
    "                logfile.writelines([logmsk,'\\n',logthr,'\\n', logdifst,'\\n', logdif,'\\n', logwri,'\\n'])\n",
    "                \n",
    "            try:\n",
    "                del src_prev\n",
    "            except:\n",
    "                print(\"('src_prev' var couldn't be deleted, likely doesn't exist)\")\n",
    "            del mask\n",
    "            del prev_dask_ar\n",
    "            del processed_data\n",
    "            del dst\n",
    "            gc.collect()\n",
    "            print(f'Gc.collect applied')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128a64a-6305-4a72-bf6c-840953f76d95",
   "metadata": {},
   "source": [
    "#### 2.2.1.4 Wrapper function regrouping all subtraction operations (allsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6ed0cd9-31c0-43d7-9928-e4a3858ae671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allsub: Subtraction Wrapper function\n",
    "# Subtracts all layers for the selected RE type, based on parameters in IGS Tables Excel Sheet\n",
    "# created 24/01/2025\n",
    "# last edit 25/02 (small edit 3/03 to change logpath & 6/03 to change some of the log text)\n",
    "# NB:\n",
    "# re_type must be 'Solar' or 'Wind'\n",
    "# requires fac_df as input: dataframe of suitability layers, their buffer and threshold parameters, and data paths. Derived from Suitability Factors sheet in IGS Tables Excel File\n",
    "# Always uses Coastline as a base\n",
    "\n",
    "def allsub(fac_df,re_type,scenario_nr, overwrite = False):\n",
    "    start = time.perf_counter() # Performance counter\n",
    "    logpath = f'{interimFiles_path}logs/S{scenario_nr} {re_type} Allsub log {datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")}.txt'\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logstart = f'_________________LAYERS SUBTRACTIONS - Scenario {scenario_nr}_________________ \\nStart {datetime.datetime.now()} \\n RE type: {re_type}'\n",
    "        logfile.writelines([logstart,'\\n'])\n",
    "    print(logstart)\n",
    "    # Check for correct re_type\n",
    "    if re_type not in ['Solar','Wind']:\n",
    "        raise TypeError(f\"re_type must be 'Solar' or 'Wind'\")\n",
    "    \n",
    "    # Preparing input dataframe:\n",
    "    # Adding bufdis_path & rasbuf_path columns to \n",
    "    scenario_df = fac_df\n",
    "    for _ in scenario_df.index:\n",
    "        if pd.isnull(scenario_df.loc[_,'filename_noExt']):\n",
    "            continue\n",
    "        #POLY\n",
    "        elif (pd.notna(scenario_df.loc[_, f'S{scenario_nr} Buffer (m)']) and (scenario_df.loc[_, f'S{scenario_nr} Buffer (m)'] != 0) and (scenario_df.loc[_, 'type'] == 'poly') and (scenario_df.loc[_, f'S{scenario_nr} inc/exc'] == 'exc')): # if buffer NOT zero and type = poly\n",
    "            bufdis_path = f'{interimFiles_path}bufdis/{scenario_df.loc[_,'filename_noExt']}_bufdis_{scenario_df.loc[_,f'S{scenario_nr} Buffer (m)']}.gpkg'\n",
    "            scenario_df.loc[_,'bufdis_path'] = bufdis_path if os.path.exists(bufdis_path) else np.nan # create bufdis_path column ONLY WHERE FILE EXISTS\n",
    "        elif(pd.notna(scenario_df.loc[_, f'S{scenario_nr} Buffer (m)']) and (scenario_df.loc[_, f'S{scenario_nr} Buffer (m)'] == 0) and (scenario_df.loc[_, 'type'] == 'poly') and (scenario_df.loc[_, f'S{scenario_nr} inc/exc'] == 'exc')): # if buffer = 0 and type = poly\n",
    "            bufdis_path = f'{scenario_df.loc[_,'Prepped Path']}'\n",
    "            scenario_df.loc[_,'bufdis_path'] = bufdis_path if os.path.exists(bufdis_path) else np.nan # create bufdis_path column ONLY WHERE FILE EXISTS\n",
    "        #RASTERS\n",
    "        elif (pd.notna(scenario_df.loc[_, f'S{scenario_nr} Buffer (m)']) and (scenario_df.loc[_, f'S{scenario_nr} Buffer (m)'] != 0) and (scenario_df.loc[_, 'type'] == 'raster') and (scenario_df.loc[_, f'S{scenario_nr} inc/exc'] == 'exc')): # if buffer NOT zero and type = raster\n",
    "            rasbuf_path = f'{interimFiles_path}rasbuf/{scenario_df.loc[_,'filename_noExt']}_rasbuf_{scenario_df.loc[_,f'S{scenario_nr} Buffer (m)']}.tif'\n",
    "            scenario_df.loc[_,'rasbuf_path'] = rasbuf_path if os.path.exists(rasbuf_path) else np.nan # create rasbuf_path column ONLY WHERE FILE EXISTS\n",
    "        elif (pd.notna(scenario_df.loc[_, f'S{scenario_nr} Buffer (m)']) and (scenario_df.loc[_, f'S{scenario_nr} Buffer (m)'] == 0)  and (scenario_df.loc[_, 'type'] == 'raster') and (scenario_df.loc[_, f'S{scenario_nr} inc/exc'] == 'exc')): #if buffer = 0 and type = raster\n",
    "            rasbuf_path = f'{scenario_df.loc[_,'Prepped Path']}'\n",
    "            scenario_df.loc[_,'rasbuf_path'] = rasbuf_path if os.path.exists(rasbuf_path) else np.nan # create rasbuf_path column ONLY WHERE FILE EXISTS\n",
    "    \n",
    "    ### SUBTRACTIONS ###\n",
    "    if 'bufdis_path' in scenario_df.columns: # check if any bufdis path was generated\n",
    "        # If True, there are poly layers, process them\n",
    "        ### 1 - POLYSUB ###'\n",
    "        logsub = f'\\n### 1 - POLYSUB ###'\n",
    "        with open(logpath, 'a') as logfile:\n",
    "            logfile.writelines([logsub,'\\n'])\n",
    "        # Prepare polysub base path\n",
    "        polysub_base_path = scenario_df.loc[(scenario_df['Resource']==re_type)&(scenario_df['Class']=='Coastline')]['bufdis_path'].iloc[0]\n",
    "        # Prepare polysub dataframe\n",
    "        polysub_df = scenario_df.loc[(scenario_df['Resource']==re_type)&(scenario_df['type']=='poly')&(scenario_df['Class']!='Coastline')].dropna(subset=['bufdis_path']) #dropping rows with no existing bufdis file & dropping coastline row\n",
    "        # Run polysub\n",
    "        polysub_write_path = polysub(polysub_base_path = polysub_base_path, polysub_df = polysub_df, re_type = re_type, scenario_nr = scenario_nr, logpath = logpath, overwrite=overwrite) # Capture output in polysub_write_path\n",
    "        ### POLYRAST\n",
    "        # Prepare rassub_base: rasterize polysub result.\n",
    "        # Requires polyrast function + result from polysub read from disk (slightly longer to process on first run but easier for re-runs, which happen often for tweaks in the raster layers)\n",
    "        lograsbase = f'Polyrast poly path: {polysub_write_path}'\n",
    "        print(lograsbase)\n",
    "        with open(logpath, 'a') as logfile:\n",
    "            logfile.writelines([lograsbase,'\\n'])\n",
    "        rassub_base_path = polyrast(poly_path = polysub_write_path, raster_path = f'{preppedDat_path}UKCEH_LC_2023_10m.tif', scenario_nr = scenario_nr, logpath = logpath) #raster_path loads UKCEH_LC_2023_10m as reference raster for img size and CRS.\n",
    "\n",
    "    else:\n",
    "        # If no poly layers present, skip straight to rassub, and provide a base path\n",
    "        logsub = f'\\nNo vector files present, moving on to raster processing'\n",
    "        with open(logpath, 'a') as logfile:\n",
    "            logfile.writelines([logsub,'\\n'])\n",
    "        rassub_base_path = scenario_df.loc[(scenario_df['Class'] == 'Coastline') & (scenario_df['Resource'] == re_type), 'rasbuf_path'].iloc[0]\n",
    "\n",
    "    ### 2 - RASSUB ###\n",
    "    logsub = f'\\n### 2 - RASSUB, by order of priority ###'\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.writelines([logsub,'\\n'])\n",
    "    # Prepare rassub dataframe\n",
    "    rassub_df = scenario_df.loc[(scenario_df['Resource']==re_type)&(scenario_df['type']=='raster')&(scenario_df['Class']!='Coastline')].dropna(subset=['rasbuf_path']).sort_values(by = 'subtraction order') # dropping rows with no existing rasbuf file & dropping coastline rows, sorting by subtraction order\n",
    "    # Run rassub\n",
    "    rassub_write_path = rassub(rassub_base = rassub_base_path, rassub_df = rassub_df , re_type = re_type, scenario_nr = scenario_nr, logpath = logpath, overwrite=overwrite) # uses write path from polyrast function\n",
    "\n",
    "    ### VECTORIZATION OF SUBTRACTIONS RESULT ####\n",
    "    # Define write path\n",
    "    vecto_write_file = f'Scenario{scenario_nr}_{re_type}_all.gpkg'\n",
    "    vecto_write_path = f'{interimFiles_path}allsub/{vecto_write_file}'\n",
    "    # Adapted from : https://gis.stackexchange.com/questions/431918/vectorizing-a-raster-containing-holes-using-rasterio \n",
    "    print(f'\\n Vectorization of results (will always run regardless of Overwrite parameters)')\n",
    "    with rio.open(rassub_write_path) as src:\n",
    "        data = src.read(1)\n",
    "        print(f'Data shape{data.shape}')\n",
    "        mask= data!=0\n",
    "        print(f'Mask shape {mask.shape}')\n",
    "        # Create a generator of the shapes\n",
    "        shape_gen = ((shape(s), v) for s, v in shapes(data, mask=mask, connectivity=8, transform=src.transform)) # Connectivity=8 -> queen connectivity\n",
    "        # Build a dict from unpacked shapes and turn into a gdf\n",
    "        gdf = gpd.GeoDataFrame(dict(zip([\"geometry\", \"class\"], zip(*shape_gen))), crs=src.crs)\n",
    "        # Calculate Area column\n",
    "        gdf['Area_(m2)']=gdf['geometry'].area # calculates area (nb: Geopandas calculations are planimetric, not ellipsoidal)\n",
    "        # Add RE_type column\n",
    "        gdf['RE_type'] = re_type\n",
    "        # Save to file\n",
    "        gdf.to_file(vecto_write_path)\n",
    "    # Get small areas threshold\n",
    "    area_thr = scenario_df.loc[(scenario_df['Class']=='Small areas')&(scenario_df['Resource']==re_type), f'S{scenario_nr} Threshold'].iloc[0]\n",
    "    # Define write path\n",
    "    vecto_big_write_file = f'Scenario{scenario_nr}_{re_type}_area-{area_thr/10000}ha.gpkg'\n",
    "    vecto_big_write_path = f'{interimFiles_path}allsub/{vecto_big_write_file}'\n",
    "    # Apply small areas threshold\n",
    "    gdf_big = gdf.loc[gdf['Area_(m2)']>=area_thr]\n",
    "    # Save to file\n",
    "    gdf_big.to_file(vecto_big_write_path)\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logvec = f'Subtractions result vectorized and saved to disk --- {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "        print(logvec)\n",
    "        logfile.writelines([logvec,'\\n'])\n",
    "    del [data,mask,shape_gen,gdf,gdf_big,area_thr]\n",
    "    gc.collect()\n",
    "\n",
    "    logend = f'Allsub done! Go check you final maps at {vecto_write_path} and {vecto_big_write_path}!'\n",
    "    print(logend)\n",
    "    # Performance check\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    logproc = f'Allsub for scenario {scenario_nr}, RE type : {re_type}. Code block run in {elapsed_time_str}\\n'\n",
    "    print(logproc[:-2])\n",
    "    # Write to log\n",
    "    with open(logpath, 'a') as logfile:\n",
    "        logfile.writelines([logend,'\\n', logproc])\n",
    "\n",
    "    return vecto_write_path, vecto_big_write_path\n",
    "\n",
    "    \n",
    "    # Beeps\n",
    "    for i in range(40,6500,400):\n",
    "        winsound.Beep(i, 200)\n",
    "        time.sleep(0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954585c-b914-4174-b88d-a4249eaa0821",
   "metadata": {},
   "source": [
    "#### 2.2.1.5 Final wrapper (mcdm_process) \n",
    "Runs allsub for both RE per scenario, then combines result gpkg into 1 to figure out intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15d423ae-5160-477c-a55f-c64bbbe357d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overarching function to run all subtractions, polygonise results and apply small areas threshold\n",
    "# created 25/02\n",
    "# last edit 11/03\n",
    "def mcdm_process(fac_df, scenario_nr, overwrite = False):\n",
    "    start = time.perf_counter() # Performance counter\n",
    "    ### Run allsub\n",
    "    re_type_list = ['Solar','Wind']\n",
    "    for i in re_type_list:\n",
    "        allsub(fac_df = fac_df,re_type = i, scenario_nr = scenario_nr, overwrite = overwrite)\n",
    "    ### Combine result gpkg\n",
    "    # Get filenames lists for processing\n",
    "    allsub_folder = f'{interimFiles_path}allsub'\n",
    "    filenames = os.listdir(allsub_folder)\n",
    "    scenar_str = f'Scenario{scenario_nr}_'\n",
    "    filenames_scenario = [_ for _ in filenames if scenar_str in _]\n",
    "    sol_thr = fac_df.loc[(fac_df['Resource']=='Solar') & (fac_df['Class']=='Small areas'),f'S{scenario_nr} Threshold'].iloc[0]/10000\n",
    "    win_thr = fac_df.loc[(fac_df['Resource']=='Wind') & (fac_df['Class']=='Small areas'),f'S{scenario_nr} Threshold'].iloc[0]/10000\n",
    "    sol_area_str = f'_area-{sol_thr}ha'\n",
    "    win_area_str = f'_area-{win_thr}ha'\n",
    "    all_str = '_all'\n",
    "    results_all = [_ for _ in filenames_scenario if all_str in _]\n",
    "    results_big = [_ for _ in filenames_scenario if sol_area_str in _ or win_area_str in _]\n",
    "    if len(results_all) != 2:\n",
    "        raise ValueError(f'Number of files processed MUST be 2, current list: {results_all}')\n",
    "    if len(results_big) != 2:\n",
    "        raise ValueError(f'Number of files processed MUST be 2, current list: {results_big}')\n",
    "    print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}  -- Files being combined: {[results_all,results_big]}')\n",
    "    # Combination process runs twice: once for all results (Wind+Solar), once for areas above threshold only (Wind+Solar)\n",
    "    for i in [results_all,results_big]:\n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}  -- Combining  {i[0]} and {i[1]}')\n",
    "        df1 = gpd.read_file(f'{allsub_folder}/{i[0]}')\n",
    "        df2 = gpd.read_file(f'{allsub_folder}/{i[1]}')\n",
    "        df3 = df1.overlay(df2, how = 'union', keep_geom_type=None)\n",
    "        df3['Area_(m2)'] = df3['geometry'].area\n",
    "        df3['RE_type_1'] = df3['RE_type_1'].fillna('')\n",
    "        df3['RE_type_2'] = df3['RE_type_2'].fillna('')\n",
    "        df3['RE_type'] = df3['RE_type_1']+df3['RE_type_2']\n",
    "        df3.drop(columns = ['Area_(m2)_1', 'RE_type_1', 'Area_(m2)_2', 'RE_type_2'], inplace = True)\n",
    "        # Save to file\n",
    "        write_file = i[0].replace('Solar_','')\n",
    "        write_file = re.sub(r'area.*?ha','area_threshold', write_file) # Removing area size from final combo filename as it can be different btw solar and wind\n",
    "        df3.to_file(f'{output_path}areas/{write_file}')\n",
    "\n",
    "    # Release variables for memory\n",
    "    del [df1,df2,df3]\n",
    "    gc.collect()\n",
    "    \n",
    "    # Performance check\n",
    "    end = time.perf_counter()\n",
    "    elapsed_time = end - start\n",
    "    # Convert the elapsed time to a timedelta object \n",
    "    elapsed_time_str = str(timedelta(seconds=elapsed_time))\n",
    "    print(f'MCDM Code block for scenario {scenario_nr} run in {elapsed_time_str}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e97d84-da0a-4be9-8120-575baccdc4e7",
   "metadata": {},
   "source": [
    "### 2.2.2 Run subtraction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2d99a-7d32-4f26-bc2e-6b5969a231a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________LAYERS SUBTRACTIONS - Scenario 5_________________ \n",
      "Start 2025-03-13 23:22:30.988396 \n",
      " RE type: Solar\n",
      "Rassub - Start time --- 2025-03-13 23:22:31 \n",
      "Subtraction order: \n",
      "3                                   OS_open_roads_lines\n",
      "5                                   Water_rivers_merged\n",
      "7                              global_solar_2020_merged\n",
      "9                        global_wind_2020_point_cropped\n",
      "10                                          UK_ALC_cat1\n",
      "12                                          UK_ALC_cat2\n",
      "15                           hotosm_gbr_airports_points\n",
      "16                                      UKCEH_10m_urban\n",
      "20                            Heritage_WHS_Battlefields\n",
      "22                                   Heritage_Monuments\n",
      "24                               Heritage_Parks_Gardens\n",
      "25                     Heritage_Listed_Buildings_merged\n",
      "27                                      JNCC_Ramsar_SPA\n",
      "30                                   UKCEH_10m_woodland\n",
      "33                                 Peatland_Lvl1_merged\n",
      "34                                 Peatland_Lvl2_merged\n",
      "37                                          UK_ALC_cat3\n",
      "38           UNEP-WCMC_Protected_Areas_2024_merged_cat1\n",
      "40           UNEP-WCMC_Protected_Areas_2024_merged_cat2\n",
      "42           UNEP-WCMC_Protected_Areas_2024_merged_cat3\n",
      "45           UNEP-WCMC_Protected_Areas_2024_merged_cat4\n",
      "46    OS Terrain 10m slope bicubic deflate float32 s...\n",
      "49                               substations_Lovett2022\n",
      "50                                     Solar-GHI_extent\n",
      "Name: filename_noExt, dtype: object\n",
      "Gc.collect applied\n",
      "\n",
      "File S5_Solar_rassub0_Transportation Network_20.tif does not exist. Processing...\n",
      "2025-03-13 23:22:31 - Processing layer 0, class: Transportation Network. \n",
      "File subtracted: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/OS_open_roads_lines_rasbuf_20.tif\n",
      "Subtracting from rassub base\n",
      " Mask creation Start 2025-03-13 23:23:39\n",
      "Threshold = nan (if NA, all values above 0 are masked)\n",
      "No threshold, binary subtraction\n",
      "Difference Start 2025-03-13 23:23:40\n",
      "2025-03-13 23:23:40 - Raster Difference 0 complete.\n",
      "Gc.collect applied\n",
      "2025-03-13 23:35:12 - Writing of rassub 0 file complete. Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/subs/S5_Solar_rassub0_Transportation Network_20.tif\n",
      "Gc.collect applied\n",
      "2025-03-13 23:35:17 End of loop 0\n",
      "Gc.collect applied\n",
      "Gc.collect applied\n",
      "\n",
      "File S5_Solar_rassub1_Water and rivers_10.tif does not exist. Processing...\n",
      "2025-03-13 23:35:17 - Processing layer 1, class: Water and rivers. \n",
      "File subtracted: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/Water_rivers_merged_rasbuf_10.tif\n",
      "Reading from previous layer: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/subs/S5_Solar_rassub0_Transportation Network_20.tif --- 2025-03-13 23:35:52\n",
      "Mask creation Start 2025-03-13 23:36:29\n",
      "Threshold = nan (if NA, all values above 0 are masked)\n",
      "No threshold, binary subtraction\n",
      "Gc.collect applied\n",
      "Difference Start 2025-03-13 23:36:31\n",
      "2025-03-13 23:36:31 - Raster Difference 1 complete.\n",
      "2025-03-13 23:49:03 - Writing of rassub 1 file complete. Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/subs/S5_Solar_rassub1_Water and rivers_10.tif\n",
      "Gc.collect applied\n",
      "2025-03-13 23:49:06 End of loop 1\n",
      "Gc.collect applied\n",
      "Gc.collect applied\n",
      "\n",
      "File S5_Solar_rassub2_Existing Solar_10.tif does not exist. Processing...\n",
      "2025-03-13 23:49:07 - Processing layer 2, class: Existing Solar. \n",
      "File subtracted: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/global_solar_2020_merged_rasbuf_10.tif\n",
      "Reading from previous layer: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/subs/S5_Solar_rassub1_Water and rivers_10.tif --- 2025-03-13 23:49:36\n",
      "Mask creation Start 2025-03-13 23:50:06\n",
      "Threshold = nan (if NA, all values above 0 are masked)\n",
      "No threshold, binary subtraction\n",
      "Gc.collect applied\n",
      "Difference Start 2025-03-13 23:50:07\n",
      "2025-03-13 23:50:07 - Raster Difference 2 complete.\n",
      "2025-03-14 00:02:11 - Writing of rassub 2 file complete. Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/subs/S5_Solar_rassub2_Existing Solar_10.tif\n",
      "Gc.collect applied\n",
      "2025-03-14 00:02:16 End of loop 2\n",
      "Gc.collect applied\n",
      "Gc.collect applied\n",
      "\n",
      "File S5_Solar_rassub3_Existing Wind_45.tif does not exist. Processing...\n",
      "2025-03-14 00:02:16 - Processing layer 3, class: Existing Wind. \n",
      "File subtracted: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/rasbuf/global_wind_2020_point_cropped_rasbuf_45.tif\n",
      "Reading from previous layer: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/subs/S5_Solar_rassub2_Existing Solar_10.tif --- 2025-03-14 00:02:41\n",
      "Mask creation Start 2025-03-14 00:03:07\n",
      "Threshold = nan (if NA, all values above 0 are masked)\n",
      "No threshold, binary subtraction\n",
      "Gc.collect applied\n",
      "Difference Start 2025-03-14 00:03:08\n",
      "2025-03-14 00:03:08 - Raster Difference 3 complete.\n",
      "2025-03-14 00:15:59 - Writing of rassub 3 file complete. Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/subs/S5_Solar_rassub3_Existing Wind_45.tif\n",
      "Gc.collect applied\n",
      "2025-03-14 00:16:03 End of loop 3\n",
      "Gc.collect applied\n",
      "Gc.collect applied\n",
      "\n",
      "File S5_Solar_rassub4_Agricultural grade 1_0.tif does not exist. Processing...\n",
      "2025-03-14 00:16:04 - Processing layer 4, class: Agricultural grade 1. \n",
      "File subtracted: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Agrigrades/UK_ALC_cat1.tif\n",
      "Reading from previous layer: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/subs/S5_Solar_rassub3_Existing Wind_45.tif --- 2025-03-14 00:16:39\n",
      "Mask creation Start 2025-03-14 00:17:10\n",
      "Threshold = nan (if NA, all values above 0 are masked)\n",
      "No threshold, binary subtraction\n",
      "Gc.collect applied\n",
      "Difference Start 2025-03-14 00:17:14\n",
      "2025-03-14 00:17:14 - Raster Difference 4 complete.\n",
      "2025-03-14 00:29:53 - Writing of rassub 4 file complete. Path: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/subs/S5_Solar_rassub4_Agricultural grade 1_0.tif\n",
      "Gc.collect applied\n",
      "2025-03-14 00:29:57 End of loop 4\n",
      "Gc.collect applied\n",
      "Gc.collect applied\n",
      "\n",
      "File S5_Solar_rassub5_Agricultural grade 2_0.tif does not exist. Processing...\n",
      "2025-03-14 00:29:57 - Processing layer 5, class: Agricultural grade 2. \n",
      "File subtracted: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/data/prepped_data/Agrigrades/UK_ALC_cat2.tif\n",
      "Reading from previous layer: C:/Users/roro_/Documents/University/UG year 3/6SSG0610 IGS Independent Geographical Study/output/intermediate_files/subs/S5_Solar_rassub4_Agricultural grade 1_0.tif --- 2025-03-14 00:30:23\n",
      "Mask creation Start 2025-03-14 00:30:51\n",
      "Threshold = nan (if NA, all values above 0 are masked)\n",
      "No threshold, binary subtraction\n",
      "Gc.collect applied\n",
      "Difference Start 2025-03-14 00:30:53\n",
      "2025-03-14 00:30:53 - Raster Difference 5 complete.\n"
     ]
    }
   ],
   "source": [
    "scenario_nr = 5\n",
    "mcdm_process(fac_df=fac_df, scenario_nr=scenario_nr, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492b2985-c927-48f8-bd39-a15df5af18ee",
   "metadata": {},
   "source": [
    "# 3. Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935fe8e5-499d-4d5c-8ba4-f87675e42ab5",
   "metadata": {},
   "source": [
    "## Imported layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37b8b9-0ed8-4b7a-827f-7c7c963ef0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking imported layers\n",
    "start = time.perf_counter()\n",
    "fig, ax = plt.subplots(1,1,figsize=(15,25))\n",
    "AOI.plot(ax=ax, color='none', edgecolor='grey',linewidth=0.1)\n",
    "PAs.plot(ax=ax, color='darkgreen', edgecolor='none', alpha=0.5)\n",
    "solSitesPoly.plot(ax=ax, color='red')\n",
    "solSitesPt.plot(ax=ax, markersize=0.1, color='yellow')\n",
    "winSitesPt.plot(ax=ax, markersize=0.1, color='blue')\n",
    "ax.set_xlim(0,700000) #Defining map extent\n",
    "ax.set_ylim(-20000,1250000) #Defining map extent\n",
    "plt.show()\n",
    "print('Code block run in '+str(end-start)+' s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd61ac-362c-48d8-9ded-37207b0f494d",
   "metadata": {},
   "source": [
    "## Buffers & exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b0c04-88ad-43ab-9f53-d3fd8cf419b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking buffers\n",
    "fig, ax = plt.subplots(1,1,figsize=(15,25))\n",
    "AOI.plot(ax=ax, color='lightgrey', edgecolor='none',linewidth=0.1)\n",
    "winSitesPt_b.plot(ax=ax, color='blue', edgecolor='none', alpha=0.5)\n",
    "solSitesPoly_b.plot(ax=ax, color='orange', edgecolor='none', alpha=0.5)\n",
    "solSitesPt_b.plot(ax=ax, color='yellow', edgecolor='none', alpha=0.5)\n",
    "ax.set_xlim(170000,200000) #Zooming in on smaller region\n",
    "ax.set_ylim(20000,50000) #Zooming in on smaller region\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1ac4b-c4c5-44ae-b9ee-046bd8324e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking exclusions mask\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,14))\n",
    "exclusions_mask.plot(ax=ax, alpha=0.5)\n",
    "ax.set_xlim(170000,200000) #Zooming in on smaller region\n",
    "ax.set_ylim(20000,50000) #Zooming in on smaller region\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04cef90-a580-4349-bfd4-c18dddcae3f1",
   "metadata": {},
   "source": [
    "## Applied exclusions & final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea2384-73d9-4ffb-a257-797812fe9406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking ginal output\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,14))\n",
    "show(sol_GHI_cstr_thr[0], cmap='viridis',ax=ax)\n",
    "#ax.set_xlim(170000,200000) #Zooming in on smaller region\n",
    "#ax.set_ylim(20000,50000) #Zooming in on smaller region\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3008a5-881e-4095-87c3-7d0a7904f868",
   "metadata": {},
   "source": [
    "## Memory usage check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9753db7b-7450-475d-b703-779e53aa1c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory use: [('factors_df', 61701), ('fac_df', 28020), ('MultiPolygon', 936), ('Point', 936), ('Polygon', 936)]\n"
     ]
    }
   ],
   "source": [
    "## Check memory usage\n",
    "logram = f'RAM memory % used:{psutil.virtual_memory()[2]} --- RAM Used (GB):{bytes2human(psutil.virtual_memory()[3])}\\nSwap memory used {psutil.swap_memory().percent}% --- {bytes2human(psutil.swap_memory().used)}'\n",
    "print(logram)\n",
    "## Code from:\n",
    "## https://stackoverflow.com/questions/40993626/list-memory-usage-in-ipython-and-jupyter\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "print(f'Memory use: {sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c7371a-2f12-458c-bcd9-9215a4a1ef08",
   "metadata": {},
   "source": [
    "## Debug raster metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c395a87-c7cf-42e8-a63b-b6573b8e6e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "None\n",
      "{'COMPRESSION': 'DEFLATE', 'INTERLEAVE': 'PIXEL'}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "paths_iteration = f'{preppedDat_path}UKCEH_10m_water.tif'\n",
    "with rio.open(paths_iteration) as src:\n",
    "    raster = src.read(1)\n",
    "    crs=src.crs\n",
    "    transform = src.transform\n",
    "    meta = src.tags(1)\n",
    "    max_val = meta.get('STATISTICS_MAXIMUM')\n",
    "    print(meta)\n",
    "    print(max_val)\n",
    "    print(src.tags(ns='IMAGE_STRUCTURE'))\n",
    "    print(src.tags(ns='SUBDATASETS'))\n",
    "    print(src.tags(ns='RPC'))\n",
    "#    if int(max_val) > 1:\n",
    "#        logmax = f'Maximum value is bigger than 1, CHECK RESULTS! (Max = {max_val}).\\n'\n",
    "#        print(logmax[:-2])\n",
    "#    else:\n",
    "#        logmax = f'(Max value = {max_val}).\\n'\n",
    "#        print(logmax[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb4711e3-4e26-4a29-9958-423abb5033c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del raster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
